# LangChain Components

![author](https://img.shields.io/badge/author-mohd--faizy-red)

# Langchain components

![image.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/Lang_comp.png)

# ðŸ”¹ **1. Models â€“ The Core of LangChain**

---

### ðŸ“Œ **What Are LangChain Models?**

- ðŸ§  The **Models component** is the **core interface** to interact with AI models (LLMs & Embedding Models).
- ðŸ”„ LangChain is **model-agnostic** â€“ you can switch between different LLM providers with minimal code changes.
- ðŸ› ï¸ Solves the **standardization problem** â€“ every provider (`OpenAI`, `Gemini`, `Anthropic`, etc.) has different APIs, but LangChain offers one unified interface.


### ðŸ“š **Why Are Models Important?**

- âœ… Most important component of LangChain â€“ it's where the AI â€œthinks.â€
- ðŸ¤– Handles both **language generation** (chatbots, agents) and **vector embedding** (search, retrieval).
- ðŸ—ï¸ Acts as a **foundation** for the other 5 components: Prompts, Chains, Memory, Indexes, Agents.


### ðŸ” **Challenges Solved by LangChain Models**

1. ðŸ§± **Huge Size** of LLMs (100GB+) â†’ Solved via API access.
2. ðŸ”Œ **Different APIs for Different Providers** â†’ LangChain unifies them.
3. ðŸ” **No Standardized Output/Input Handling** â†’ LangChain parses and handles it uniformly.


### ðŸ¤¹â€â™‚ï¸ **Types of Models in LangChain**

1. ðŸ—£ï¸ **Language Models (LLMs)**
    - Input: Text
    - Output: Text
    - Use cases: Chatbots, summarization, translation, coding.
    - Providers: `OpenAI`, `Claude`, `Hugging Face`, `Bedrock`, `Mistral`, `Vertex AI`, `Azure`.
  
2. ðŸ§­ **Embedding Models**
    - Input: Text
    - Output: Vector (numerical representation)
    - Use case: `Semantic Search` / `Vector DB`
    - Providers: `OpenAI`, `Mistral` AI, `IBM`, `Llama`, etc.


### ðŸ§ª **Features Supported Across Models**

- ðŸ§° Tool calling
- ðŸ“¦ JSON / Structured output
- ðŸ§‘â€ðŸ’» Local execution
- ðŸ“¸ Multimodal input (e.g., images + text)


## ðŸ’¡ **Code Examples for LangChain Models**

### 1ï¸âƒ£ Load a Chat Model (OpenAI)

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4", temperature=0.7)
response = llm.invoke("What is the capital of France?")

print(response.content)

```


### 2ï¸âƒ£ Load a Chat Model (Anthropic Claude)

```python
from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(model="claude-3-opus-20240229")
response = llm.invoke("Explain quantum entanglement in simple terms.")

print(response.content)

```


### 3ï¸âƒ£ Load an Embedding Model (OpenAI)

```python
from langchain_openai import OpenAIEmbeddings

embedder = OpenAIEmbeddings()
vector = embedder.embed_query("What is machine learning?")

print(vector[:5])  # Print first 5 values of the vector

```


### 4ï¸âƒ£ Switch Between Providers with 1 Line

```python
# Switching from OpenAI to Mistral (Minimal change)
from langchain_mistralai import ChatMistralAI

llm = ChatMistralAI(model="mistral-small")
response = llm.invoke("Summarize the plot of Inception.")

print(response.content)

```


### 5ï¸âƒ£ Use Local Language Model (e.g., Llama.cpp or Ollama)

```python
from langchain_community.chat_models import ChatOllama

llm = ChatOllama(model="llama2")
response = llm.invoke("What are black holes?")

print(response.content)

```


### 6ï¸âƒ£ Advanced: JSON Output from a Chat Model

```python
llm = ChatOpenAI(model="gpt-4", temperature=0.2)
response = llm.invoke("Return a JSON of 3 countries and their capitals.")

# Ensure the output is structured JSON (using function calling or prompt formatting)
print(response.content)  # Should be a structured response like: {"France": "Paris", ...}

```


### âœ… **Summary**

- The **Models component** provides a **standardized, pluggable way** to interact with any LLM or embedding model.
- Enables rapid experimentation and development with **minimal vendor lock-in**.
- Supports both **language tasks (text in â†’ text out)** and **vector embeddings (text in â†’ vector out)**.


---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

---

# ðŸ”¹**2. Prompts â€“ Crafting the Right Questions for LLMs**

### ðŸ“Œ **What Are Prompts in LangChain?**

- âœï¸ A **prompt** is the **input or instruction** you give to an LLM.
- â— The **quality of the output** depends directly on the **quality of the prompt**.
- ðŸ§  Even small changes in the prompt can **hugely change** the LLMâ€™s response.
- ðŸ§ª Example:
  - "Explain Linear Regression in an academic tone"
  - vs
  - "Explain Linear Regression in a fun tone"

        ðŸ”„ â†’ Two completely different outputs!

### ðŸŽ“ **Why Are Prompts Important?**

- ðŸ’¥ Prompts are the **most sensitive and influential** part of working with LLMs.
- ðŸ§‘â€ðŸ”¬ The rise of **Prompt Engineering** as a field (and job!) proves how central prompts are.
- ðŸ§© LangChain provides a **Prompts component** to manage, customize, and structure prompts efficiently.


### ðŸ§° **What the Prompts Component Offers**

- ðŸ”„ **Dynamic prompts** â€“ insert values at runtime using placeholders.
- ðŸ§‘â€âš–ï¸ **Role-based prompts** â€“ guide the LLM to take on a persona or expertise.
- ðŸ§ª **Few-shot prompts** â€“ train the model by showing it examples of the behavior you expect.
- ðŸ“¦ Reusability â€“ create prompt **templates** you can use again and again in different contexts.


## ðŸ§  **Types of Prompts in LangChain**

### 1ï¸âƒ£ Dynamic & Reusable Prompts

- ðŸ”§ Use placeholders like `{topic}` or `{tone}` that get filled dynamically.
- âœ… Example: `"Summarize this {topic} in a {tone} tone."`

### 2ï¸âƒ£ Role-Based Prompts

- ðŸ§‘â€âš•ï¸ Use a system-level prompt like: `"You are an experienced doctor."`
- ðŸ‘¤ Then ask: `"Explain symptoms of viral fever."`

### 3ï¸âƒ£ Few-Shot Prompts

- ðŸŽ“ Give **input-output examples** to teach the model before the real query.
- ðŸ“Š Example: Show how messages map to categories before asking it to classify a new one.


## ðŸ§ª **Code Examples for LangChain Prompts**

### 1ï¸âƒ£ Basic Prompt Template

```python
from langchain.prompts import PromptTemplate

prompt = PromptTemplate.from_template("What is {topic}?")
formatted = prompt.format(topic="Quantum Computing")
print(formatted)

```


### 2ï¸âƒ£ Dynamic Multi-Variable Prompt

```python
prompt = PromptTemplate.from_template("Summarize the topic '{topic}' in a {tone} tone.")
print(prompt.format(topic="Climate Change", tone="fun"))

```


### 3ï¸âƒ£ Role-Based Prompt with System Message

```python
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template("You are an expert {profession}."),
    HumanMessagePromptTemplate.from_template("Tell me about {topic}.")
])

formatted = prompt.format_messages(profession="architect", topic="modern skyscrapers")
print([msg.content for msg in formatted])

```


### 4ï¸âƒ£ Few-Shot Prompt Template

```python
from langchain.prompts import FewShotPromptTemplate

examples = [
    {"message": "I can't log in", "category": "Technical Issue"},
    {"message": "Please update my billing info", "category": "Billing"}
]

example_template = PromptTemplate.from_template("User: {message}\nCategory: {category}\n")
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_template,
    prefix="Classify the user's query:",
    suffix="User: {query}\nCategory:",
    input_variables=["query"]
)

print(few_shot_prompt.format(query="How do I change my credit card info?"))

```


### 5ï¸âƒ£ Combine Prompt with Chat Model

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4")
response = llm.invoke(prompt.format(topic="Machine Learning", tone="formal"))
print(response.content)

```


### 6ï¸âƒ£ Prompt with Custom Jinja Template (Advanced)

```python
from langchain.prompts import PromptTemplate

template = """You are a {role}.
Answer the question below clearly and professionally.

Question: {question}
"""

prompt = PromptTemplate(template=template, input_variables=["role", "question"])
print(prompt.format(role="data scientist", question="What is overfitting?"))

```


### âœ… **Summary**

- The **Prompts component** gives **full control** over how you talk to LLMs.
- Enables **reusable, flexible, and structured** prompt design.
- Makes your apps **more reliable and intelligent** by controlling how LLMs interpret input.
- âœ¨ Essential for building smart, adaptive, and role-aware AI apps.

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)


# ðŸ”¹ **3. Chains â€“ Build Smart Pipelines for LLM Workflows**

### ðŸ“Œ **What Are Chains in LangChain?**

- ðŸ”— Chains are used to **link multiple steps** of an LLM app into a **single automated pipeline**.
- ðŸ¤– LangChain is **named after Chains** â€“ thatâ€™s how fundamental they are!
- âš™ï¸ They let you build **sequential**, **parallel**, or **conditional** flows between components like LLMs, tools, and memory.


### âš¡ **Why Use Chains?**

- ðŸ”„ Automatically passes the **output of one step as the input** to the next.
- ðŸ§¼ Avoids repetitive manual code to handle data transfer between steps.
- ðŸš€ Lets you design **multi-step AI applications** that work as one smooth pipeline.


### ðŸ› ï¸ **Real-World Use Case (Sequential Chain Example)**

### ðŸ” English Text âž¡ï¸ Hindi Translation âž¡ï¸ Hindi Summary

1. Step 1: Translate English to Hindi (LLM 1)
2. Step 2: Summarize Hindi text (LLM 2)

    âœ… Chains handle this flow without manual intervention â€” just input English text and get the final Hindi summary.


### ðŸ” **Types of Chains in LangChain**

### 1ï¸âƒ£ **Sequential Chains**

- Steps run **one after another** in order.
- Example: Translate â†’ Summarize â†’ Format â†’ Output

### 2ï¸âƒ£ **Parallel Chains**

- ðŸ§  Run multiple LLMs **simultaneously** and combine results.
- Example: Same input sent to 3 LLMs to generate different takes â†’ Combine in final report.

### 3ï¸âƒ£ **Conditional Chains**

- ðŸ¤” Branching logic: behavior changes based on input/response.
- Example: If user feedback is negative â†’ Send alert to support; else â†’ Send thank-you note.


## ðŸ’» **Code Examples for LangChain Chains**


### 1ï¸âƒ£ Basic LLMChain (1-step flow)

```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_openai import OpenAI

llm = OpenAI(model="gpt-3.5-turbo")
prompt = PromptTemplate.from_template("Translate the following English text to Hindi:\n\n{text}")

chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run("I love learning about AI.")
print(result)

```


### 2ï¸âƒ£ SequentialChain: Translation âž¡ï¸ Summarization

```python
from langchain.chains import SequentialChain

translate_prompt = PromptTemplate.from_template("Translate to Hindi:\n\n{text}")
summary_prompt = PromptTemplate.from_template("Summarize this Hindi text in under 100 words:\n\n{text}")

translate_chain = LLMChain(llm=llm, prompt=translate_prompt, output_key="translated")
summary_chain = LLMChain(llm=llm, prompt=summary_prompt, input_key="translated")

full_chain = SequentialChain(
    chains=[translate_chain, summary_chain],
    input_variables=["text"],
    output_variables=["translated", "text"]
)

result = full_chain.run({"text": "Artificial Intelligence is transforming the world."})
print(result)

```


### 3ï¸âƒ£ Simple Conditional Chain (If-Else Logic)

```python
from langchain.chains import TransformChain

def route_feedback(inputs):
    feedback = inputs["feedback"]
    return {"action": "thank user" if "good" in feedback.lower() else "alert support"}

router = TransformChain(input_variables=["feedback"], output_variables=["action"], transform=route_feedback)

result = router.run({"feedback": "The product is not working."})
print(result)

```


### 4ï¸âƒ£ Parallel Chain (Mock Conceptual Example)

```python
from langchain.chains import SimpleSequentialChain

prompt1 = PromptTemplate.from_template("Write a poem about {topic}")
prompt2 = PromptTemplate.from_template("Write a joke about {topic}")

chain1 = LLMChain(llm=llm, prompt=prompt1)
chain2 = LLMChain(llm=llm, prompt=prompt2)

# In practice, you could run these chains in parallel using asyncio or LangGraph (experimental)
poem = chain1.run("robots")
joke = chain2.run("robots")

print("Poem:\n", poem)
print("Joke:\n", joke)

```


### 5ï¸âƒ£ Chain with Memory Integration (Preview)

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
prompt = PromptTemplate.from_template("You are a chatbot. User said: {input}")

chain = LLMChain(llm=llm, prompt=prompt, memory=memory)
print(chain.run("Hello, how are you?"))
print(chain.run("What did I just say?"))

```


### âœ… **Summary**

- ðŸ§© **Chains** simplify **multi-step workflows** in LLM applications.
- ðŸ’¡ They abstract away manual code and let you focus on logic and flow.
- ðŸ§  Types:
  - **Sequential** â€“ one step after another
  - **Parallel** â€“ multiple steps at once
  - **Conditional** â€“ smart branching
- ðŸ“¦ Combine Chains with Prompts, Memory, and Agents for powerful apps.

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

---

# ðŸ§  **4. Memory â€“ Remembering Past Conversations in LangChain**

### ðŸ“Œ **What Is Memory in LangChain?**

- ðŸ” Most LLMs like GPT are **stateless** â€” they forget everything after each message.
- âŒ If you ask:
  - "Who is Narendra Modi?"
  - Then: "How old is he?"
  - â†’ The model doesnâ€™t remember who *"he"* is.
- ðŸ§  **Memory solves this problem** by maintaining **context across turns** in a conversation.



### ðŸš€ **Why Is Memory Important?**

- ðŸ—£ï¸ Makes **chatbots and assistants feel natural and human-like**.
- ðŸ§¾ Keeps track of what users say â€” no need to repeat questions.
- ðŸ¤– Essential for building **stateful AI applications** like customer service bots, AI tutors, assistants, etc.


### ðŸ” **Types of Memory in LangChain**

| ðŸ§  Type | ðŸ“‹ Description | ðŸ’¡ Use Case |
| --- | --- | --- |
| **ConversationBufferMemory** | Stores **full chat history** | Best for short conversations |
| **ConversationBufferWindowMemory** | Stores **last N messages** | Great for recent context without overloading |
| **ConversationSummaryMemory** | Stores a **summary of conversation** | Ideal for long chats, saves cost |
| **Custom Memory** | Store **special facts or variables** | Good for personalized assistants |



## ðŸ’» **Code Examples for LangChain Memory**


### 1ï¸âƒ£ Basic Memory Integration with `LLMChain`

```python
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_openai import OpenAI

llm = OpenAI(model="gpt-3.5-turbo")
memory = ConversationBufferMemory()

prompt = PromptTemplate.from_template("You are a helpful bot. User said: {input}")
chain = LLMChain(llm=llm, prompt=prompt, memory=memory)

# Simulate conversation
print(chain.run("Who is Virat Kohli?"))
print(chain.run("What team does he play for?"))  # Remembers previous message

```


### 2ï¸âƒ£ Using `ConversationBufferWindowMemory`

```python
from langchain.memory import ConversationBufferWindowMemory

memory = ConversationBufferWindowMemory(k=2)  # Remembers last 2 interactions

chain = LLMChain(llm=llm, prompt=prompt, memory=memory)
print(chain.run("Explain Machine Learning."))
print(chain.run("Give an example."))
print(chain.run("What did I just say?"))  # Only remembers 2 last messages

```


### 3ï¸âƒ£ Using `ConversationSummaryMemory` (with summarization)

```python
from langchain.memory import ConversationSummaryMemory

summary_memory = ConversationSummaryMemory(llm=llm)  # Uses LLM to auto-summarize past chat

chain = LLMChain(llm=llm, prompt=prompt, memory=summary_memory)
print(chain.run("Explain the plot of Inception."))
print(chain.run("Who was the main character?"))  # Will have access to summary, not full text

```


### 4ï¸âƒ£ Custom Memory Example (storing variables)

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.save_context({"input": "My name is Alex"}, {"output": "Nice to meet you, Alex!"})
memory.save_context({"input": "I live in Delhi"}, {"output": "Delhi is a great city."})

# Access stored memory
print(memory.load_memory_variables({}))  # Returns entire conversation history

```


### 5ï¸âƒ£ Use Memory with a ChatPromptTemplate

```python
from langchain.prompts import ChatPromptTemplate
from langchain.chains import ConversationChain

chat_prompt = ChatPromptTemplate.from_template("Human: {input}\nAI:")

conversation = ConversationChain(
    llm=llm,
    prompt=chat_prompt,
    memory=ConversationBufferMemory()
)

print(conversation.run("Tell me a joke."))
print(conversation.run("Another one please!"))  # Keeps previous context

```


### âœ… **Summary**

- ðŸ§  **Memory makes LangChain apps stateful** â€” just like real conversations.
- ðŸ’¬ It keeps track of what was said earlier and gives the model **context**.
- ðŸ”§ Use different memory types based on your appâ€™s need:
  - Full history (Buffer)
  - Recent messages only (Window)
  - Summarized context (Summary)
- ðŸ§© Combine Memory with Chains, Prompts, and Models to build **real conversational agents**.

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)


# ðŸ—‚ï¸ **5. Indexes â€“ Letting LLMs Use Your Private Data**

### ðŸ¤” **Why Do We Need Indexes?**

- ðŸ¤– LLMs like ChatGPT **do not know your private data**.
  - âŒ "Whatâ€™s the leave policy of XYZ company?" â†’ Can't answer.
  - Because it's **not in the training data**.
- âœ… We solve this using **Indexes** in LangChain to:
  - **Connect LLMs to external data** (e.g. PDFs, websites).
  - **Search and retrieve only whatâ€™s needed** from this data.
  - Use it for **answering questions** based on it.


### ðŸ§± **The 4 Core Sub-Components of Indexes**

| ðŸ”¢ | ðŸ”§ Component | ðŸ“‹ Role |
| --- | --- | --- |
| 1ï¸âƒ£ | **Document Loader** | Loads your file (PDF, CSV, Notion, Drive, etc.) |
| 2ï¸âƒ£ | **Text Splitter** | Breaks large text into smaller chunks |
| 3ï¸âƒ£ | **Vector Store** | Stores chunk embeddings for similarity search |
| 4ï¸âƒ£ | **Retriever** | Finds the best chunks for a user query |


### ðŸ“Š **How It Works (Simplified Flow)**

```
PDF file (RulesBook.pdf)
     â†“
[1] Document Loader âžœ Load the document
     â†“
[2] Text Splitter âžœ Split into small chunks
     â†“
[3] Vector Store âžœ Embed chunks + Store
     â†“
[4] Retriever âžœ Semantic search on user query
     â†“
     LLM (answers based on relevant chunks)

```



## ðŸ’» **LangChain Indexes â€“ Code Example**


### ðŸ§¾ 1. Load Your PDF Document

```python
from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("XYZ_Company_Policy.pdf")
docs = loader.load()

```


### âœ‚ï¸ 2. Split Into Chunks

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(docs)

```


### ðŸ§  3. Create Embeddings + Vector Store

```python
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
vector_store = FAISS.from_documents(chunks, embeddings)

```


### ðŸ” 4. Setup Retriever and Ask Questions

```python
retriever = vector_store.as_retriever()

query = "What is the official leave policy?"
relevant_docs = retriever.get_relevant_documents(query)

for doc in relevant_docs:
    print(doc.page_content)

```


### âœ… Optional: Use with RetrievalQA Chain

```python
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(),
    retriever=retriever
)

print(qa_chain.run("What is the resignation notice period?"))

```


## ðŸ§  **Why Indexes Are Crucial**

- ðŸ”“ They unlock the **power of private, local, or custom data**.
- âš™ï¸ They work seamlessly with other components (like Prompts + Chains).
- ðŸ“š Perfect for building:
  - Internal company chatbots
  - Personalized tutors
  - Research assistants
  - FAQ bots on your data


## ðŸ” Recap of the 4 Sub-Components

| ðŸ“ DocumentLoader | ðŸ”¢ TextSplitter | ðŸ§  VectorStore | ðŸ•µï¸â€â™‚ï¸ Retriever |
| --- | --- | --- | --- |
| Load files | Split into chunks | Store vectors | Find relevant chunks |

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)


# ðŸ¤– **6. Agents â€“ The Smartest, Action-Oriented Component**

### ðŸ’¡ **What Are Agents?**

- Think of Agents as **chatbots with superpowers** âš¡
- They donâ€™t just *respond* â€“ they can **think, decide, and act**
- Agents combine:
  - ðŸ§  Reasoning (`"What should I do first?"`)
  - ðŸ”§ Tool use (`"Let me use a calculator or weather API"`)
  - ðŸ§© Integration with other LangChain components


### ðŸŽ¯ **How Are Agents Different from Chatbots?**

| Chatbot | Agent |
| --- | --- |
| Just responds to queries | **Performs actions** |
| Canâ€™t use APIs or tools | **Can call tools, APIs, functions** |
| Gives answers | **Finds answers + performs real tasks** |


### ðŸ§  **Two Key Superpowers of Agents**

1. **ðŸ§© Reasoning**: They break problems down into logical steps.
    - Often via *Chain of Thought* prompting.
2. **ðŸ”§ Tool Use**: They can use:
    - ðŸ”¢ Calculator
    - ðŸŒ¦ï¸ Weather API
    - ðŸ” Search
    - ðŸ“… Calendar
    - ðŸ“Š Custom APIs
    - ðŸ’¾ Local Indexes
    - and more...


### ðŸ” **How an Agent Works (Behind-the-Scenes Flow)**

1. User: *â€œMultiply todayâ€™s temperature in Delhi by 3â€*
2. Agent thinks:
    - â€œI need to find Delhiâ€™s temperatureâ€
    - â€œThen multiply it by 3â€
3. Agent uses ðŸ”§ weather tool â†’ gets 25Â°C
4. Agent uses ðŸ”§ calculator tool: 25 Ã— 3 = 75
5. Agent returns: **â€œThe result is 75â€**


### ðŸ’¡ **10 Awesome Real-World Agent Examples**

| ðŸ”¢ # | ðŸŒ Real-World Use Case | ðŸ§  Tools / Steps |
| --- | --- | --- |
| 1ï¸âƒ£ | "Convert todayâ€™s INR to USD" | Currency API + calculator |
| 2ï¸âƒ£ | "Remind me to call mom at 7 PM" | Calendar API |
| 3ï¸âƒ£ | "Summarize this YouTube transcript and email me" | Summarizer + Email API |
| 4ï¸âƒ£ | "Book a cab from home to airport" | Location API + Cab Booking API |
| 5ï¸âƒ£ | "Give me weather in 3 cities and compare them" | Weather tool Ã— 3 + comparison logic |
| 6ï¸âƒ£ | "Tell me the latest stock price of Apple and calculate 5% profit on 10 shares" | Stock API + calculator |
| 7ï¸âƒ£ | "Find top 3 tourist places in Japan and translate to Hindi" | Search + Translator tool |
| 8ï¸âƒ£ | "Fetch leave balance from HR system and show calendar view" | HR API + calendar integration |
| 9ï¸âƒ£ | "Search PDF for 'termination policy' and translate to Marathi" | PDF retriever + translator |
| ðŸ”Ÿ | "Ask a question, retrieve from my docs, and save the result to Notion" | Vector index + Notion API |


### ðŸ”§ **Minimal Code Example: Agent with Tools**

```python
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from langchain.chat_models import ChatOpenAI
from langchain.tools import DuckDuckGoSearchRun, Calculator

# Define Tools
search = DuckDuckGoSearchRun()
calc = Calculator()

tools = [
    Tool(name="Search", func=search.run, description="Useful for web search"),
    Tool(name="Calculator", func=calc.run, description="Useful for math calculations")
]

# Load model
llm = ChatOpenAI(temperature=0)

# Initialize Agent
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# Ask a smart question
agent.run("What's the population of Japan divided by 3?")

```


```python
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from langchain.chat_models import ChatOpenAI
from langchain.tools import DuckDuckGoSearchRun, Calculator

search = DuckDuckGoSearchRun()
calc = Calculator()

llm = ChatOpenAI(temperature=0)

tools = [
    Tool(name="Search", func=search.run, description="Web search"),
    Tool(name="Calculator", func=calc.run, description="Math ops")
]

agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)
```

### ðŸ§© **How Agents Connect to Other Components**

| ðŸ§  Component | ðŸ¤ Role |
| --- | --- |
| **Models** | For reasoning + responses |
| **Prompts** | Guide agent thinking |
| **Chains** | Internal pipelines agent may call |
| **Memory** | Track long conversations or tasks |
| **Indexes** | Retrieve knowledge to reason on |

Agents are the **glue** that orchestrates all the above when needed.


### ðŸ“Œ **Summary**

- ðŸ“¦ **Agents = Intelligent Orchestrators**
- ðŸ” Understand what needs to be done
- ðŸ› ï¸ Use tools and APIs to **act**
- ðŸ”— Leverage all other LangChain components
- ðŸš€ Power behind **real-world, useful LLM apps**

---
---

![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

---
---

# âœ… Commonly Used Built-in Tools in LangChain

These are prebuilt and can be used directly or extended:

### ðŸ“š 1. `WikipediaQueryRun`

- Search and summarize Wikipedia content.

```python
from langchain.tools import WikipediaQueryRun
```

---

### ðŸ” 2. `DuckDuckGoSearchRun`

- Performs web searches using DuckDuckGo.

```python
from langchain.tools import DuckDuckGoSearchRun
```

---

### ðŸ§® 3. `Calculator`

- Evaluates mathematical expressions using Python.

```python
from langchain.tools import Calculator
```

---

### ðŸ“† 4. `LLMMathTool`

- Parses and evaluates math problems with reasoning using the LLM + calculator.

---

### ðŸ“‚ 5. `PythonREPLTool`

- Runs Python code interactively inside a REPL.

```python
from langchain.tools.python.tool import PythonREPLTool
```

---

### ðŸŒ 6. `SerpAPIWrapper`

- Uses the Google Search API (SerpAPI) for rich search queries.

```python
from langchain.tools import SerpAPIWrapper
```

---

### ðŸ’¬ 7. `HumanInputRun`

- Asks for manual input from a human (useful in CLI tools).

---

### ðŸ§¾ 8. `TerminalTool`

- Allows executing real commands in a shell (use cautiously).

---

### ðŸ” 9. `RequestsGetTool`, `RequestsPostTool`

- Send HTTP GET or POST requests.

```python
from langchain.tools.requests.tool import RequestsGetTool
```

---

### ðŸ§  10. `RetrievalQA` or `VectorStoreQATool`

- Allows agents to query a **Vector Store** (e.g., FAISS, Pinecone) via semantic search.

---

## ðŸ§© Custom Tools

You can define **any function as a tool**:

```python
from langchain.tools import tool

@tool
def get_greeting(name: str) -> str:
    return f"Hello, {name}!"
```

Then include it in the `tools` list when initializing an agent.

---

## ðŸ’¡ Specialized Integrations / Tools via LangChain Plugins

LangChain also provides wrappers for:

| Service/API | Tool Type |
| --- | --- |
| Wolfram Alpha | `WolframAlphaQueryRun` |
| Google Search (Serp) | `SerpAPIWrapper` |
| OpenWeatherMap | Custom API + `RequestsGetTool` |
| SQL Databases | `SQLDatabaseToolkit` |
| Python Code Execution | `PythonREPLTool` or `LLMMathTool` |
| Notion API | Custom Tool using SDK |
| Zapier API | `ZapierNLARunAction` |
| File I/O Tools | Read/write files from local system (custom) |

---

## ðŸ”§ How Agent Uses Tools

When you pass tools to the agent:

```python
agent = initialize_agent(
    tools=[search, calc, custom_tool],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

```

LangChain parses the prompt, detects tool requirements, and **automatically selects and invokes tools** in real-time.

---

## ðŸ§  Summary: Categories of Tools

| Category | Tools |
| --- | --- |
| **Math** | `Calculator`, `LLMMathTool`  |
| **Search** | `DuckDuckGoSearchRun`, `SerpAPIWrapper`, `Wikipedia` |
| **Code** | `PythonREPLTool`, `TerminalTool` |
| **Web Requests** | `RequestsGetTool`, `RequestsPostTool`  |
| **Memory / Data** | `VectorStoreQATool`, `RetrievalQA`, `RedisTool`  |
| **APIs** | `Wolfram`, `Notion`, `Zapier`, `OpenWeather`  |
| **Human Input** | `HumanInputRun` |

![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

