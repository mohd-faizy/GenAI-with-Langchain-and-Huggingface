# LangChain Components

![author](https://img.shields.io/badge/author-mohd--faizy-red)

# Langchain components

![image.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/Lang_comp.png)

# ğŸ”¹ **1. Models â€“ The Core of LangChain**

---

### ğŸ“Œ **What Are LangChain Models?**

- ğŸ§  The **Models component** is the **core interface** to interact with AI models (LLMs & Embedding Models).
- ğŸ”„ LangChain is **model-agnostic** â€“ you can switch between different LLM providers with minimal code changes.
- ğŸ› ï¸ Solves the **standardization problem** â€“ every provider (OpenAI, Google, Anthropic, etc.) has different APIs, but LangChain offers one unified interface.

---

### ğŸ“š **Why Are Models Important?**

- âœ… Most important component of LangChain â€“ it's where the AI â€œthinks.â€
- ğŸ¤– Handles both **language generation** (chatbots, agents) and **vector embedding** (search, retrieval).
- ğŸ—ï¸ Acts as a **foundation** for the other 5 components: Prompts, Chains, Memory, Indexes, Agents.

---

### ğŸ” **Challenges Solved by LangChain Models**

1. ğŸ§± **Huge Size** of LLMs (100GB+) â†’ Solved via API access.
2. ğŸ”Œ **Different APIs for Different Providers** â†’ LangChain unifies them.
3. ğŸ” **No Standardized Output/Input Handling** â†’ LangChain parses and handles it uniformly.

---

### ğŸ¤¹â€â™‚ï¸ **Types of Models in LangChain**

1. ğŸ—£ï¸ **Language Models (LLMs)**
    - Input: Text
    - Output: Text
    - Use cases: Chatbots, summarization, translation, coding.
    - Providers: OpenAI, Claude, Hugging Face, Bedrock, Mistral, Vertex AI, Azure OpenAI.
2. ğŸ§­ **Embedding Models**
    - Input: Text
    - Output: Vector (numerical representation)
    - Use case: Semantic Search / Vector DB
    - Providers: OpenAI, Mistral AI, IBM, Llama, etc.

---

### ğŸ§ª **Features Supported Across Models**

- ğŸ§° Tool calling
- ğŸ“¦ JSON / Structured output
- ğŸ§‘â€ğŸ’» Local execution
- ğŸ“¸ Multimodal input (e.g., images + text)

---

## ğŸ’¡ **Code Examples for LangChain Models**

### 1ï¸âƒ£ Load a Chat Model (OpenAI)

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4", temperature=0.7)
response = llm.invoke("What is the capital of France?")
print(response.content)

```

---

### 2ï¸âƒ£ Load a Chat Model (Anthropic Claude)

```python
from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(model="claude-3-opus-20240229")
response = llm.invoke("Explain quantum entanglement in simple terms.")
print(response.content)

```

---

### 3ï¸âƒ£ Load an Embedding Model (OpenAI)

```python
from langchain_openai import OpenAIEmbeddings

embedder = OpenAIEmbeddings()
vector = embedder.embed_query("What is machine learning?")
print(vector[:5])  # Print first 5 values of the vector

```

---

### 4ï¸âƒ£ Switch Between Providers with 1 Line

```python
# Switching from OpenAI to Mistral (Minimal change)
from langchain_mistralai import ChatMistralAI

llm = ChatMistralAI(model="mistral-small")
response = llm.invoke("Summarize the plot of Inception.")
print(response.content)

```

---

### 5ï¸âƒ£ Use Local Language Model (e.g., Llama.cpp or Ollama)

```python
from langchain_community.chat_models import ChatOllama

llm = ChatOllama(model="llama2")
response = llm.invoke("What are black holes?")
print(response.content)

```

---

### 6ï¸âƒ£ Advanced: JSON Output from a Chat Model

```python
llm = ChatOpenAI(model="gpt-4", temperature=0.2)
response = llm.invoke("Return a JSON of 3 countries and their capitals.")

# Ensure the output is structured JSON (using function calling or prompt formatting)
print(response.content)  # Should be a structured response like: {"France": "Paris", ...}

```

---

### âœ… **Summary**

- The **Models component** provides a **standardized, pluggable way** to interact with any LLM or embedding model.
- Enables rapid experimentation and development with **minimal vendor lock-in**.
- Supports both **language tasks (text in â†’ text out)** and **vector embeddings (text in â†’ vector out)**.


---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

# ğŸ”¹**2. Prompts â€“ Crafting the Right Questions for LLMs**

### ğŸ“Œ **What Are Prompts in LangChain?**

- âœï¸ A **prompt** is the **input or instruction** you give to an LLM.
- â— The **quality of the output** depends directly on the **quality of the prompt**.
- ğŸ§  Even small changes in the prompt can **hugely change** the LLMâ€™s response.
- ğŸ§ª Example:
  - "Explain Linear Regression in an academic tone"
  - vs
  - "Explain Linear Regression in a fun tone"

        ğŸ”„ â†’ Two completely different outputs!

### ğŸ“ **Why Are Prompts Important?**

- ğŸ’¥ Prompts are the **most sensitive and influential** part of working with LLMs.
- ğŸ§‘â€ğŸ”¬ The rise of **Prompt Engineering** as a field (and job!) proves how central prompts are.
- ğŸ§© LangChain provides a **Prompts component** to manage, customize, and structure prompts efficiently.

---

### ğŸ§° **What the Prompts Component Offers**

- ğŸ”„ **Dynamic prompts** â€“ insert values at runtime using placeholders.
- ğŸ§‘â€âš–ï¸ **Role-based prompts** â€“ guide the LLM to take on a persona or expertise.
- ğŸ§ª **Few-shot prompts** â€“ train the model by showing it examples of the behavior you expect.
- ğŸ“¦ Reusability â€“ create prompt **templates** you can use again and again in different contexts.

---

## ğŸ§  **Types of Prompts in LangChain**

### 1ï¸âƒ£ Dynamic & Reusable Prompts

- ğŸ”§ Use placeholders like `{topic}` or `{tone}` that get filled dynamically.
- âœ… Example: `"Summarize this {topic} in a {tone} tone."`

### 2ï¸âƒ£ Role-Based Prompts

- ğŸ§‘â€âš•ï¸ Use a system-level prompt like: `"You are an experienced doctor."`
- ğŸ‘¤ Then ask: `"Explain symptoms of viral fever."`

### 3ï¸âƒ£ Few-Shot Prompts

- ğŸ“ Give **input-output examples** to teach the model before the real query.
- ğŸ“Š Example: Show how messages map to categories before asking it to classify a new one.

---

## ğŸ§ª **Code Examples for LangChain Prompts**

### 1ï¸âƒ£ Basic Prompt Template

```python
from langchain.prompts import PromptTemplate

prompt = PromptTemplate.from_template("What is {topic}?")
formatted = prompt.format(topic="Quantum Computing")
print(formatted)

```

---

### 2ï¸âƒ£ Dynamic Multi-Variable Prompt

```python
prompt = PromptTemplate.from_template("Summarize the topic '{topic}' in a {tone} tone.")
print(prompt.format(topic="Climate Change", tone="fun"))

```

---

### 3ï¸âƒ£ Role-Based Prompt with System Message

```python
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template("You are an expert {profession}."),
    HumanMessagePromptTemplate.from_template("Tell me about {topic}.")
])

formatted = prompt.format_messages(profession="architect", topic="modern skyscrapers")
print([msg.content for msg in formatted])

```

---

### 4ï¸âƒ£ Few-Shot Prompt Template

```python
from langchain.prompts import FewShotPromptTemplate

examples = [
    {"message": "I can't log in", "category": "Technical Issue"},
    {"message": "Please update my billing info", "category": "Billing"}
]

example_template = PromptTemplate.from_template("User: {message}\nCategory: {category}\n")
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_template,
    prefix="Classify the user's query:",
    suffix="User: {query}\nCategory:",
    input_variables=["query"]
)

print(few_shot_prompt.format(query="How do I change my credit card info?"))

```

---

### 5ï¸âƒ£ Combine Prompt with Chat Model

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4")
response = llm.invoke(prompt.format(topic="Machine Learning", tone="formal"))
print(response.content)

```

---

### 6ï¸âƒ£ Prompt with Custom Jinja Template (Advanced)

```python
from langchain.prompts import PromptTemplate

template = """You are a {role}.
Answer the question below clearly and professionally.

Question: {question}
"""

prompt = PromptTemplate(template=template, input_variables=["role", "question"])
print(prompt.format(role="data scientist", question="What is overfitting?"))

```

---

### âœ… **Summary**

- The **Prompts component** gives **full control** over how you talk to LLMs.
- Enables **reusable, flexible, and structured** prompt design.
- Makes your apps **more reliable and intelligent** by controlling how LLMs interpret input.
- âœ¨ Essential for building smart, adaptive, and role-aware AI apps.

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

# ğŸ”¹ **3. Chains â€“ Build Smart Pipelines for LLM Workflows**

### ğŸ“Œ **What Are Chains in LangChain?**

- ğŸ”— Chains are used to **link multiple steps** of an LLM app into a **single automated pipeline**.
- ğŸ¤– LangChain is **named after Chains** â€“ thatâ€™s how fundamental they are!
- âš™ï¸ They let you build **sequential**, **parallel**, or **conditional** flows between components like LLMs, tools, and memory.

---

### âš¡ **Why Use Chains?**

- ğŸ”„ Automatically passes the **output of one step as the input** to the next.
- ğŸ§¼ Avoids repetitive manual code to handle data transfer between steps.
- ğŸš€ Lets you design **multi-step AI applications** that work as one smooth pipeline.

---

### ğŸ› ï¸ **Real-World Use Case (Sequential Chain Example)**

### ğŸ” English Text â¡ï¸ Hindi Translation â¡ï¸ Hindi Summary

1. Step 1: Translate English to Hindi (LLM 1)
2. Step 2: Summarize Hindi text (LLM 2)

    âœ… Chains handle this flow without manual intervention â€” just input English text and get the final Hindi summary.

---

### ğŸ” **Types of Chains in LangChain**

### 1ï¸âƒ£ **Sequential Chains**

- Steps run **one after another** in order.
- Example: Translate â†’ Summarize â†’ Format â†’ Output

### 2ï¸âƒ£ **Parallel Chains**

- ğŸ§  Run multiple LLMs **simultaneously** and combine results.
- Example: Same input sent to 3 LLMs to generate different takes â†’ Combine in final report.

### 3ï¸âƒ£ **Conditional Chains**

- ğŸ¤” Branching logic: behavior changes based on input/response.
- Example: If user feedback is negative â†’ Send alert to support; else â†’ Send thank-you note.

---

## ğŸ’» **Code Examples for LangChain Chains**

---

### 1ï¸âƒ£ Basic LLMChain (1-step flow)

```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_openai import OpenAI

llm = OpenAI(model="gpt-3.5-turbo")
prompt = PromptTemplate.from_template("Translate the following English text to Hindi:\n\n{text}")

chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run("I love learning about AI.")
print(result)

```

---

### 2ï¸âƒ£ SequentialChain: Translation â¡ï¸ Summarization

```python
from langchain.chains import SequentialChain

translate_prompt = PromptTemplate.from_template("Translate to Hindi:\n\n{text}")
summary_prompt = PromptTemplate.from_template("Summarize this Hindi text in under 100 words:\n\n{text}")

translate_chain = LLMChain(llm=llm, prompt=translate_prompt, output_key="translated")
summary_chain = LLMChain(llm=llm, prompt=summary_prompt, input_key="translated")

full_chain = SequentialChain(
    chains=[translate_chain, summary_chain],
    input_variables=["text"],
    output_variables=["translated", "text"]
)

result = full_chain.run({"text": "Artificial Intelligence is transforming the world."})
print(result)

```

---

### 3ï¸âƒ£ Simple Conditional Chain (If-Else Logic)

```python
from langchain.chains import TransformChain

def route_feedback(inputs):
    feedback = inputs["feedback"]
    return {"action": "thank user" if "good" in feedback.lower() else "alert support"}

router = TransformChain(input_variables=["feedback"], output_variables=["action"], transform=route_feedback)

result = router.run({"feedback": "The product is not working."})
print(result)

```

---

### 4ï¸âƒ£ Parallel Chain (Mock Conceptual Example)

```python
from langchain.chains import SimpleSequentialChain

prompt1 = PromptTemplate.from_template("Write a poem about {topic}")
prompt2 = PromptTemplate.from_template("Write a joke about {topic}")

chain1 = LLMChain(llm=llm, prompt=prompt1)
chain2 = LLMChain(llm=llm, prompt=prompt2)

# In practice, you could run these chains in parallel using asyncio or LangGraph (experimental)
poem = chain1.run("robots")
joke = chain2.run("robots")

print("Poem:\n", poem)
print("Joke:\n", joke)

```

---

### 5ï¸âƒ£ Chain with Memory Integration (Preview)

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
prompt = PromptTemplate.from_template("You are a chatbot. User said: {input}")

chain = LLMChain(llm=llm, prompt=prompt, memory=memory)
print(chain.run("Hello, how are you?"))
print(chain.run("What did I just say?"))

```

---

### âœ… **Summary**

- ğŸ§© **Chains** simplify **multi-step workflows** in LLM applications.
- ğŸ’¡ They abstract away manual code and let you focus on logic and flow.
- ğŸ§  Types:
  - **Sequential** â€“ one step after another
  - **Parallel** â€“ multiple steps at once
  - **Conditional** â€“ smart branching
- ğŸ“¦ Combine Chains with Prompts, Memory, and Agents for powerful apps.

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

# ğŸ§  **4. Memory â€“ Remembering Past Conversations in LangChain**

### ğŸ“Œ **What Is Memory in LangChain?**

- ğŸ” Most LLMs like GPT are **stateless** â€” they forget everything after each message.
- âŒ If you ask:
  - "Who is Narendra Modi?"
  - Then: "How old is he?"
  - â†’ The model doesnâ€™t remember who *"he"* is.
- ğŸ§  **Memory solves this problem** by maintaining **context across turns** in a conversation.

---

### ğŸš€ **Why Is Memory Important?**

- ğŸ—£ï¸ Makes **chatbots and assistants feel natural and human-like**.
- ğŸ§¾ Keeps track of what users say â€” no need to repeat questions.
- ğŸ¤– Essential for building **stateful AI applications** like customer service bots, AI tutors, assistants, etc.

---

### ğŸ” **Types of Memory in LangChain**

| ğŸ§  Type | ğŸ“‹ Description | ğŸ’¡ Use Case |
| --- | --- | --- |
| **ConversationBufferMemory** | Stores **full chat history** | Best for short conversations |
| **ConversationBufferWindowMemory** | Stores **last N messages** | Great for recent context without overloading |
| **ConversationSummaryMemory** | Stores a **summary of conversation** | Ideal for long chats, saves cost |
| **Custom Memory** | Store **special facts or variables** | Good for personalized assistants |

---

## ğŸ’» **Code Examples for LangChain Memory**

---

### 1ï¸âƒ£ Basic Memory Integration with `LLMChain`

```python
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_openai import OpenAI

llm = OpenAI(model="gpt-3.5-turbo")
memory = ConversationBufferMemory()

prompt = PromptTemplate.from_template("You are a helpful bot. User said: {input}")
chain = LLMChain(llm=llm, prompt=prompt, memory=memory)

# Simulate conversation
print(chain.run("Who is Virat Kohli?"))
print(chain.run("What team does he play for?"))  # Remembers previous message

```

---

### 2ï¸âƒ£ Using `ConversationBufferWindowMemory`

```python
from langchain.memory import ConversationBufferWindowMemory

memory = ConversationBufferWindowMemory(k=2)  # Remembers last 2 interactions

chain = LLMChain(llm=llm, prompt=prompt, memory=memory)
print(chain.run("Explain Machine Learning."))
print(chain.run("Give an example."))
print(chain.run("What did I just say?"))  # Only remembers 2 last messages

```

---

### 3ï¸âƒ£ Using `ConversationSummaryMemory` (with summarization)

```python
from langchain.memory import ConversationSummaryMemory

summary_memory = ConversationSummaryMemory(llm=llm)  # Uses LLM to auto-summarize past chat

chain = LLMChain(llm=llm, prompt=prompt, memory=summary_memory)
print(chain.run("Explain the plot of Inception."))
print(chain.run("Who was the main character?"))  # Will have access to summary, not full text

```

---

### 4ï¸âƒ£ Custom Memory Example (storing variables)

```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
memory.save_context({"input": "My name is Alex"}, {"output": "Nice to meet you, Alex!"})
memory.save_context({"input": "I live in Delhi"}, {"output": "Delhi is a great city."})

# Access stored memory
print(memory.load_memory_variables({}))  # Returns entire conversation history

```

---

### 5ï¸âƒ£ Use Memory with a ChatPromptTemplate

```python
from langchain.prompts import ChatPromptTemplate
from langchain.chains import ConversationChain

chat_prompt = ChatPromptTemplate.from_template("Human: {input}\nAI:")

conversation = ConversationChain(
    llm=llm,
    prompt=chat_prompt,
    memory=ConversationBufferMemory()
)

print(conversation.run("Tell me a joke."))
print(conversation.run("Another one please!"))  # Keeps previous context

```

---

### âœ… **Summary**

- ğŸ§  **Memory makes LangChain apps stateful** â€” just like real conversations.
- ğŸ’¬ It keeps track of what was said earlier and gives the model **context**.
- ğŸ”§ Use different memory types based on your appâ€™s need:
  - Full history (Buffer)
  - Recent messages only (Window)
  - Summarized context (Summary)
- ğŸ§© Combine Memory with Chains, Prompts, and Models to build **real conversational agents**.

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

# ğŸ—‚ï¸ **5. Indexes â€“ Letting LLMs Use Your Private Data**

### ğŸ¤” **Why Do We Need Indexes?**

- ğŸ¤– LLMs like ChatGPT **do not know your private data**.
  - âŒ "Whatâ€™s the leave policy of XYZ company?" â†’ Can't answer.
  - Because it's **not in the training data**.
- âœ… We solve this using **Indexes** in LangChain to:
  - **Connect LLMs to external data** (e.g. PDFs, websites).
  - **Search and retrieve only whatâ€™s needed** from this data.
  - Use it for **answering questions** based on it.

---

### ğŸ§± **The 4 Core Sub-Components of Indexes**

| ğŸ”¢ | ğŸ”§ Component | ğŸ“‹ Role |
| --- | --- | --- |
| 1ï¸âƒ£ | **Document Loader** | Loads your file (PDF, CSV, Notion, Drive, etc.) |
| 2ï¸âƒ£ | **Text Splitter** | Breaks large text into smaller chunks |
| 3ï¸âƒ£ | **Vector Store** | Stores chunk embeddings for similarity search |
| 4ï¸âƒ£ | **Retriever** | Finds the best chunks for a user query |

---

### ğŸ“Š **How It Works (Simplified Flow)**

```
PDF file (RulesBook.pdf)
     â†“
[1] Document Loader âœ Load the document
     â†“
[2] Text Splitter âœ Split into small chunks
     â†“
[3] Vector Store âœ Embed chunks + Store
     â†“
[4] Retriever âœ Semantic search on user query
     â†“
     LLM (answers based on relevant chunks)

```



## ğŸ’» **LangChain Indexes â€“ Code Example**

---

### ğŸ§¾ 1. Load Your PDF Document

```python
from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("XYZ_Company_Policy.pdf")
docs = loader.load()

```

---

### âœ‚ï¸ 2. Split Into Chunks

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(docs)

```

---

### ğŸ§  3. Create Embeddings + Vector Store

```python
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
vector_store = FAISS.from_documents(chunks, embeddings)

```

---

### ğŸ” 4. Setup Retriever and Ask Questions

```python
retriever = vector_store.as_retriever()

query = "What is the official leave policy?"
relevant_docs = retriever.get_relevant_documents(query)

for doc in relevant_docs:
    print(doc.page_content)

```

---

### âœ… Optional: Use with RetrievalQA Chain

```python
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(),
    retriever=retriever
)

print(qa_chain.run("What is the resignation notice period?"))

```

---

## ğŸ§  **Why Indexes Are Crucial**

- ğŸ”“ They unlock the **power of private, local, or custom data**.
- âš™ï¸ They work seamlessly with other components (like Prompts + Chains).
- ğŸ“š Perfect for building:
  - Internal company chatbots
  - Personalized tutors
  - Research assistants
  - FAQ bots on your data

---

## ğŸ” Recap of the 4 Sub-Components

| ğŸ“ DocumentLoader | ğŸ”¢ TextSplitter | ğŸ§  VectorStore | ğŸ•µï¸â€â™‚ï¸ Retriever |
| --- | --- | --- | --- |
| Load files | Split into chunks | Store vectors | Find relevant chunks |

---
![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

# ğŸ¤– **6. Agents â€“ The Smartest, Action-Oriented Component**

### ğŸ’¡ **What Are Agents?**

- Think of Agents as **chatbots with superpowers** âš¡
- They donâ€™t just *respond* â€“ they can **think, decide, and act**
- Agents combine:
  - ğŸ§  Reasoning (`"What should I do first?"`)
  - ğŸ”§ Tool use (`"Let me use a calculator or weather API"`)
  - ğŸ§© Integration with other LangChain components

---

### ğŸ¯ **How Are Agents Different from Chatbots?**

| Chatbot | Agent |
| --- | --- |
| Just responds to queries | **Performs actions** |
| Canâ€™t use APIs or tools | **Can call tools, APIs, functions** |
| Gives answers | **Finds answers + performs real tasks** |

---

### ğŸ§  **Two Key Superpowers of Agents**

1. **ğŸ§© Reasoning**: They break problems down into logical steps.
    - Often via *Chain of Thought* prompting.
2. **ğŸ”§ Tool Use**: They can use:
    - ğŸ”¢ Calculator
    - ğŸŒ¦ï¸ Weather API
    - ğŸ” Search
    - ğŸ“… Calendar
    - ğŸ“Š Custom APIs
    - ğŸ’¾ Local Indexes
    - and more...

---

### ğŸ” **How an Agent Works (Behind-the-Scenes Flow)**

1. User: *â€œMultiply todayâ€™s temperature in Delhi by 3â€*
2. Agent thinks:
    - â€œI need to find Delhiâ€™s temperatureâ€
    - â€œThen multiply it by 3â€
3. Agent uses ğŸ”§ weather tool â†’ gets 25Â°C
4. Agent uses ğŸ”§ calculator tool: 25 Ã— 3 = 75
5. Agent returns: **â€œThe result is 75â€**

---

### ğŸ’¡ **10 Awesome Real-World Agent Examples**

| ğŸ”¢ # | ğŸŒ Real-World Use Case | ğŸ§  Tools / Steps |
| --- | --- | --- |
| 1ï¸âƒ£ | "Convert todayâ€™s INR to USD" | Currency API + calculator |
| 2ï¸âƒ£ | "Remind me to call mom at 7 PM" | Calendar API |
| 3ï¸âƒ£ | "Summarize this YouTube transcript and email me" | Summarizer + Email API |
| 4ï¸âƒ£ | "Book a cab from home to airport" | Location API + Cab Booking API |
| 5ï¸âƒ£ | "Give me weather in 3 cities and compare them" | Weather tool Ã— 3 + comparison logic |
| 6ï¸âƒ£ | "Tell me the latest stock price of Apple and calculate 5% profit on 10 shares" | Stock API + calculator |
| 7ï¸âƒ£ | "Find top 3 tourist places in Japan and translate to Hindi" | Search + Translator tool |
| 8ï¸âƒ£ | "Fetch leave balance from HR system and show calendar view" | HR API + calendar integration |
| 9ï¸âƒ£ | "Search PDF for 'termination policy' and translate to Marathi" | PDF retriever + translator |
| ğŸ”Ÿ | "Ask a question, retrieve from my docs, and save the result to Notion" | Vector index + Notion API |

---

### ğŸ”§ **Minimal Code Example: Agent with Tools**

```python
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from langchain.chat_models import ChatOpenAI
from langchain.tools import DuckDuckGoSearchRun, Calculator

# Define Tools
search = DuckDuckGoSearchRun()
calc = Calculator()

tools = [
    Tool(name="Search", func=search.run, description="Useful for web search"),
    Tool(name="Calculator", func=calc.run, description="Useful for math calculations")
]

# Load model
llm = ChatOpenAI(temperature=0)

# Initialize Agent
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# Ask a smart question
agent.run("What's the population of Japan divided by 3?")

```

---

```python
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from langchain.chat_models import ChatOpenAI
from langchain.tools import DuckDuckGoSearchRun, Calculator

search = DuckDuckGoSearchRun()
calc = Calculator()

llm = ChatOpenAI(temperature=0)

tools = [
    Tool(name="Search", func=search.run, description="Web search"),
    Tool(name="Calculator", func=calc.run, description="Math ops")
]

agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)
```

### ğŸ§© **How Agents Connect to Other Components**

| ğŸ§  Component | ğŸ¤ Role |
| --- | --- |
| **Models** | For reasoning + responses |
| **Prompts** | Guide agent thinking |
| **Chains** | Internal pipelines agent may call |
| **Memory** | Track long conversations or tasks |
| **Indexes** | Retrieve knowledge to reason on |

Agents are the **glue** that orchestrates all the above when needed.

---

### ğŸ“Œ **Summary**

- ğŸ“¦ **Agents = Intelligent Orchestrators**
- ğŸ” Understand what needs to be done
- ğŸ› ï¸ Use tools and APIs to **act**
- ğŸ”— Leverage all other LangChain components
- ğŸš€ Power behind **real-world, useful LLM apps**

---
<center>â­â­â­</center>

---

![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

# âœ… Commonly Used Built-in Tools in LangChain

These are prebuilt and can be used directly or extended:

### ğŸ“š 1. `WikipediaQueryRun`

- Search and summarize Wikipedia content.

```python
from langchain.tools import WikipediaQueryRun
```

---

### ğŸ” 2. `DuckDuckGoSearchRun`

- Performs web searches using DuckDuckGo.

```python
from langchain.tools import DuckDuckGoSearchRun
```

---

### ğŸ§® 3. `Calculator`

- Evaluates mathematical expressions using Python.

```python
from langchain.tools import Calculator
```

---

### ğŸ“† 4. `LLMMathTool`

- Parses and evaluates math problems with reasoning using the LLM + calculator.

---

### ğŸ“‚ 5. `PythonREPLTool`

- Runs Python code interactively inside a REPL.

```python
from langchain.tools.python.tool import PythonREPLTool
```

---

### ğŸŒ 6. `SerpAPIWrapper`

- Uses the Google Search API (SerpAPI) for rich search queries.

```python
from langchain.tools import SerpAPIWrapper
```

---

### ğŸ’¬ 7. `HumanInputRun`

- Asks for manual input from a human (useful in CLI tools).

---

### ğŸ§¾ 8. `TerminalTool`

- Allows executing real commands in a shell (use cautiously).

---

### ğŸ” 9. `RequestsGetTool`, `RequestsPostTool`

- Send HTTP GET or POST requests.

```python
from langchain.tools.requests.tool import RequestsGetTool
```

---

### ğŸ§  10. `RetrievalQA` or `VectorStoreQATool`

- Allows agents to query a **Vector Store** (e.g., FAISS, Pinecone) via semantic search.

---

## ğŸ§© Custom Tools

You can define **any function as a tool**:

```python
from langchain.tools import tool

@tool
def get_greeting(name: str) -> str:
    return f"Hello, {name}!"
```

Then include it in the `tools` list when initializing an agent.

---

## ğŸ’¡ Specialized Integrations / Tools via LangChain Plugins

LangChain also provides wrappers for:

| Service/API | Tool Type |
| --- | --- |
| Wolfram Alpha | `WolframAlphaQueryRun` |
| Google Search (Serp) | `SerpAPIWrapper` |
| OpenWeatherMap | Custom API + `RequestsGetTool` |
| SQL Databases | `SQLDatabaseToolkit` |
| Python Code Execution | `PythonREPLTool` or `LLMMathTool` |
| Notion API | Custom Tool using SDK |
| Zapier API | `ZapierNLARunAction` |
| File I/O Tools | Read/write files from local system (custom) |

---

## ğŸ”§ How Agent Uses Tools

When you pass tools to the agent:

```python
agent = initialize_agent(
    tools=[search, calc, custom_tool],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

```

LangChain parses the prompt, detects tool requirements, and **automatically selects and invokes tools** in real-time.

---

## ğŸ§  Summary: Categories of Tools

| Category | Tools |
| --- | --- |
| **Math** | `Calculator`, `LLMMathTool`  |
| **Search** | `DuckDuckGoSearchRun`, `SerpAPIWrapper`, `Wikipedia` |
| **Code** | `PythonREPLTool`, `TerminalTool` |
| **Web Requests** | `RequestsGetTool`, `RequestsPostTool`  |
| **Memory / Data** | `VectorStoreQATool`, `RetrievalQA`, `RedisTool`  |
| **APIs** | `Wolfram`, `Notion`, `Zapier`, `OpenWeather`  |
| **Human Input** | `HumanInputRun` |

![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)

