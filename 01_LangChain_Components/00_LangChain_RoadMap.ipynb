{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNqIFXrA0aPm"
      },
      "source": [
        "# **ü¶úüîóLangChain RoadMap**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![author](https://img.shields.io/badge/author-mohd--faizy-red)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oFFyEjtJLVY"
      },
      "source": [
        "\n",
        "\n",
        "### **üß© What is LangChain?**\n",
        "\n",
        "* Open-source framework (Python & JS/TS) for building LLM-powered applications‚Äîlike `chatbots`, `RAG` systems, `agents`, and `pipelines`.\n",
        "\n",
        "\n",
        "### **üìÖ Timeline & Major Releases**\n",
        "\n",
        "\n",
        "| üìÖ Date          | ‚öôÔ∏è Release             | üìù Details                                                                                                                                                                                                                                              |\n",
        "| ---------------- | ---------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Oct 2022**     | **Project Launch**     | LangChain was founded by Harrison Chase‚Äîmarking the initial release and growth into a robust LLM application framework                                                                                  |\n",
        "| **May 10, 2024** | **v0.2 Pre‚ÄëRelease**   | Introduced separation of `langchain` & `langchain-community`, versioned docs, mature agent framework (LangGraph), standardized tool calls, improved streaming, and over 30 partner packages                                                             |\n",
        "| **May 20, 2024** | **v0.2 Full Release**  | Finalized documentation refresh with clear structure (tutorials, guides, API), event streaming API, async support, and further LangGraph enhancements                                                                                                   |\n",
        "| **Sep 16, 2024** | **v0.3 (Python & JS)** | Major upgrade: full switch to Pydantic v2 (deprecated v1 in June 2024), dropped Python 3.8 support (end-of-life Oct 2024); JS ecosystem adopted `@langchain/core` as peer dependency, non-blocking callbacks, and deprecated older loaders/entrypoints  |\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FJuUZxyXfLI"
      },
      "source": [
        "## **‚≠ï1. Fundamentals**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSzByRzyEtnO"
      },
      "source": [
        "### **‚≠êa. What is LangChain?**\n",
        "\n",
        "- **LangChain** is an open-source framework designed to simplify the development of **LLM-based applications**. It provides **modular components** and **end-to-end tools** that help developers build complex AI systems such as:\n",
        "\n",
        "    -  ü§ñ `Chatbots`\n",
        "    -  ‚ùì `Question-answering systems`\n",
        "    -  üîç `Retrieval-Augmented Generation (RAG) applications`\n",
        "    -  üß† `Autonomous AI agents`\n",
        "    -  üß∞ `Tool-using agents and more`\n",
        "\n",
        "- üîë **Key Features:**\n",
        "\n",
        "    1. ‚úÖ **Supports all major LLMs** (`OpenAI`, `Anthropic`, `Gemnai`,`Hugging Face`, etc.).\n",
        "    - **Model-agnostic Framework** means LangChain can work with multiplelarge language models (LLMs) like `OpenAI`, `Anthropic`, `HuggingFace`, `gemini`, and more.\n",
        "    2. ‚öôÔ∏è **Simplifies LLM-based app development** through reusablecomponents like `Chains`, `Prompts`, `Memory`, and `Runnables`.\n",
        "    3. üîå **Integrates with key tools** such as `vector stores`, `APIs`,and `databases`.\n",
        "    4. üÜì **Free and open-source**, with active community and continuousupdates\n",
        "    5. üåê **Supports all major GenAI use cases**, making it a versatileframework for developers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da8h19cA9gsF"
      },
      "source": [
        "### **‚≠êb. LangChain Components**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iaybk3R99hOt"
      },
      "source": [
        "- **`Models`**: Interface for LLMs and chat models.\n",
        "- **`Prompts`**: Templates for structured inputs to LLMs.\n",
        "- **`Chains`**: Sequences of calls (models, tools).\n",
        "- **`Indexes`**: This include documents loders, text splitters, vectorstores and retrivers for structured data retrieval.\n",
        "- **`Memory`**: Allow the LLM to maintain a flow in the conversation bykeeping the entire conversation in contex.\n",
        "- **`Agents`**: Leverage LLMs as a reasoning engine to determine whichactions to take."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "922mzd79801G"
      },
      "source": [
        "### **‚≠êc. Models**\n",
        "\n",
        "- LangChain supports multiple LLMs (`OpenAI`, `HuggingFace`, `Cohere`, etc.) via standard interfaces.\n",
        "- You define which model to use and optionally provide `API` keys or configurations.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4e0K7YJ-_O2"
      },
      "source": [
        "### **‚≠êd. Prompts**\n",
        "\n",
        "- Prompts are templates or examples designed to guide LLM responses.  \n",
        "- LangChain uses **PromptTemplates** to standardize and reuse prompts.  \n",
        "- You can include variables and format them at runtime.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VTIHIP5_BbN"
      },
      "source": [
        "### **‚≠êe. Parsing Output**\n",
        "\n",
        "Post-processing is often necessary to convert LLM output into structuredformats. LangChain provides:\n",
        "\n",
        "* **Regex parsers**  \n",
        "* **Pydantic-based output parsers**  \n",
        "* **Structured JSON parsers**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_shBu9zD_EVd"
      },
      "source": [
        "### **‚≠êf. Runnables & LCEL (LangChain Expression Language)**\n",
        "\n",
        "LangChain 0.1+ introduces **Runnables**, a functional abstraction over allLangChain components.  \n",
        "LCEL allows you to compose logic using `|` and `+`, building complex pipelines declaratively.\n",
        "\n",
        "```python\n",
        "chain = prompt | llm | output_parser\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZYhSRxj_GfN"
      },
      "source": [
        "### **‚≠êg. Chains**\n",
        "\n",
        "Chains are sequences of calls that produce a final result. LangChainprovides:\n",
        "\n",
        "* **Simple chains** (e.g., Prompt + LLM)  \n",
        "* **Sequential chains**  \n",
        "* **Custom chains** (your logic)\n",
        "\n",
        "Useful for workflows like:\n",
        "\n",
        "* Input ‚Üí Prompt ‚Üí LLM ‚Üí Output  \n",
        "* Multi-step reasoning tasks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA58QTIi_Ihl"
      },
      "source": [
        "### **‚≠êh. Memory**\n",
        "\n",
        "Memory allows LangChain apps to remember past interactions. Useful in:\n",
        "\n",
        "* Chatbots (session history)  \n",
        "* Agents (tool-use history)  \n",
        "\n",
        "Types include:\n",
        "\n",
        "* **BufferMemory**: Stores raw input/output  \n",
        "* **SummaryMemory**: Stores summarized history  \n",
        "* **TokenBufferMemory**: Limited by token count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWxaAEk4-g2t"
      },
      "source": [
        "## **‚≠ï2. Retrieval-Augmented Generation**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH7Fls58GQRO"
      },
      "source": [
        "### **‚≠êa. Document Loaders**\n",
        "\n",
        "These ingest data from various sources:\n",
        "- Files (`PDF`, `.txt`, `CSV`)  \n",
        "- Web pages (via scraping)  \n",
        "- `APIs` or `databases`  \n",
        "\n",
        "LangChain supports many prebuilt loaders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvAFvefuGV4P"
      },
      "source": [
        "### **‚≠êb. Text Splitters**\n",
        "\n",
        "Large documents need splitting to avoid token limits. Splitters include:\\\n",
        "\n",
        "- **`RecursiveCharacterTextSplitter`**: Preserves structure  \n",
        "- **`TokenTextSplitter`**: Splits by model tokens\n",
        "\n",
        "Custom splitting strategies are also supported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgFU4q9zFtZ-"
      },
      "source": [
        "### **‚≠êc. Embeddings**\n",
        "\n",
        "Embeddings convert text chunks into vector representations for semanticsimilarity. Supported models:\n",
        "-  `OpenAI` Embeddings  \n",
        "-  `HuggingFace` Sentence Transformers  \n",
        "-  `Cohere`, `Google`, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dptueNkMGf22"
      },
      "source": [
        "### **‚≠êd. Vector Stores**\n",
        "\n",
        "Storage solutions for embeddings. They support similarity search(k-NN). Popular vector stores:\n",
        "\n",
        "-  `FAISS (in-memory)`\n",
        "-  `Pinecone`\n",
        "-  `Chroma`\n",
        "-  `Weaviate`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl0xxO10Gh1P"
      },
      "source": [
        "### **‚≠êe. Retrievers**\n",
        "\n",
        "- Interfaces to get relevant chunks from vector stores.  \n",
        "- Can apply filters, scores, and combine retrievers for hybrid search (eg., `BM25` + `vectors`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTJm6OZNGjr3"
      },
      "source": [
        "### **‚≠êf. Building a RAG Application**\n",
        "    \n",
        "Combines:\n",
        "\n",
        "1. Document ingestion (loaders)  \n",
        "2. Chunking (splitters)  \n",
        "3. Embedding + storing (vector store)  \n",
        "4. Query-time retrieval  \n",
        "5. LLM answering using retrieved context  \n",
        "    \n",
        "Use `RetrievalQA` chain or LCEL for more control."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BpZFe-p-kLW"
      },
      "source": [
        "## **‚≠ï3. Agents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4DbCQURG4Oe"
      },
      "source": [
        "### **‚≠êa. Tools & Toolkits**\n",
        "- Tools are functions an agent can call. A tool may be:\n",
        "    - `Web search`  \n",
        "    - `Calculator`  \n",
        "    - `API call`\n",
        "    - `Database query`\n",
        "\n",
        "> Toolkits group related tools (e.g., a SQL toolkit includes a queryexecutor + schema inspector).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JQtEH1bHeRv"
      },
      "source": [
        "### **‚≠êb. Tool Calling**\n",
        "- Agents decide whether and when to use tools via reasoning (viaprompts). LangChain supports:\n",
        "    - OpenAI function calling (tool descriptions)  \n",
        "    - JSON mode (structured calls)  \n",
        "\n",
        "> Agents use intermediate steps (thoughts, actions, observations) toreach answers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp7hZwhcHg2r"
      },
      "source": [
        "### **‚≠êc. Building an AI Agent**\n",
        "\n",
        "**Steps:**\n",
        "1. Define tools  \n",
        "2. Create prompt to guide agent behavior  \n",
        "3. Choose agent type (`zero-shot-react`, `function-calling`, etc.)  \n",
        "4. Initialize with `initialize_agent(...)`\n",
        "\n",
        "- **Agents can:**\n",
        "    - Reason over multiple steps  \n",
        "    - Maintain state (via memory)  \n",
        "    - Decide which tool to use, and how"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb1zL0ObwygP"
      },
      "source": [
        "# **üü¢Example**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULZzr5r5AHge"
      },
      "source": [
        "## **‚≠êPDF-based RAG (Retrieval-Augmented Generation) Pipeline Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l79DKGQ1ALXc"
      },
      "source": [
        "![LC_00_01](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_oth_img/LC_00_01.png)\n",
        "\n",
        "- **PDF Upload**: A PDF is uploaded to `AWS S3`.\n",
        "- **Document Loading**: The file is fetched using a Doc Loader.\n",
        "- **Text Splitting**: The PDF is split into individual pages or chunks.\n",
        "- **Embedding Generation**: Each chunk is converted into embeddings.\n",
        "- **Vector Database**: These embeddings are stored in a vector database.\n",
        "- **User Query**: The user query is also converted into an embedding.\n",
        "- **Semantic Search**: A semantic `similarity` search is performed to find relevant pages/chunks.\n",
        "- **Context Assembly**: Relevant document chunks and the user query are combined into a `system prompt`.\n",
        "- **LLM Processing**: This prompt is sent to an LLM `API` to generate the final answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnNK-yARjMk7"
      },
      "source": [
        "\n",
        "\n",
        "## üîç **LLM Framework Comparison: `LlamaIndex` vs `Haystack` vs `LangChain`**\n",
        "\n",
        "| Feature / Criteria                    | **LlamaIndex**                              | **Haystack**                                          | **LangChain**                                 |                              |\n",
        "| ------------------------------------- | ------------------------------------------- | ----------------------------------------------------- | --------------------------------------------- | ---------------------------- |\n",
        "| **Primary Use Case**                  | Document indexing & RAG pipelines           | Search & QA pipelines (initially Elasticsearch-based) | Modular LLM app building (RAG, agents, tools) |                              |\n",
        "| **Modular Components**                | ‚úÖ Nodes, Indexes, Retrievers, Engines       | ‚úÖ Pipelines, Nodes                                    | ‚úÖ Chains, Runnables, Agents, Memory           |                              |\n",
        "| **Agent Support**                     | ‚ö†Ô∏è Limited (experimental or via plugins)    | ‚ö†Ô∏è Limited / basic (beta-level agent support)         | ‚úÖ Full support (tools, memory, multi-step)    |                              |\n",
        "| **Retrieval-Augmented Generation**    | ‚úÖ Native & optimized                        | ‚úÖ Well-supported                                      | ‚úÖ Fully supported with LCEL & RAG chains      |                              |\n",
        "| **Data Ingestion**                    | ‚úÖ Document loaders & structured data        | ‚úÖ Strong file + database support                      | ‚úÖ Rich set of loaders (via integrations)      |                              |\n",
        "| **Integration with Vector Stores**    | ‚úÖ FAISS, Chroma, Weaviate, Pinecone, etc.   | ‚úÖ FAISS, Milvus, Elasticsearch, etc.                  | ‚úÖ Wide integration with popular stores        |                              |\n",
        "| **Embeddings Support**                | ‚úÖ OpenAI, HuggingFace, Cohere, etc.         | ‚úÖ Wide support via transformers                       | ‚úÖ Full support via plugins + LLM wrappers     |                              |\n",
        "| **Memory Management**                 | ‚ö†Ô∏è Basic context injection                  | ‚ö†Ô∏è Session-based history                              | ‚úÖ Buffer, Summary, TokenBufferMemory types    |                              |\n",
        "| **Tool Use (Calculator, APIs, etc.)** | ‚ùå Not native (needs LangChain-style agents) | ‚ö†Ô∏è Custom node needed                                 | ‚úÖ Native tool use with agents                 |                              |\n",
        "| **Custom Logic Composition**          | ‚úÖ High-level with Composability APIs        | ‚úÖ With custom pipelines                               | ‚úÖ LCEL (\\`                                    | `, `+\\`) + Pythonic chaining |\n",
        "| **Ease of Use**                       | ‚úÖ Simple RAG workflows                      | ‚ö†Ô∏è Moderate (YAML or Python)                          | ‚ö†Ô∏è Moderate‚Äìsteep learning curve              |                              |\n",
        "| **Community & Docs**                  | ‚úÖ Growing, great tutorials                  | ‚úÖ Strong docs, active GitHub                          | ‚úÖ Large community, frequent updates           |                              |\n",
        "| **Language Support**                  | üü° Python-only                              | üü¢ Python (core), some JS/TS & Java work              | üü¢ Python (main), TypeScript JS SDK (beta)    |                              |\n",
        "| **Production Readiness**              | ‚úÖ Stable core with experimental agents      | ‚úÖ Used in enterprise (deployed search apps)           | ‚úÖ Production-ready (widely adopted)           |                              |\n",
        "| **Best For**                          | Fast RAG setup with structured data         | Hybrid QA systems, search with transformers           | Advanced LLM workflows, agents, tool use      |                              |\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ujot2OYjtC5"
      },
      "source": [
        "### **‚úÖ Summary**\n",
        "\n",
        "| Use Case                   | Best Framework |\n",
        "| -------------------------- | -------------- |\n",
        "| Simple, fast RAG setup     | **LlamaIndex** |\n",
        "| Hybrid search pipelines    | **Haystack**   |\n",
        "| Tool-using agents & chains | **LangChain**  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJJnrzUnJsmD"
      },
      "source": [
        "![divider.png](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_img/_langCompIMG/divider.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5FJuUZxyXfLI",
        "LWxaAEk4-g2t",
        "2BpZFe-p-kLW",
        "Cb1zL0ObwygP"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
