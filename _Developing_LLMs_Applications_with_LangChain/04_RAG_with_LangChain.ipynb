{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3626325",
   "metadata": {},
   "source": [
    "# **Retrieval-Augmented Generation (RAG) with LangChain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afdcaa2",
   "metadata": {},
   "source": [
    "## Introduction to RAG\n",
    "\n",
    "### LLM Limitation: Knowledge Constraints\n",
    "Large Language Models (LLMs) are limited by the data they were trained on. They cannot dynamically pull in real-time or external knowledge.\n",
    "\n",
    "### What is Retrieval-Augmented Generation?\n",
    "RAG integrates external data sources with LLMs to overcome this limitation. It retrieves relevant documents or information based on user queries and uses that as context for LLMs to generate responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c00a17c",
   "metadata": {},
   "source": [
    "## Standard RAG Workflow\n",
    "1. **User Query Input**\n",
    "2. **Retriever fetches relevant documents** from vector store\n",
    "3. **Context + Query is passed to the LLM**\n",
    "4. **LLM generates answer** using retrieved context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476397bb",
   "metadata": {},
   "source": [
    "## Preparing Data for Retrieval\n",
    "To use RAG effectively, the documents must be ingested, split into manageable chunks, embedded, and stored in a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d0b0d",
   "metadata": {},
   "source": [
    "## ⭐ Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e233e4",
   "metadata": {},
   "source": [
    "LangChain provides loaders for various file formats.\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    CSVLoader,\n",
    "    JSONLoader,\n",
    "    DirectoryLoader,\n",
    "    PyPDFLoader,\n",
    "    PDFPlumberLoader,\n",
    "    PyMuPDFLoader,\n",
    "    PDFMinerLoader,\n",
    "    WebBaseLoader,\n",
    "    UnstructuredURLLoader,\n",
    "    RecursiveURLLoader,\n",
    "    SitemapLoader,\n",
    "    S3DirectoryLoader,\n",
    "    AzureBlobStorageLoader,\n",
    "    GoogleDriveLoader,\n",
    "    ArxivLoader,\n",
    "    YoutubeAudioLoader,\n",
    "    NotionDirectoryLoader\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14976adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  country: united states\n",
      "confederation: concacaf\n",
      "population_share: 4.5\n",
      "tv_audience_share: 4.3\n",
      "gdp_weighted_share: 11.3 \n",
      "\n",
      "Metadata: {'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\fifa_countries_audience.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "path_to_csv =  r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\fifa_countries_audience.csv\"\n",
    "# Load the CSV file using the CSVLoader\n",
    "\n",
    "csv_loader = CSVLoader(file_path= path_to_csv)\n",
    "documents = csv_loader.load()\n",
    "\n",
    "print(\"Content: \", documents[0].page_content, \"\\n\")\n",
    "print(\"Metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f2c09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  Retrieval Argument Generation: Enhancing Language Model \n",
      " Capabilities Through External Knowledge Integration \n",
      " 1. Introduction to Retrieval Argument Generation (RAG) \n",
      " Retrieval-Augmented Generation (RAG) represents a paradigm shift in how large \n",
      " language models (LLMs) operate, moving beyond the constraints of their pre-trained \n",
      " knowledge by incorporating information from external, authoritative knowledge bases \n",
      " during the response generation process.  1  This  technique fundamentally optimizes the \n",
      " output of LLMs, ensuring that the generated content is not solely reliant on the \n",
      " model's internal parameters but is also grounded in a broader, often more current and \n",
      " specific, set of information.  1  In the realm of natural  language processing (NLP), RAG \n",
      " serves as a powerful tool to enhance text generation by seamlessly integrating data \n",
      " from diverse knowledge repositories, including databases, digital asset libraries, and \n",
      " comprehensive document repositories.  3  This architectural  pattern within generative AI \n",
      " is specifically designed to elevate the accuracy and relevance of LLM responses by \n",
      " dynamically retrieving pertinent external data precisely when a user issues a prompt.  4 \n",
      " At its core, RAG is an advanced artificial intelligence (AI) technique that masterfully \n",
      " combines the strengths of information retrieval and text generation.  5  This synergistic \n",
      " approach empowers AI models to access and retrieve relevant information from a \n",
      " multitude of knowledge sources and subsequently incorporate this retrieved \n",
      " information directly into the text they generate.  5  Functioning  as an AI framework, \n",
      " RAG's primary aim is to ground LLMs on the most accurate and up-to-date \n",
      " information available within an external knowledge base.  7  This not only improves the \n",
      " factual correctness of the generated content but also provides users with valuable \n",
      " insight into the generative process undertaken by the LLM.  7  By modifying the \n",
      " standard interaction with an LLM, RAG ensures that the model's responses are \n",
      " formulated with direct reference to a specified set of documents, effectively \n",
      " supplementing the information gleaned from its initial training data.  8  This capability is \n",
      " particularly significant as it allows LLMs to leverage domain-specific and recently \n",
      " updated information without requiring a complete model retraining.  8  As a technique, \n",
      " RAG is instrumental in enhancing the overall accuracy and reliability of generative AI \n",
      " models by equipping them with the ability to draw upon specific and relevant data \n",
      " sources.  9 \n",
      " From a machine learning perspective, Retrieval Augmented Generation is a \n",
      " sophisticated technique that harmoniously blends retrieval-based methodologies with \n",
      " generative models.  10  Its application is particularly  prominent within Natural Language \n",
      " Processing (NLP), where it serves to significantly enhance the capabilities of large \n",
      "\n",
      "Metadata: {'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "path_to_pdf =  r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\RAG.pdf\"\n",
    "\n",
    "pdf_loader = PyPDFLoader(file_path= path_to_pdf)\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "print(\"Content: \", documents[0].page_content, \"\\n\")\n",
    "print(\"Metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  October 30, 2023\n",
      "\n",
      "Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\n",
      "\n",
      "By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows:\n",
      "\n",
      "Section 1. Purpose. Artificial intelligence (AI) holds extraordinary potential for both promise and peril. Responsible AI use has the potential to help solve urgent challenges while making our world more prosperous, productive, innovative, and secure. At the same time, irresponsible use could exacerbate societal harms such as fraud, discrimination, bias, and disinformation; displace and disempower workers; stifle competition; and pose risks to national security. Harnessing AI for good and realizing its myriad benefits requires mitigating its substantial risks. This endeavor demands a society-wide effort that includes government, the private sector, academia, and civil society.\n",
      "\n",
      "My Administration places the highest urgency on governing the development and use of AI safely and responsibly, and is therefore advancing a coordinated, Federal Government-wide approach to doing so. The rapid speed at which AI capabilities are advancing compels the United States to lead in this moment for the sake of our security, economy, and society.\n",
      "\n",
      "In the end, AI reflects the principles of the people who build it, the people who use it, and the data upon which it is built. I firmly believe that the power of our ideals; the foundations of our society; and the creativity, diversity, and decency of our people are the reasons that America thrived in past eras of rapid change. They are the reasons we will succeed again in this moment. We are more than capable of harnessing AI for justice, security, and opportunity for all.\n",
      "\n",
      "Sec. 2. Policy and Principles. It is the policy of my Administration to advance and govern the development and use of AI in accordance with eight guiding principles and priorities. When undertaking the actions set forth in this order, executive departments and agencies (agencies) shall, as appropriate and consistent with applicable law, adhere to these principles, while, as feasible, taking into account the views of other agencies, industry, members of academia, civil society, labor unions, international allies and partners, and other relevant organizations:\n",
      "\n",
      "(a) Artificial Intelligence must be safe and secure. Meeting this goal requires robust, reliable, repeatable, and standardized evaluations of AI systems, as well as policies, institutions, and, as appropriate, other mechanisms to test, understand, and mitigate risks from these systems before they are put to use. It also requires addressing AI systems’ most pressing security risks — including with respect to biotechnology, cybersecurity, critical infrastructure, and other national security dangers — while navigating AI’s opacity and complexity. Testing and evaluations, including post-deployment performance monitoring, will help ensure that AI systems function as intended, are resilient against misuse or dangerous modifications, are ethically developed and operated in a secure manner, and are compliant with applicable Federal laws and policies. Finally, my Administration will help develop effective labeling and content provenance mechanisms, so that Americans are able to determine when content is generated using AI and when it is not. These actions will provide a vital foundation for an approach that addresses AI’s risks without unduly reducing its benefits.\n",
      "\n",
      "(b) Promoting responsible innovation, competition, and collaboration will allow the United States to lead in AI and unlock the technology’s potential to solve some of society’s most difficult challenges. This effort requires investments in AI-related education, training, development, research, and capacity, while simultaneously tackling novel intellectual property (IP) questions and other problems to protect inventors and creators. Across the Federal Government, my Administration will support programs to provide Americans the skills they need for the age of AI and attract the world’s AI talent to our shores — not just to study, but to stay — so that the companies and technologies of the future are made in America. The Federal Government will promote a fair, open, and competitive ecosystem and marketplace for AI and related technologies so that small developers and entrepreneurs can continue to drive innovation. Doing so requires stopping unlawful collusion and addressing risks from dominant firms’ use of key assets such as semiconductors, computing power, cloud storage, and data to disadvantage competitors, and it requires supporting a marketplace that harnesses the benefits of AI to provide new opportunities for small businesses, workers, and entrepreneurs.\n",
      "\n",
      "(c) The responsible development and use of AI require a commitment to supporting American workers. As AI creates new jobs and industries, all workers need a seat at the table, including through collective bargaining, to ensure that they benefit from these opportunities. My Administration will seek to adapt job training and education to support a diverse workforce and help provide access to opportunities that AI creates. In the workplace itself, AI should not be deployed in ways that undermine rights, worsen job quality, encourage undue worker surveillance, lessen market competition, introduce new health and safety risks, or cause harmful labor-force disruptions. The critical next steps in AI development should be built on the views of workers, labor unions, educators, and employers to support responsible uses of AI that improve workers’ lives, positively augment human work, and help all people safely enjoy the gains and opportunities from technological innovation.\n",
      "\n",
      "(d) Artificial Intelligence policies must be consistent with my Administration’s dedication to advancing equity and civil rights. My Administration cannot — and will not — tolerate the use of AI to disadvantage those who are already too often denied equal opportunity and justice. From hiring to housing to healthcare, we have seen what happens when AI use deepens discrimination and bias, rather than improving quality of life. Artificial Intelligence systems deployed irresponsibly have reproduced and intensified existing inequities, caused new types of harmful discrimination, and exacerbated online and physical harms. My Administration will build on the important steps that have already been taken — such as issuing the Blueprint for an AI Bill of Rights, the AI Risk Management Framework, and Executive Order 14091 of February 16, 2023 (Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government) — in seeking to ensure that AI complies with all Federal laws and to promote robust technical evaluations, careful oversight, engagement with affected communities, and rigorous regulation. It is necessary to hold those developing and deploying AI accountable to standards that protect against unlawful discrimination and abuse, including in the justice system and the Federal Government. Only then can Americans trust AI to advance civil rights, civil liberties, equity, and justice for all.\n",
      "\n",
      "(e) The interests of Americans who increasingly use, interact with, or purchase AI and AI-enabled products in their daily lives must be protected. Use of new technologies, such as AI, does not excuse organizations from their legal obligations, and hard-won consumer protections are more important than ever in moments of technological change. The Federal Government will enforce existing consumer protection laws and principles and enact appropriate safeguards against fraud, unintended bias, discrimination, infringements on privacy, and other harms from AI. Such protections are especially important in critical fields like healthcare, financial services, education, housing, law, and transportation, where mistakes by or misuse of AI could harm patients, cost consumers or small businesses, or jeopardize safety or rights. At the same time, my Administration will promote responsible uses of AI that protect consumers, raise the quality of goods and services, lower their prices, or expand selection and availability.\n",
      "\n",
      "(f) Americans’ privacy and civil liberties must be protected as AI continues advancing. Artificial Intelligence is making it easier to extract, re-identify, link, infer, and act on sensitive information about people’s identities, locations, habits, and desires. Artificial Intelligence’s capabilities in these areas can increase the risk that personal data could be exploited and exposed. To combat this risk, the Federal Government will ensure that the collection, use, and retention of data is lawful, is secure, and mitigates privacy and confidentiality risks. Agencies shall use available policy and technical tools, including privacy-enhancing technologies (PETs) where appropriate, to protect privacy and to combat the broader legal and societal risks — including the chilling of First Amendment rights — that result from the improper collection and use of people’s data.\n",
      "\n",
      "(g) It is important to manage the risks from the Federal Government’s own use of AI and increase its internal capacity to regulate, govern, and support responsible use of AI to deliver better results for Americans. These efforts start with people, our Nation’s greatest asset. My Administration will take steps to attract, retain, and develop public service-oriented AI professionals, including from underserved communities, across disciplines — including technology, policy, managerial, procurement, regulatory, ethical, governance, and legal fields — and ease AI professionals’ path into the Federal Government to help harness and govern AI. The Federal Government will work to ensure that all members of its workforce receive adequate training to understand the benefits, risks, and limitations of AI for their job functions, and to modernize Federal Government information technology infrastructure, remove bureaucratic obstacles, and ensure that safe and rights-respecting AI is adopted, deployed, and used.\n",
      "\n",
      "(h) The Federal Government should lead the way to global societal, economic, and technological progress, as the United States has in previous eras of disruptive innovation and change. This leadership is not measured solely by the technological advancements our country makes. Effective leadership also means pioneering those systems and safeguards needed to deploy technology responsibly — and building and promoting those safeguards with the rest of the world. My Administration will engage with international allies and partners in developing a framework to manage AI’s risks, unlock AI’s potential for good, and promote common approaches to shared challenges. The Federal Government will seek to promote responsible AI safety and security principles and actions with other nations, including our competitors, while leading key global conversations and collaborations to ensure that AI benefits the whole world, rather than exacerbating inequities, threatening human rights, and causing other harms.\n",
      "\n",
      "Sec. 3. Definitions. For purposes of this order:\n",
      "\n",
      "(a) The term “agency” means each agency described in 44 U.S.C. 3502(1), except for the independent regulatory agencies described in 44 U.S.C. 3502(5).\n",
      "\n",
      "(b) The term “artificial intelligence” or “AI” has the meaning set forth in 15 U.S.C. 9401(3): a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action.\n",
      "\n",
      "(c) The term “AI model” means a component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs.\n",
      "\n",
      "(d) The term “AI red-teaming” means a structured testing effort to find flaws and vulnerabilities in an AI system, often in a controlled environment and in collaboration with developers of AI. Artificial Intelligence red-teaming is most often performed by dedicated “red teams” that adopt adversarial methods to identify flaws and vulnerabilities, such as harmful or discriminatory outputs from an AI system, unforeseen or undesirable system behaviors, limitations, or potential risks associated with the misuse of the system.\n",
      "\n",
      "(e) The term “AI system” means any data system, software, hardware, application, tool, or utility that operates in whole or in part using AI.\n",
      "\n",
      "(f) The term “commercially available information” means any information or data about an individual or group of individuals, including an individual’s or group of individuals’ device or location, that is made available or obtainable and sold, leased, or licensed to the general public or to governmental or non-governmental entities.\n",
      "\n",
      "(g) The term “crime forecasting” means the use of analytical techniques to attempt to predict future crimes or crime-related information. It can include machine-generated predictions that use algorithms to analyze large volumes of data, as well as other forecasts that are generated without machines and based on statistics, such as historical crime statistics.\n",
      "\n",
      "(h) The term “critical and emerging technologies” means those technologies listed in the February 2022 Critical and Emerging Technologies List Update issued by the National Science and Technology Council (NSTC), as amended by subsequent updates to the list issued by the NSTC.\n",
      "\n",
      "(i) The term “critical infrastructure” has the meaning set forth in section 1016(e) of the USA PATRIOT Act of 2001, 42 U.S.C. 5195c(e).\n",
      "\n",
      "(j) The term “differential-privacy guarantee” means protections that allow information about a group to be shared while provably limiting the improper access, use, or disclosure of personal information about particular entities.\n",
      "\n",
      "(k) The term “dual-use foundation model” means an AI model that is trained on broad data; generally uses self-supervision; contains at least tens of billions of parameters; is applicable across a wide range of contexts; and that exhibits, or could be easily modified to exhibit, high levels of performance at tasks that pose a serious risk to security, national economic security, national public health or safety, or any combination of those matters, such as by:\n",
      "\n",
      "(i) substantially lowering the barrier of entry for non-experts to design, synthesize, acquire, or use chemical, biological, radiological, or nuclear (CBRN) weapons;\n",
      "\n",
      "(ii) enabling powerful offensive cyber operations through automated vulnerability discovery and exploitation against a wide range of potential targets of cyber attacks; or\n",
      "\n",
      "(iii) permitting the evasion of human control or oversight through means of deception or obfuscation.\n",
      "\n",
      "Models meet this definition even if they are provided to end users with technical safeguards that attempt to prevent users from taking advantage of the relevant unsafe capabilities.\n",
      "\n",
      "(l) The term “Federal law enforcement agency” has the meaning set forth in section 21(a) of Executive Order 14074 of May 25, 2022 (Advancing Effective, Accountable Policing and Criminal Justice Practices To Enhance Public Trust and Public Safety).\n",
      "\n",
      "(m) The term “floating-point operation” means any mathematical operation or assignment involving floating-point numbers, which are a subset of the real numbers typically represented on computers by an integer of fixed precision scaled by an integer exponent of a fixed base.\n",
      "\n",
      "(n) The term “foreign person” has the meaning set forth in section 5(c) of Executive Order 13984 of January 19, 2021 (Taking Additional Steps To Address the National Emergency With Respect to Significant Malicious Cyber-Enabled Activities).\n",
      "\n",
      "(o) The terms “foreign reseller” and “foreign reseller of United States Infrastructure as a Service Products” mean a foreign person who has established an Infrastructure as a Service Account to provide Infrastructure as a Service Products subsequently, in whole or in part, to a third party.\n",
      "\n",
      "(p) The term “generative AI” means the class of AI models that emulate the structure and characteristics of input data in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital content.\n",
      "\n",
      "(q) The terms “Infrastructure as a Service Product,” “United States Infrastructure as a Service Product,” “United States Infrastructure as a Service Provider,” and “Infrastructure as a Service Account” each have the respective meanings given to those terms in section 5 of Executive Order 13984.\n",
      "\n",
      "(r) The term “integer operation” means any mathematical operation or assignment involving only integers, or whole numbers expressed without a decimal point.\n",
      "\n",
      "(s) The term “Intelligence Community” has the meaning given to that term in section 3.5(h) of Executive Order 12333 of December 4, 1981 (United States Intelligence Activities), as amended.\n",
      "\n",
      "(t) The term “machine learning” means a set of techniques that can be used to train AI algorithms to improve performance at a task based on data.\n",
      "\n",
      "(u) The term “model weight” means a numerical parameter within an AI model that helps determine the model’s outputs in response to inputs.\n",
      "\n",
      "(v) The term “national security system” has the meaning set forth in 44 U.S.C. 3552(b)(6).\n",
      "\n",
      "(w) The term “omics” means biomolecules, including nucleic acids, proteins, and metabolites, that make up a cell or cellular system.\n",
      "\n",
      "(x) The term “Open RAN” means the Open Radio Access Network approach to telecommunications-network standardization adopted by the O-RAN Alliance, Third Generation Partnership Project, or any similar set of published open standards for multi-vendor network equipment interoperability.\n",
      "\n",
      "(y) The term “personally identifiable information” has the meaning set forth in Office of Management and Budget (OMB) Circular No. A-130.\n",
      "\n",
      "(z) The term “privacy-enhancing technology” means any software or hardware solution, technical process, technique, or other technological means of mitigating privacy risks arising from data processing, including by enhancing predictability, manageability, disassociability, storage, security, and confidentiality. These technological means may include secure multiparty computation, homomorphic encryption, zero-knowledge proofs, federated learning, secure enclaves, differential privacy, and synthetic-data-generation tools. This is also sometimes referred to as “privacy-preserving technology.”\n",
      "\n",
      "(aa) The term “privacy impact assessment” has the meaning set forth in OMB Circular No. A-130.\n",
      "\n",
      "(bb) The term “Sector Risk Management Agency” has the meaning set forth in 6 U.S.C. 650(23).\n",
      "\n",
      "(cc) The term “self-healing network” means a telecommunications network that automatically diagnoses and addresses network issues to permit self-restoration.\n",
      "\n",
      "(dd) The term “synthetic biology” means a field of science that involves redesigning organisms, or the biomolecules of organisms, at the genetic level to give them new characteristics. Synthetic nucleic acids are a type of biomolecule redesigned through synthetic-biology methods.\n",
      "\n",
      "(ee) The term “synthetic content” means information, such as images, videos, audio clips, and text, that has been significantly modified or generated by algorithms, including by AI.\n",
      "\n",
      "(ff) The term “testbed” means a facility or mechanism equipped for conducting rigorous, transparent, and replicable testing of tools and technologies, including AI and PETs, to help evaluate the functionality, usability, and performance of those tools or technologies.\n",
      "\n",
      "(gg) The term “watermarking” means the act of embedding information, which is typically difficult to remove, into outputs created by AI — including into outputs such as photos, videos, audio clips, or text — for the purposes of verifying the authenticity of the output or the identity or characteristics of its provenance, modifications, or conveyance. Sec. 4. Ensuring the Safety and Security of AI Technology.\n",
      "\n",
      "4.1. Developing Guidelines, Standards, and Best Practices for AI Safety and Security. (a) Within 270 days of the date of this order, to help ensure the development of safe, secure, and trustworthy AI systems, the Secretary of Commerce, acting through the Director of the National Institute of Standards and Technology (NIST), in coordination with the Secretary of Energy, the Secretary of Homeland Security, and the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall:\n",
      "\n",
      "(i) Establish guidelines and best practices, with the aim of promoting consensus industry standards, for developing and deploying safe, secure, and trustworthy AI systems, including:\n",
      "\n",
      "(A) developing a companion resource to the AI Risk Management Framework, NIST AI 100-1, for generative AI;\n",
      "\n",
      "(B) developing a companion resource to the Secure Software Development Framework to incorporate secure development practices for generative AI and for dual-use foundation models; and\n",
      "\n",
      "(C) launching an initiative to create guidance and benchmarks for evaluating and auditing AI capabilities, with a focus on capabilities through which AI could cause harm, such as in the areas of cybersecurity and biosecurity.\n",
      "\n",
      "(ii) Establish appropriate guidelines (except for AI used as a component of a national security system), including appropriate procedures and processes, to enable developers of AI, especially of dual-use foundation models, to conduct AI red-teaming tests to enable deployment of safe, secure, and trustworthy systems. These efforts shall include:\n",
      "\n",
      "(A) coordinating or developing guidelines related to assessing and managing the safety, security, and trustworthiness of dual-use foundation models; and\n",
      "\n",
      "(B) in coordination with the Secretary of Energy and the Director of the National Science Foundation (NSF), developing and helping to ensure the availability of testing environments, such as testbeds, to support the development of safe, secure, and trustworthy AI technologies, as well as to support the design, development, and deployment of associated PETs, consistent with section 9(b) of this order.\n",
      "\n",
      "(b) Within 270 days of the date of this order, to understand and mitigate AI security risks, the Secretary of Energy, in coordination with the heads of other Sector Risk Management Agencies (SRMAs) as the Secretary of Energy may deem appropriate, shall develop and, to the extent permitted by law and available appropriations, implement a plan for developing the Department of Energy’s AI model evaluation tools and AI testbeds. The Secretary shall undertake this work using existing solutions where possible, and shall develop these tools and AI testbeds to be capable of assessing near-term extrapolations of AI systems’ capabilities. At a minimum, the Secretary shall develop tools to evaluate AI capabilities to generate outputs that may represent nuclear, nonproliferation, biological, chemical, critical infrastructure, and energy-security threats or hazards. The Secretary shall do this work solely for the purposes of guarding against these threats, and shall also develop model guardrails that reduce such risks. The Secretary shall, as appropriate, consult with private AI laboratories, academia, civil society, and third-party evaluators, and shall use existing solutions.\n",
      "\n",
      "4.2. Ensuring Safe and Reliable AI. (a) Within 90 days of the date of this order, to ensure and verify the continuous availability of safe, reliable, and effective AI in accordance with the Defense Production Act, as amended, 50 U.S.C. 4501 et seq., including for the national defense and the protection of critical infrastructure, the Secretary of Commerce shall require:\n",
      "\n",
      "(i) Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records regarding the following:\n",
      "\n",
      "(A) any ongoing or planned activities related to training, developing, or producing dual-use foundation models, including the physical and cybersecurity protections taken to assure the integrity of that training process against sophisticated threats;\n",
      "\n",
      "(B) the ownership and possession of the model weights of any dual-use foundation models, and the physical and cybersecurity measures taken to protect those model weights; and\n",
      "\n",
      "(C) the results of any developed dual-use foundation model’s performance in relevant AI red-team testing based on guidance developed by NIST pursuant to subsection 4.1(a)(ii) of this section, and a description of any associated measures the company has taken to meet safety objectives, such as mitigations to improve performance on these red-team tests and strengthen overall model security. Prior to the development of guidance on red-team testing standards by NIST pursuant to subsection 4.1(a)(ii) of this section, this description shall include the results of any red-team testing that the company has conducted relating to lowering the barrier to entry for the development, acquisition, and use of biological weapons by non-state actors; the discovery of software vulnerabilities and development of associated exploits; the use of software or tools to influence real or virtual events; the possibility for self-replication or propagation; and associated measures to meet safety objectives; and\n",
      "\n",
      "(ii) Companies, individuals, or other organizations or entities that acquire, develop, or possess a potential large-scale computing cluster to report any such acquisition, development, or possession, including the existence and location of these clusters and the amount of total computing power available in each cluster.\n",
      "\n",
      "(b) The Secretary of Commerce, in consultation with the Secretary of State, the Secretary of Defense, the Secretary of Energy, and the Director of National Intelligence, shall define, and thereafter update as needed on a regular basis, the set of technical conditions for models and computing clusters that would be subject to the reporting requirements of subsection 4.2(a) of this section. Until such technical conditions are defined, the Secretary shall require compliance with these reporting requirements for:\n",
      "\n",
      "(i) any model that was trained using a quantity of computing power greater than 1026 integer or floating-point operations, or using primarily biological sequence data and using a quantity of computing power greater than 1023 integer or floating-point operations; and\n",
      "\n",
      "(ii) any computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum computing capacity of 1020 integer or floating-point operations per second for training AI.\n",
      "\n",
      "(c) Because I find that additional steps must be taken to deal with the national emergency related to significant malicious cyber-enabled activities declared in Executive Order 13694 of April 1, 2015 (Blocking the Property of Certain Persons Engaging in Significant Malicious Cyber-Enabled Activities), as amended by Executive Order 13757 of December 28, 2016 (Taking Additional Steps to Address the National Emergency With Respect to Significant Malicious Cyber-Enabled Activities), and further amended by Executive Order 13984, to address the use of United States Infrastructure as a Service (IaaS) Products by foreign malicious cyber actors, including to impose additional record-keeping obligations with respect to foreign transactions and to assist in the investigation of transactions involving foreign malicious cyber actors, I hereby direct the Secretary of Commerce, within 90 days of the date of this order, to:\n",
      "\n",
      "(i) Propose regulations that require United States IaaS Providers to submit a report to the Secretary of Commerce when a foreign person transacts with that United States IaaS Provider to train a large AI model with potential capabilities that could be used in malicious cyber-enabled activity (a “training run”). Such reports shall include, at a minimum, the identity of the foreign person and the existence of any training run of an AI model meeting the criteria set forth in this section, or other criteria defined by the Secretary in regulations, as well as any additional information identified by the Secretary.\n",
      "\n",
      "(ii) Include a requirement in the regulations proposed pursuant to subsection 4.2(c)(i) of this section that United States IaaS Providers prohibit any foreign reseller of their United States IaaS Product from providing those products unless such foreign reseller submits to the United States IaaS Provider a report, which the United States IaaS Provider must provide to the Secretary of Commerce, detailing each instance in which a foreign person transacts with the foreign reseller to use the United States IaaS Product to conduct a training run described in subsection 4.2(c)(i) of this section. Such reports shall include, at a minimum, the information specified in subsection 4.2(c)(i) of this section as well as any additional information identified by the Secretary.\n",
      "\n",
      "(iii) Determine the set of technical conditions for a large AI model to have potential capabilities that could be used in malicious cyber-enabled activity, and revise that determination as necessary and appropriate. Until the Secretary makes such a determination, a model shall be considered to have potential capabilities that could be used in malicious cyber-enabled activity if it requires a quantity of computing power greater than 1026 integer or floating-point operations and is trained on a computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum compute capacity of 1020 integer or floating-point operations per second for training AI.\n",
      "\n",
      "(d) Within 180 days of the date of this order, pursuant to the finding set forth in subsection 4.2(c) of this section, the Secretary of Commerce shall propose regulations that require United States IaaS Providers to ensure that foreign resellers of United States IaaS Products verify the identity of any foreign person that obtains an IaaS account (account) from the foreign reseller. These regulations shall, at a minimum:\n",
      "\n",
      "(i) Set forth the minimum standards that a United States IaaS Provider must require of foreign resellers of its United States IaaS Products to verify the identity of a foreign person who opens an account or maintains an existing account with a foreign reseller, including:\n",
      "\n",
      "(A) the types of documentation and procedures that foreign resellers of United States IaaS Products must require to verify the identity of any foreign person acting as a lessee or sub-lessee of these products or services;\n",
      "\n",
      "(B) records that foreign resellers of United States IaaS Products must securely maintain regarding a foreign person that obtains an account, including information establishing:\n",
      "\n",
      "(1) the identity of such foreign person, including name and address;\n",
      "\n",
      "(2) the means and source of payment (including any associated financial institution and other identifiers such as credit card number, account number, customer identifier, transaction identifiers, or virtual currency wallet or wallet address identifier);\n",
      "\n",
      "(3) the electronic mail address and telephonic contact information used to verify a foreign person’s identity; and\n",
      "\n",
      "(4) the Internet Protocol addresses used for access or administration and the date and time of each such access or administrative action related to ongoing verification of such foreign person’s ownership of such an account; and\n",
      "\n",
      "(C) methods that foreign resellers of United States IaaS Products must implement to limit all third-party access to the information described in this subsection, except insofar as such access is otherwise consistent with this order and allowed under applicable law;\n",
      "\n",
      "(ii) Take into consideration the types of accounts maintained by foreign resellers of United States IaaS Products, methods of opening an account, and types of identifying information available to accomplish the objectives of identifying foreign malicious cyber actors using any such products and avoiding the imposition of an undue burden on such resellers; and\n",
      "\n",
      "(iii) Provide that the Secretary of Commerce, in accordance with such standards and procedures as the Secretary may delineate and in consultation with the Secretary of Defense, the Attorney General, the Secretary of Homeland Security, and the Director of National Intelligence, may exempt a United States IaaS Provider with respect to any specific foreign reseller of their United States IaaS Products, or with respect to any specific type of account or lessee, from the requirements of any regulation issued pursuant to this subsection. Such standards and procedures may include a finding by the Secretary that such foreign reseller, account, or lessee complies with security best practices to otherwise deter abuse of United States IaaS Products.\n",
      "\n",
      "(e) The Secretary of Commerce is hereby authorized to take such actions, including the promulgation of rules and regulations, and to employ all powers granted to the President by the International Emergency Economic Powers Act, 50 U.S.C. 1701 et seq., as may be necessary to carry out the purposes of subsections 4.2(c) and (d) of this section. Such actions may include a requirement that United States IaaS Providers require foreign resellers of United States IaaS Products to provide United States IaaS Providers verifications relative to those subsections.\n",
      "\n",
      "4.3. Managing AI in Critical Infrastructure and in Cybersecurity. (a) To ensure the protection of critical infrastructure, the following actions shall be taken:\n",
      "\n",
      "(i) Within 90 days of the date of this order, and at least annually thereafter, the head of each agency with relevant regulatory authority over critical infrastructure and the heads of relevant SRMAs, in coordination with the Director of the Cybersecurity and Infrastructure Security Agency within the Department of Homeland Security for consideration of cross-sector risks, shall evaluate and provide to the Secretary of Homeland Security an assessment of potential risks related to the use of AI in critical infrastructure sectors involved, including ways in which deploying AI may make critical infrastructure systems more vulnerable to critical failures, physical attacks, and cyber attacks, and shall consider ways to mitigate these vulnerabilities. Independent regulatory agencies are encouraged, as they deem appropriate, to contribute to sector-specific risk assessments.\n",
      "\n",
      "(ii) Within 150 days of the date of this order, the Secretary of the Treasury shall issue a public report on best practices for financial institutions to manage AI-specific cybersecurity risks.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Secretary of Homeland Security, in coordination with the Secretary of Commerce and with SRMAs and other regulators as determined by the Secretary of Homeland Security, shall incorporate as appropriate the AI Risk Management Framework, NIST AI 100-1, as well as other appropriate security guidance, into relevant safety and security guidelines for use by critical infrastructure owners and operators.\n",
      "\n",
      "(iv) Within 240 days of the completion of the guidelines described in subsection 4.3(a)(iii) of this section, the Assistant to the President for National Security Affairs and the Director of OMB, in consultation with the Secretary of Homeland Security, shall coordinate work by the heads of agencies with authority over critical infrastructure to develop and take steps for the Federal Government to mandate such guidelines, or appropriate portions thereof, through regulatory or other appropriate action. Independent regulatory agencies are encouraged, as they deem appropriate, to consider whether to mandate guidance through regulatory action in their areas of authority and responsibility.\n",
      "\n",
      "(v) The Secretary of Homeland Security shall establish an Artificial Intelligence Safety and Security Board as an advisory committee pursuant to section 871 of the Homeland Security Act of 2002 (Public Law 107-296). The Advisory Committee shall include AI experts from the private sector, academia, and government, as appropriate, and provide to the Secretary of Homeland Security and the Federal Government’s critical infrastructure community advice, information, or recommendations for improving security, resilience, and incident response related to AI usage in critical infrastructure.\n",
      "\n",
      "(b) To capitalize on AI’s potential to improve United States cyber defenses:\n",
      "\n",
      "(i) The Secretary of Defense shall carry out the actions described in subsections 4.3(b)(ii) and (iii) of this section for national security systems, and the Secretary of Homeland Security shall carry out these actions for non-national security systems. Each shall do so in consultation with the heads of other relevant agencies as the Secretary of Defense and the Secretary of Homeland Security may deem appropriate.\n",
      "\n",
      "(ii) As set forth in subsection 4.3(b)(i) of this section, within 180 days of the date of this order, the Secretary of Defense and the Secretary of Homeland Security shall, consistent with applicable law, each develop plans for, conduct, and complete an operational pilot project to identify, develop, test, evaluate, and deploy AI capabilities, such as large-language models, to aid in the discovery and remediation of vulnerabilities in critical United States Government software, systems, and networks.\n",
      "\n",
      "(iii) As set forth in subsection 4.3(b)(i) of this section, within 270 days of the date of this order, the Secretary of Defense and the Secretary of Homeland Security shall each provide a report to the Assistant to the President for National Security Affairs on the results of actions taken pursuant to the plans and operational pilot projects required by subsection 4.3(b)(ii) of this section, including a description of any vulnerabilities found and fixed through the development and deployment of AI capabilities and any lessons learned on how to identify, develop, test, evaluate, and deploy AI capabilities effectively for cyber defense.\n",
      "\n",
      "4.4. Reducing Risks at the Intersection of AI and CBRN Threats. (a) To better understand and mitigate the risk of AI being misused to assist in the development or use of CBRN threats — with a particular focus on biological weapons — the following actions shall be taken:\n",
      "\n",
      "(i) Within 180 days of the date of this order, the Secretary of Homeland Security, in consultation with the Secretary of Energy and the Director of the Office of Science and Technology Policy (OSTP), shall evaluate the potential for AI to be misused to enable the development or production of CBRN threats, while also considering the benefits and application of AI to counter these threats, including, as appropriate, the results of work conducted under section 8(b) of this order. The Secretary of Homeland Security shall:\n",
      "\n",
      "(A) consult with experts in AI and CBRN issues from the Department of Energy, private AI laboratories, academia, and third-party model evaluators, as appropriate, to evaluate AI model capabilities to present CBRN threats — for the sole purpose of guarding against those threats — as well as options for minimizing the risks of AI model misuse to generate or exacerbate those threats; and\n",
      "\n",
      "(B) submit a report to the President that describes the progress of these efforts, including an assessment of the types of AI models that may present CBRN risks to the United States, and that makes recommendations for regulating or overseeing the training, deployment, publication, or use of these models, including requirements for safety evaluations and guardrails for mitigating potential threats to national security.\n",
      "\n",
      "(ii) Within 120 days of the date of this order, the Secretary of Defense, in consultation with the Assistant to the President for National Security Affairs and the Director of OSTP, shall enter into a contract with the National Academies of Sciences, Engineering, and Medicine to conduct — and submit to the Secretary of Defense, the Assistant to the President for National Security Affairs, the Director of the Office of Pandemic Preparedness and Response Policy, the Director of OSTP, and the Chair of the Chief Data Officer Council — a study that:\n",
      "\n",
      "(A) assesses the ways in which AI can increase biosecurity risks, including risks from generative AI models trained on biological data, and makes recommendations on how to mitigate these risks;\n",
      "\n",
      "(B) considers the national security implications of the use of data and datasets, especially those associated with pathogens and omics studies, that the United States Government hosts, generates, funds the creation of, or otherwise owns, for the training of generative AI models, and makes recommendations on how to mitigate the risks related to the use of these data and datasets;\n",
      "\n",
      "(C) assesses the ways in which AI applied to biology can be used to reduce biosecurity risks, including recommendations on opportunities to coordinate data and high-performance computing resources; and\n",
      "\n",
      "(D) considers additional concerns and opportunities at the intersection of AI and synthetic biology that the Secretary of Defense deems appropriate.\n",
      "\n",
      "(b) To reduce the risk of misuse of synthetic nucleic acids, which could be substantially increased by AI’s capabilities in this area, and improve biosecurity measures for the nucleic acid synthesis industry, the following actions shall be taken:\n",
      "\n",
      "(i) Within 180 days of the date of this order, the Director of OSTP, in consultation with the Secretary of State, the Secretary of Defense, the Attorney General, the Secretary of Commerce, the Secretary of Health and Human Services (HHS), the Secretary of Energy, the Secretary of Homeland Security, the Director of National Intelligence, and the heads of other relevant agencies as the Director of OSTP may deem appropriate, shall establish a framework, incorporating, as appropriate, existing United States Government guidance, to encourage providers of synthetic nucleic acid sequences to implement comprehensive, scalable, and verifiable synthetic nucleic acid procurement screening mechanisms, including standards and recommended incentives. As part of this framework, the Director of OSTP shall:\n",
      "\n",
      "(A) establish criteria and mechanisms for ongoing identification of biological sequences that could be used in a manner that would pose a risk to the national security of the United States; and\n",
      "\n",
      "(B) determine standardized methodologies and tools for conducting and verifying the performance of sequence synthesis procurement screening, including customer screening approaches to support due diligence with respect to managing security risks posed by purchasers of biological sequences identified in subsection 4.4(b)(i)(A) of this section, and processes for the reporting of concerning activity to enforcement entities.\n",
      "\n",
      "(ii) Within 180 days of the date of this order, the Secretary of Commerce, acting through the Director of NIST, in coordination with the Director of OSTP, and in consultation with the Secretary of State, the Secretary of HHS, and the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall initiate an effort to engage with industry and relevant stakeholders, informed by the framework developed under subsection 4.4(b)(i) of this section, to develop and refine for possible use by synthetic nucleic acid sequence providers:\n",
      "\n",
      "(A) specifications for effective nucleic acid synthesis procurement screening;\n",
      "\n",
      "(B) best practices, including security and access controls, for managing sequence-of-concern databases to support such screening;\n",
      "\n",
      "(C) technical implementation guides for effective screening; and\n",
      "\n",
      "(D) conformity-assessment best practices and mechanisms.\n",
      "\n",
      "(iii) Within 180 days of the establishment of the framework pursuant to subsection 4.4(b)(i) of this section, all agencies that fund life-sciences research shall, as appropriate and consistent with applicable law, establish that, as a requirement of funding, synthetic nucleic acid procurement is conducted through providers or manufacturers that adhere to the framework, such as through an attestation from the provider or manufacturer. The Assistant to the President for National Security Affairs and the Director of OSTP shall coordinate the process of reviewing such funding requirements to facilitate consistency in implementation of the framework across funding agencies.\n",
      "\n",
      "(iv) In order to facilitate effective implementation of the measures described in subsections 4.4(b)(i)-(iii) of this section, the Secretary of Homeland Security, in consultation with the heads of other relevant agencies as the Secretary of Homeland Security may deem appropriate, shall:\n",
      "\n",
      "(A) within 180 days of the establishment of the framework pursuant to subsection 4.4(b)(i) of this section, develop a framework to conduct structured evaluation and stress testing of nucleic acid synthesis procurement screening, including the systems developed in accordance with subsections 4.4(b)(i)-(ii) of this section and implemented by providers of synthetic nucleic acid sequences; and\n",
      "\n",
      "(B) following development of the framework pursuant to subsection 4.4(b)(iv)(A) of this section, submit an annual report to the Assistant to the President for National Security Affairs, the Director of the Office of Pandemic Preparedness and Response Policy, and the Director of OSTP on any results of the activities conducted pursuant to subsection 4.4(b)(iv)(A) of this section, including recommendations, if any, on how to strengthen nucleic acid synthesis procurement screening, including customer screening systems.\n",
      "\n",
      "4.5. Reducing the Risks Posed by Synthetic Content.\n",
      "\n",
      "To foster capabilities for identifying and labeling synthetic content produced by AI systems, and to establish the authenticity and provenance of digital content, both synthetic and not synthetic, produced by the Federal Government or on its behalf: (a) Within 240 days of the date of this order, the Secretary of Commerce, in consultation with the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall submit a report to the Director of OMB and the Assistant to the President for National Security Affairs identifying the existing standards, tools, methods, and practices, as well as the potential development of further science-backed standards and techniques, for:\n",
      "\n",
      "(i) authenticating content and tracking its provenance;\n",
      "\n",
      "(ii) labeling synthetic content, such as using watermarking;\n",
      "\n",
      "(iii) detecting synthetic content;\n",
      "\n",
      "(iv) preventing generative AI from producing child sexual abuse material or producing non-consensual intimate imagery of real individuals (to include intimate digital depictions of the body or body parts of an identifiable individual);\n",
      "\n",
      "(v) testing software used for the above purposes; and\n",
      "\n",
      "(vi) auditing and maintaining synthetic content. (b) Within 180 days of submitting the report required under subsection 4.5(a) of this section, and updated periodically thereafter, the Secretary of Commerce, in coordination with the Director of OMB, shall develop guidance regarding the existing tools and practices for digital content authentication and synthetic content detection measures. The guidance shall include measures for the purposes listed in subsection 4.5(a) of this section. (c) Within 180 days of the development of the guidance required under subsection 4.5(b) of this section, and updated periodically thereafter, the Director of OMB, in consultation with the Secretary of State; the Secretary of Defense; the Attorney General; the Secretary of Commerce, acting through the Director of NIST; the Secretary of Homeland Security; the Director of National Intelligence; and the heads of other agencies that the Director of OMB deems appropriate, shall — for the purpose of strengthening public confidence in the integrity of official United States Government digital content — issue guidance to agencies for labeling and authenticating such content that they produce or publish. (d) The Federal Acquisition Regulatory Council shall, as appropriate and consistent with applicable law, consider amending the Federal Acquisition Regulation to take into account the guidance established under subsection 4.5 of this section.\n",
      "\n",
      "4.6. Soliciting Input on Dual-Use Foundation Models with Widely Available Model Weights. When the weights for a dual-use foundation model are widely available — such as when they are publicly posted on the Internet — there can be substantial benefits to innovation, but also substantial security risks, such as the removal of safeguards within the model. To address the risks and potential benefits of dual-use foundation models with widely available weights, within 270 days of the date of this order, the Secretary of Commerce, acting through the Assistant Secretary of Commerce for Communications and Information, and in consultation with the Secretary of State, shall: (a) solicit input from the private sector, academia, civil society, and other stakeholders through a public consultation process on potential risks, benefits, other implications, and appropriate policy and regulatory approaches related to dual-use foundation models for which the model weights are widely available, including:\n",
      "\n",
      "(i) risks associated with actors fine-tuning dual-use foundation models for which the model weights are widely available or removing those models’ safeguards;\n",
      "\n",
      "(ii) benefits to AI innovation and research, including research into AI safety and risk management, of dual-use foundation models for which the model weights are widely available; and\n",
      "\n",
      "(iii) potential voluntary, regulatory, and international mechanisms to manage the risks and maximize the benefits of dual-use foundation models for which the model weights are widely available; and (b) based on input from the process described in subsection 4.6(a) of this section, and in consultation with the heads of other relevant agencies as the Secretary of Commerce deems appropriate, submit a report to the President on the potential benefits, risks, and implications of dual-use foundation models for which the model weights are widely available, as well as policy and regulatory recommendations pertaining to those models.\n",
      "\n",
      "4.7. Promoting Safe Release and Preventing the Malicious Use of Federal Data for AI Training.To improve public data access and manage security risks, and consistent with the objectives of the Open, Public, Electronic, and Necessary Government Data Act (title II of Public Law 115-435) to expand public access to Federal data assets in a machine-readable format while also taking into account security considerations, including the risk that information in an individual data asset in isolation does not pose a security risk but, when combined with other available information, may pose such a risk: (a) within 270 days of the date of this order, the Chief Data Officer Council, in consultation with the Secretary of Defense, the Secretary of Commerce, the Secretary of Energy, the Secretary of Homeland Security, and the Director of National Intelligence, shall develop initial guidelines for performing security reviews, including reviews to identify and manage the potential security risks of releasing Federal data that could aid in the development of CBRN weapons as well as the development of autonomous offensive cyber capabilities, while also providing public access to Federal Government data in line with the goals stated in the Open, Public, Electronic, and Necessary Government Data Act (title II of Public Law 115-435); and\n",
      "\n",
      "(b) within 180 days of the development of the initial guidelines required by subsection 4.7(a) of this section, agencies shall conduct a security review of all data assets in the comprehensive data inventory required under 44 U.S.C. 3511(a)(1) and (2)(B) and shall take steps, as appropriate and consistent with applicable law, to address the highest-priority potential security risks that releasing that data could raise with respect to CBRN weapons, such as the ways in which that data could be used to train AI systems.\n",
      "\n",
      "4.8. Directing the Development of a National Security Memorandum. To develop a coordinated executive branch approach to managing AI’s security risks, the Assistant to the President for National Security Affairs and the Assistant to the President and Deputy Chief of Staff for Policy shall oversee an interagency process with the purpose of, within 270 days of the date of this order, developing and submitting a proposed National Security Memorandum on AI to the President. The memorandum shall address the governance of AI used as a component of a national security system or for military and intelligence purposes. The memorandum shall take into account current efforts to govern the development and use of AI for national security systems. The memorandum shall outline actions for the Department of Defense, the Department of State, other relevant agencies, and the Intelligence Community to address the national security risks and potential benefits posed by AI. In particular, the memorandum shall:\n",
      "\n",
      "(a) provide guidance to the Department of Defense, other relevant agencies, and the Intelligence Community on the continued adoption of AI capabilities to advance the United States national security mission, including through directing specific AI assurance and risk-management practices for national security uses of AI that may affect the rights or safety of United States persons and, in appropriate contexts, non-United States persons; and\n",
      "\n",
      "(b) direct continued actions, as appropriate and consistent with applicable law, to address the potential use of AI systems by adversaries and other foreign actors in ways that threaten the capabilities or objectives of the Department of Defense or the Intelligence Community, or that otherwise pose risks to the security of the United States or its allies and partners.\n",
      "\n",
      "Sec. 5. Promoting Innovation and Competition.\n",
      "\n",
      "5.1. Attracting AI Talent to the United States. (a) Within 90 days of the date of this order, to attract and retain talent in AI and other critical and emerging technologies in the United States economy, the Secretary of State and the Secretary of Homeland Security shall take appropriate steps to:\n",
      "\n",
      "(i) streamline processing times of visa petitions and applications, including by ensuring timely availability of visa appointments, for noncitizens who seek to travel to the United States to work on, study, or conduct research in AI or other critical and emerging technologies; and\n",
      "\n",
      "(ii) facilitate continued availability of visa appointments in sufficient volume for applicants with expertise in AI or other critical and emerging technologies.\n",
      "\n",
      "(b) Within 120 days of the date of this order, the Secretary of State shall:\n",
      "\n",
      "(i) consider initiating a rulemaking to establish new criteria to designate countries and skills on the Department of State’s Exchange Visitor Skills List as it relates to the 2-year foreign residence requirement for certain J-1 nonimmigrants, including those skills that are critical to the United States;\n",
      "\n",
      "(ii) consider publishing updates to the 2009 Revised Exchange Visitor Skills List (74 FR 20108); and\n",
      "\n",
      "(iii) consider implementing a domestic visa renewal program under 22 C.F.R. 41.111(b) to facilitate the ability of qualified applicants, including highly skilled talent in AI and critical and emerging technologies, to continue their work in the United States without unnecessary interruption.\n",
      "\n",
      "(c) Within 180 days of the date of this order, the Secretary of State shall:\n",
      "\n",
      "(i) consider initiating a rulemaking to expand the categories of nonimmigrants who qualify for the domestic visa renewal program covered under 22 C.F.R. 41.111(b) to include academic J-1 research scholars and F-1 students in science, technology, engineering, and mathematics (STEM); and\n",
      "\n",
      "(ii) establish, to the extent permitted by law and available appropriations, a program to identify and attract top talent in AI and other critical and emerging technologies at universities, research institutions, and the private sector overseas, and to establish and increase connections with that talent to educate them on opportunities and resources for research and employment in the United States, including overseas educational components to inform top STEM talent of nonimmigrant and immigrant visa options and potential expedited adjudication of their visa petitions and applications.\n",
      "\n",
      "(d) Within 180 days of the date of this order, the Secretary of Homeland Security shall:\n",
      "\n",
      "(i) review and initiate any policy changes the Secretary determines necessary and appropriate to clarify and modernize immigration pathways for experts in AI and other critical and emerging technologies, including O-1A and EB-1 noncitizens of extraordinary ability; EB-2 advanced-degree holders and noncitizens of exceptional ability; and startup founders in AI and other critical and emerging technologies using the International Entrepreneur Rule; and\n",
      "\n",
      "(ii) continue its rulemaking process to modernize the H-1B program and enhance its integrity and usage, including by experts in AI and other critical and emerging technologies, and consider initiating a rulemaking to enhance the process for noncitizens, including experts in AI and other critical and emerging technologies and their spouses, dependents, and children, to adjust their status to lawful permanent resident.\n",
      "\n",
      "(e) Within 45 days of the date of this order, for purposes of considering updates to the “Schedule A” list of occupations, 20 C.F.R. 656.5, the Secretary of Labor shall publish a request for information (RFI) to solicit public input, including from industry and worker-advocate communities, identifying AI and other STEM-related occupations, as well as additional occupations across the economy, for which there is an insufficient number of ready, willing, able, and qualified United States workers.\n",
      "\n",
      "(f) The Secretary of State and the Secretary of Homeland Security shall, consistent with applicable law and implementing regulations, use their discretionary authorities to support and attract foreign nationals with special skills in AI and other critical and emerging technologies seeking to work, study, or conduct research in the United States.\n",
      "\n",
      "(g) Within 120 days of the date of this order, the Secretary of Homeland Security, in consultation with the Secretary of State, the Secretary of Commerce, and the Director of OSTP, shall develop and publish informational resources to better attract and retain experts in AI and other critical and emerging technologies, including:\n",
      "\n",
      "(i) a clear and comprehensive guide for experts in AI and other critical and emerging technologies to understand their options for working in the United States, to be published in multiple relevant languages on AI.gov; and\n",
      "\n",
      "(ii) a public report with relevant data on applications, petitions, approvals, and other key indicators of how experts in AI and other critical and emerging technologies have utilized the immigration system through the end of Fiscal Year 2023.\n",
      "\n",
      "5.2. Promoting Innovation. (a) To develop and strengthen public-private partnerships for advancing innovation, commercialization, and risk-mitigation methods for AI, and to help promote safe, responsible, fair, privacy-protecting, and trustworthy AI systems, the Director of NSF shall take the following steps:\n",
      "\n",
      "(i) Within 90 days of the date of this order, in coordination with the heads of agencies that the Director of NSF deems appropriate, launch a pilot program implementing the National AI Research Resource (NAIRR), consistent with past recommendations of the NAIRR Task Force. The program shall pursue the infrastructure, governance mechanisms, and user interfaces to pilot an initial integration of distributed computational, data, model, and training resources to be made available to the research community in support of AI-related research and development. The Director of NSF shall identify Federal and private sector computational, data, software, and training resources appropriate for inclusion in the NAIRR pilot program. To assist with such work, within 45 days of the date of this order, the heads of agencies whom the Director of NSF identifies for coordination pursuant to this subsection shall each submit to the Director of NSF a report identifying the agency resources that could be developed and integrated into such a pilot program. These reports shall include a description of such resources, including their current status and availability; their format, structure, or technical specifications; associated agency expertise that will be provided; and the benefits and risks associated with their inclusion in the NAIRR pilot program. The heads of independent regulatory agencies are encouraged to take similar steps, as they deem appropriate.\n",
      "\n",
      "(ii) Within 150 days of the date of this order, fund and launch at least one NSF Regional Innovation Engine that prioritizes AI-related work, such as AI-related research, societal, or workforce needs.\n",
      "\n",
      "(iii) Within 540 days of the date of this order, establish at least four new National AI Research Institutes, in addition to the 25 currently funded as of the date of this order.\n",
      "\n",
      "(b) Within 120 days of the date of this order, to support activities involving high-performance and data-intensive computing, the Secretary of Energy, in coordination with the Director of NSF, shall, in a manner consistent with applicable law and available appropriations, establish a pilot program to enhance existing successful training programs for scientists, with the goal of training 500 new researchers by 2025 capable of meeting the rising demand for AI talent.\n",
      "\n",
      "(c) To promote innovation and clarify issues related to AI and inventorship of patentable subject matter, the Under Secretary of Commerce for Intellectual Property and Director of the United States Patent and Trademark Office (USPTO Director) shall:\n",
      "\n",
      "(i) within 120 days of the date of this order, publish guidance to USPTO patent examiners and applicants addressing inventorship and the use of AI, including generative AI, in the inventive process, including illustrative examples in which AI systems play different roles in inventive processes and how, in each example, inventorship issues ought to be analyzed;\n",
      "\n",
      "(ii) subsequently, within 270 days of the date of this order, issue additional guidance to USPTO patent examiners and applicants to address other considerations at the intersection of AI and IP, which could include, as the USPTO Director deems necessary, updated guidance on patent eligibility to address innovation in AI and critical and emerging technologies; and\n",
      "\n",
      "(iii) within 270 days of the date of this order or 180 days after the United States Copyright Office of the Library of Congress publishes its forthcoming AI study that will address copyright issues raised by AI, whichever comes later, consult with the Director of the United States Copyright Office and issue recommendations to the President on potential executive actions relating to copyright and AI. The recommendations shall address any copyright and related issues discussed in the United States Copyright Office’s study, including the scope of protection for works produced using AI and the treatment of copyrighted works in AI training.\n",
      "\n",
      "(d) Within 180 days of the date of this order, to assist developers of AI in combatting AI-related IP risks, the Secretary of Homeland Security, acting through the Director of the National Intellectual Property Rights Coordination Center, and in consultation with the Attorney General, shall develop a training, analysis, and evaluation program to mitigate AI-related IP risks. Such a program shall:\n",
      "\n",
      "(i) include appropriate personnel dedicated to collecting and analyzing reports of AI-related IP theft, investigating such incidents with implications for national security, and, where appropriate and consistent with applicable law, pursuing related enforcement actions;\n",
      "\n",
      "(ii) implement a policy of sharing information and coordinating on such work, as appropriate and consistent with applicable law, with the Federal Bureau of Investigation; United States Customs and Border Protection; other agencies; State and local agencies; and appropriate international organizations, including through work-sharing agreements;\n",
      "\n",
      "(iii) develop guidance and other appropriate resources to assist private sector actors with mitigating the risks of AI-related IP theft;\n",
      "\n",
      "(iv) share information and best practices with AI developers and law enforcement personnel to identify incidents, inform stakeholders of current legal requirements, and evaluate AI systems for IP law violations, as well as develop mitigation strategies and resources; and\n",
      "\n",
      "(v) assist the Intellectual Property Enforcement Coordinator in updating the Intellectual Property Enforcement Coordinator Joint Strategic Plan on Intellectual Property Enforcement to address AI-related issues.\n",
      "\n",
      "(e) To advance responsible AI innovation by a wide range of healthcare technology developers that promotes the welfare of patients and workers in the healthcare sector, the Secretary of HHS shall identify and, as appropriate and consistent with applicable law and the activities directed in section 8 of this order, prioritize grantmaking and other awards, as well as undertake related efforts, to support responsible AI development and use, including:\n",
      "\n",
      "(i) collaborating with appropriate private sector actors through HHS programs that may support the advancement of AI-enabled tools that develop personalized immune-response profiles for patients, consistent with section 4 of this order;\n",
      "\n",
      "(ii) prioritizing the allocation of 2024 Leading Edge Acceleration Project cooperative agreement awards to initiatives that explore ways to improve healthcare-data quality to support the responsible development of AI tools for clinical care, real-world-evidence programs, population health, public health, and related research; and\n",
      "\n",
      "(iii) accelerating grants awarded through the National Institutes of Health Artificial Intelligence/Machine Learning Consortium to Advance Health Equity and Researcher Diversity (AIM-AHEAD) program and showcasing current AIM-AHEAD activities in underserved communities.\n",
      "\n",
      "(f) To advance the development of AI systems that improve the quality of veterans’ healthcare, and in order to support small businesses’ innovative capacity, the Secretary of Veterans Affairs shall:\n",
      "\n",
      "(i) within 365 days of the date of this order, host two 3-month nationwide AI Tech Sprint competitions; and\n",
      "\n",
      "(ii) as part of the AI Tech Sprint competitions and in collaboration with appropriate partners, provide participants access to technical assistance, mentorship opportunities, individualized expert feedback on products under development, potential contract opportunities, and other programming and resources.\n",
      "\n",
      "(g) Within 180 days of the date of this order, to support the goal of strengthening our Nation’s resilience against climate change impacts and building an equitable clean energy economy for the future, the Secretary of Energy, in consultation with the Chair of the Federal Energy Regulatory Commission, the Director of OSTP, the Chair of the Council on Environmental Quality, the Assistant to the President and National Climate Advisor, and the heads of other relevant agencies as the Secretary of Energy may deem appropriate, shall:\n",
      "\n",
      "(i) issue a public report describing the potential for AI to improve planning, permitting, investment, and operations for electric grid infrastructure and to enable the provision of clean, affordable, reliable, resilient, and secure electric power to all Americans;\n",
      "\n",
      "(ii) develop tools that facilitate building foundation models useful for basic and applied science, including models that streamline permitting and environmental reviews while improving environmental and social outcomes;\n",
      "\n",
      "(iii) collaborate, as appropriate, with private sector organizations and members of academia to support development of AI tools to mitigate climate change risks;\n",
      "\n",
      "(iv) take steps to expand partnerships with industry, academia, other agencies, and international allies and partners to utilize the Department of Energy’s computing capabilities and AI testbeds to build foundation models that support new applications in science and energy, and for national security, including partnerships that increase community preparedness for climate-related risks, enable clean-energy deployment (including addressing delays in permitting reviews), and enhance grid reliability and resilience; and\n",
      "\n",
      "(v) establish an office to coordinate development of AI and other critical and emerging technologies across Department of Energy programs and the 17 National Laboratories.\n",
      "\n",
      "(h) Within 180 days of the date of this order, to understand AI’s implications for scientific research, the President’s Council of Advisors on Science and Technology shall submit to the President and make publicly available a report on the potential role of AI, especially given recent developments in AI, in research aimed at tackling major societal and global challenges. The report shall include a discussion of issues that may hinder the effective use of AI in research and practices needed to ensure that AI is used responsibly for research.\n",
      "\n",
      "5.3. Promoting Competition. (a) The head of each agency developing policies and regulations related to AI shall use their authorities, as appropriate and consistent with applicable law, to promote competition in AI and related technologies, as well as in other markets. Such actions include addressing risks arising from concentrated control of key inputs, taking steps to stop unlawful collusion and prevent dominant firms from disadvantaging competitors, and working to provide new opportunities for small businesses and entrepreneurs. In particular, the Federal Trade Commission is encouraged to consider, as it deems appropriate, whether to exercise the Commission’s existing authorities, including its rulemaking authority under the Federal Trade Commission Act, 15 U.S.C. 41 et seq., to ensure fair competition in the AI marketplace and to ensure that consumers and workers are protected from harms that may be enabled by the use of AI.\n",
      "\n",
      "(b) To promote competition and innovation in the semiconductor industry, recognizing that semiconductors power AI technologies and that their availability is critical to AI competition, the Secretary of Commerce shall, in implementing division A of Public Law 117-167, known as the Creating Helpful Incentives to Produce Semiconductors (CHIPS) Act of 2022, promote competition by:\n",
      "\n",
      "(i) implementing a flexible membership structure for the National Semiconductor Technology Center that attracts all parts of the semiconductor and microelectronics ecosystem, including startups and small firms;\n",
      "\n",
      "(ii) implementing mentorship programs to increase interest and participation in the semiconductor industry, including from workers in underserved communities;\n",
      "\n",
      "(iii) increasing, where appropriate and to the extent permitted by law, the availability of resources to startups and small businesses, including:\n",
      "\n",
      "(A) funding for physical assets, such as specialty equipment or facilities, to which startups and small businesses may not otherwise have access;\n",
      "\n",
      "(B) datasets — potentially including test and performance data — collected, aggregated, or shared by CHIPS research and development programs;\n",
      "\n",
      "(C) workforce development programs;\n",
      "\n",
      "(D) design and process technology, as well as IP, as appropriate; and\n",
      "\n",
      "(E) other resources, including technical and intellectual property assistance, that could accelerate commercialization of new technologies by startups and small businesses, as appropriate; and\n",
      "\n",
      "(iv) considering the inclusion, to the maximum extent possible, and as consistent with applicable law, of competition-increasing measures in notices of funding availability for commercial research-and-development facilities focused on semiconductors, including measures that increase access to facility capacity for startups or small firms developing semiconductors used to power AI technologies.\n",
      "\n",
      "(c) To support small businesses innovating and commercializing AI, as well as in responsibly adopting and deploying AI, the Administrator of the Small Business Administration shall:\n",
      "\n",
      "(i) prioritize the allocation of Regional Innovation Cluster program funding for clusters that support planning activities related to the establishment of one or more Small Business AI Innovation and Commercialization Institutes that provide support, technical assistance, and other resources to small businesses seeking to innovate, commercialize, scale, or otherwise advance the development of AI;\n",
      "\n",
      "(ii) prioritize the allocation of up to $2 million in Growth Accelerator Fund Competition bonus prize funds for accelerators that support the incorporation or expansion of AI-related curricula, training, and technical assistance, or other AI-related resources within their programming; and\n",
      "\n",
      "(iii) assess the extent to which the eligibility criteria of existing programs, including the State Trade Expansion Program, Technical and Business Assistance funding, and capital-access programs — such as the 7(a) loan program, 504 loan program, and Small Business Investment Company (SBIC) program — support appropriate expenses by small businesses related to the adoption of AI and, if feasible and appropriate, revise eligibility criteria to improve support for these expenses.\n",
      "\n",
      "(d) The Administrator of the Small Business Administration, in coordination with resource partners, shall conduct outreach regarding, and raise awareness of, opportunities for small businesses to use capital-access programs described in subsection 5.3(c) of this section for eligible AI-related purposes, and for eligible investment funds with AI-related expertise — particularly those seeking to serve or with experience serving underserved communities — to apply for an SBIC license.\n",
      "\n",
      "Sec. 6. Supporting Workers.(a) To advance the Government’s understanding of AI’s implications for workers, the following actions shall be taken within 180 days of the date of this order:\n",
      "\n",
      "(i) The Chairman of the Council of Economic Advisers shall prepare and submit a report to the President on the labor-market effects of AI.\n",
      "\n",
      "(ii) To evaluate necessary steps for the Federal Government to address AI-related workforce disruptions, the Secretary of Labor shall submit to the President a report analyzing the abilities of agencies to support workers displaced by the adoption of AI and other technological advancements. The report shall, at a minimum:\n",
      "\n",
      "(A) assess how current or formerly operational Federal programs designed to assist workers facing job disruptions — including unemployment insurance and programs authorized by the Workforce Innovation and Opportunity Act (Public Law 113-128) — could be used to respond to possible future AI-related disruptions; and\n",
      "\n",
      "(B) identify options, including potential legislative measures, to strengthen or develop additional Federal support for workers displaced by AI and, in consultation with the Secretary of Commerce and the Secretary of Education, strengthen and expand education and training opportunities that provide individuals pathways to occupations related to AI.\n",
      "\n",
      "(b) To help ensure that AI deployed in the workplace advances employees’ well-being:\n",
      "\n",
      "(i) The Secretary of Labor shall, within 180 days of the date of this order and in consultation with other agencies and with outside entities, including labor unions and workers, as the Secretary of Labor deems appropriate, develop and publish principles and best practices for employers that could be used to mitigate AI’s potential harms to employees’ well-being and maximize its potential benefits. The principles and best practices shall include specific steps for employers to take with regard to AI, and shall cover, at a minimum:\n",
      "\n",
      "(A) job-displacement risks and career opportunities related to AI, including effects on job skills and evaluation of applicants and workers;\n",
      "\n",
      "(B) labor standards and job quality, including issues related to the equity, protected-activity, compensation, health, and safety implications of AI in the workplace; and\n",
      "\n",
      "(C) implications for workers of employers’ AI-related collection and use of data about them, including transparency, engagement, management, and activity protected under worker-protection laws.\n",
      "\n",
      "(ii) After principles and best practices are developed pursuant to subsection (b)(i) of this section, the heads of agencies shall consider, in consultation with the Secretary of Labor, encouraging the adoption of these guidelines in their programs to the extent appropriate for each program and consistent with applicable law.\n",
      "\n",
      "(iii) To support employees whose work is monitored or augmented by AI in being compensated appropriately for all of their work time, the Secretary of Labor shall issue guidance to make clear that employers that deploy AI to monitor or augment employees’ work must continue to comply with protections that ensure that workers are compensated for their hours worked, as defined under the Fair Labor Standards Act of 1938, 29 U.S.C. 201 et seq., and other legal requirements.\n",
      "\n",
      "(c) To foster a diverse AI-ready workforce, the Director of NSF shall prioritize available resources to support AI-related education and AI-related workforce development through existing programs. The Director shall additionally consult with agencies, as appropriate, to identify further opportunities for agencies to allocate resources for those purposes. The actions by the Director shall use appropriate fellowship programs and awards for these purposes.\n",
      "\n",
      "Sec. 7. Advancing Equity and Civil Rights.\n",
      "\n",
      "7.1. Strengthening AI and Civil Rights in the Criminal Justice System. (a) To address unlawful discrimination and other harms that may be exacerbated by AI, the Attorney General shall:\n",
      "\n",
      "(i) consistent with Executive Order 12250 of November 2, 1980 (Leadership and Coordination of Nondiscrimination Laws), Executive Order 14091, and 28 C.F.R. 0.50-51, coordinate with and support agencies in their implementation and enforcement of existing Federal laws to address civil rights and civil liberties violations and discrimination related to AI;\n",
      "\n",
      "(ii) direct the Assistant Attorney General in charge of the Civil Rights Division to convene, within 90 days of the date of this order, a meeting of the heads of Federal civil rights offices — for which meeting the heads of civil rights offices within independent regulatory agencies will be encouraged to join — to discuss comprehensive use of their respective authorities and offices to: prevent and address discrimination in the use of automated systems, including algorithmic discrimination; increase coordination between the Department of Justice’s Civil Rights Division and Federal civil rights offices concerning issues related to AI and algorithmic discrimination; improve external stakeholder engagement to promote public awareness of potential discriminatory uses and effects of AI; and develop, as appropriate, additional training, technical assistance, guidance, or other resources; and\n",
      "\n",
      "(iii) consider providing, as appropriate and consistent with applicable law, guidance, technical assistance, and training to State, local, Tribal, and territorial investigators and prosecutors on best practices for investigating and prosecuting civil rights violations and discrimination related to automated systems, including AI.\n",
      "\n",
      "(b) To promote the equitable treatment of individuals and adhere to the Federal Government’s fundamental obligation to ensure fair and impartial justice for all, with respect to the use of AI in the criminal justice system, the Attorney General shall, in consultation with the Secretary of Homeland Security and the Director of OSTP:\n",
      "\n",
      "(i) within 365 days of the date of this order, submit to the President a report that addresses the use of AI in the criminal justice system, including any use in:\n",
      "\n",
      "(A) sentencing;\n",
      "\n",
      "(B) parole, supervised release, and probation;\n",
      "\n",
      "(C) bail, pretrial release, and pretrial detention;\n",
      "\n",
      "(D) risk assessments, including pretrial, earned time, and early release or transfer to home-confinement determinations;\n",
      "\n",
      "(E) police surveillance;\n",
      "\n",
      "(F) crime forecasting and predictive policing, including the ingestion of historical crime data into AI systems to predict high-density “hot spots”;\n",
      "\n",
      "(G) prison-management tools; and\n",
      "\n",
      "(H) forensic analysis;\n",
      "\n",
      "(ii) within the report set forth in subsection 7.1(b)(i) of this section:\n",
      "\n",
      "(A) identify areas where AI can enhance law enforcement efficiency and accuracy, consistent with protections for privacy, civil rights, and civil liberties; and\n",
      "\n",
      "(B) recommend best practices for law enforcement agencies, including safeguards and appropriate use limits for AI, to address the concerns set forth in section 13(e)(i) of Executive Order 14074 as well as the best practices and the guidelines set forth in section 13(e)(iii) of Executive Order 14074; and\n",
      "\n",
      "(iii) supplement the report set forth in subsection 7.1(b)(i) of this section as appropriate with recommendations to the President, including with respect to requests for necessary legislation.\n",
      "\n",
      "(c) To advance the presence of relevant technical experts and expertise (such as machine-learning engineers, software and infrastructure engineering, data privacy experts, data scientists, and user experience researchers) among law enforcement professionals:\n",
      "\n",
      "(i) The interagency working group created pursuant to section 3 of Executive Order 14074 shall, within 180 days of the date of this order, identify and share best practices for recruiting and hiring law enforcement professionals who have the technical skills mentioned in subsection 7.1(c) of this section, and for training law enforcement professionals about responsible application of AI.\n",
      "\n",
      "(ii) Within 270 days of the date of this order, the Attorney General shall, in consultation with the Secretary of Homeland Security, consider those best practices and the guidance developed under section 3(d) of Executive Order 14074 and, if necessary, develop additional general recommendations for State, local, Tribal, and territorial law enforcement agencies and criminal justice agencies seeking to recruit, hire, train, promote, and retain highly qualified and service-oriented officers and staff with relevant technical knowledge. In considering this guidance, the Attorney General shall consult with State, local, Tribal, and territorial law enforcement agencies, as appropriate.\n",
      "\n",
      "(iii) Within 365 days of the date of this order, the Attorney General shall review the work conducted pursuant to section 2(b) of Executive Order 14074 and, if appropriate, reassess the existing capacity to investigate law enforcement deprivation of rights under color of law resulting from the use of AI, including through improving and increasing training of Federal law enforcement officers, their supervisors, and Federal prosecutors on how to investigate and prosecute cases related to AI involving the deprivation of rights under color of law pursuant to 18 U.S.C. 242.\n",
      "\n",
      "7.2. Protecting Civil Rights Related to Government Benefits and Programs. (a) To advance equity and civil rights, consistent with the directives of Executive Order 14091, and in addition to complying with the guidance on Federal Government use of AI issued pursuant to section 10.1(b) of this order, agencies shall use their respective civil rights and civil liberties offices and authorities — as appropriate and consistent with applicable law — to prevent and address unlawful discrimination and other harms that result from uses of AI in Federal Government programs and benefits administration. This directive does not apply to agencies’ civil or criminal enforcement authorities. Agencies shall consider opportunities to ensure that their respective civil rights and civil liberties offices are appropriately consulted on agency decisions regarding the design, development, acquisition, and use of AI in Federal Government programs and benefits administration. To further these objectives, agencies shall also consider opportunities to increase coordination, communication, and engagement about AI as appropriate with community-based organizations; civil-rights and civil-liberties organizations; academic institutions; industry; State, local, Tribal, and territorial governments; and other stakeholders.\n",
      "\n",
      "(b) To promote equitable administration of public benefits:\n",
      "\n",
      "(i) The Secretary of HHS shall, within 180 days of the date of this order and in consultation with relevant agencies, publish a plan, informed by the guidance issued pursuant to section 10.1(b) of this order, addressing the use of automated or algorithmic systems in the implementation by States and localities of public benefits and services administered by the Secretary, such as to promote: assessment of access to benefits by qualified recipients; notice to recipients about the presence of such systems; regular evaluation to detect unjust denials; processes to retain appropriate levels of discretion of expert agency staff; processes to appeal denials to human reviewers; and analysis of whether algorithmic systems in use by benefit programs achieve equitable and just outcomes.\n",
      "\n",
      "(ii) The Secretary of Agriculture shall, within 180 days of the date of this order and as informed by the guidance issued pursuant to section 10.1(b) of this order, issue guidance to State, local, Tribal, and territorial public-benefits administrators on the use of automated or algorithmic systems in implementing benefits or in providing customer support for benefit programs administered by the Secretary, to ensure that programs using those systems:\n",
      "\n",
      "(A) maximize program access for eligible recipients;\n",
      "\n",
      "(B) employ automated or algorithmic systems in a manner consistent with any requirements for using merit systems personnel in public-benefits programs;\n",
      "\n",
      "(C) identify instances in which reliance on automated or algorithmic systems would require notification by the State, local, Tribal, or territorial government to the Secretary;\n",
      "\n",
      "(D) identify instances when applicants and participants can appeal benefit determinations to a human reviewer for reconsideration and can receive other customer support from a human being;\n",
      "\n",
      "(E) enable auditing and, if necessary, remediation of the logic used to arrive at an individual decision or determination to facilitate the evaluation of appeals; and\n",
      "\n",
      "(F) enable the analysis of whether algorithmic systems in use by benefit programs achieve equitable outcomes.\n",
      "\n",
      "7.3. Strengthening AI and Civil Rights in the Broader Economy. (a) Within 365 days of the date of this order, to prevent unlawful discrimination from AI used for hiring, the Secretary of Labor shall publish guidance for Federal contractors regarding nondiscrimination in hiring involving AI and other technology-based hiring systems.\n",
      "\n",
      "(b) To address discrimination and biases against protected groups in housing markets and consumer financial markets, the Director of the Federal Housing Finance Agency and the Director of the Consumer Financial Protection Bureau are encouraged to consider using their authorities, as they deem appropriate, to require their respective regulated entities, where possible, to use appropriate methodologies including AI tools to ensure compliance with Federal law and:\n",
      "\n",
      "(i) evaluate their underwriting models for bias or disparities affecting protected groups; and\n",
      "\n",
      "(ii) evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.\n",
      "\n",
      "(c) Within 180 days of the date of this order, to combat unlawful discrimination enabled by automated or algorithmic tools used to make decisions about access to housing and in other real estate-related transactions, the Secretary of Housing and Urban Development shall, and the Director of the Consumer Financial Protection Bureau is encouraged to, issue additional guidance:\n",
      "\n",
      "(i) addressing the use of tenant screening systems in ways that may violate the Fair Housing Act (Public Law 90-284), the Fair Credit Reporting Act (Public Law 91-508), or other relevant Federal laws, including how the use of data, such as criminal records, eviction records, and credit information, can lead to discriminatory outcomes in violation of Federal law; and\n",
      "\n",
      "(ii) addressing how the Fair Housing Act, the Consumer Financial Protection Act of 2010 (title X of Public Law 111-203), or the Equal Credit Opportunity Act (Public Law 93-495) apply to the advertising of housing, credit, and other real estate-related transactions through digital platforms, including those that use algorithms to facilitate advertising delivery, as well as on best practices to avoid violations of Federal law.\n",
      "\n",
      "(d) To help ensure that people with disabilities benefit from AI’s promise while being protected from its risks, including unequal treatment from the use of biometric data like gaze direction, eye tracking, gait analysis, and hand motions, the Architectural and Transportation Barriers Compliance Board is encouraged, as it deems appropriate, to solicit public participation and conduct community engagement; to issue technical assistance and recommendations on the risks and benefits of AI in using biometric data as an input; and to provide people with disabilities access to information and communication technology and transportation services.\n",
      "\n",
      "Sec. 8. Protecting Consumers, Patients, Passengers, and Students. (a) Independent regulatory agencies are encouraged, as they deem appropriate, to consider using their full range of authorities to protect American consumers from fraud, discrimination, and threats to privacy and to address other risks that may arise from the use of AI, including risks to financial stability, and to consider rulemaking, as well as emphasizing or clarifying where existing regulations and guidance apply to AI, including clarifying the responsibility of regulated entities to conduct due diligence on and monitor any third-party AI services they use, and emphasizing or clarifying requirements and expectations related to the transparency of AI models and regulated entities’ ability to explain their use of AI models.\n",
      "\n",
      "(b) To help ensure the safe, responsible deployment and use of AI in the healthcare, public-health, and human-services sectors:\n",
      "\n",
      "(i) Within 90 days of the date of this order, the Secretary of HHS shall, in consultation with the Secretary of Defense and the Secretary of Veterans Affairs, establish an HHS AI Task Force that shall, within 365 days of its creation, develop a strategic plan that includes policies and frameworks — possibly including regulatory action, as appropriate — on responsible deployment and use of AI and AI-enabled technologies in the health and human services sector (including research and discovery, drug and device safety, healthcare delivery and financing, and public health), and identify appropriate guidance and resources to promote that deployment, including in the following areas:\n",
      "\n",
      "(A) development, maintenance, and use of predictive and generative AI-enabled technologies in healthcare delivery and financing — including quality measurement, performance improvement, program integrity, benefits administration, and patient experience — taking into account considerations such as appropriate human oversight of the application of AI-generated output;\n",
      "\n",
      "(B) long-term safety and real-world performance monitoring of AI-enabled technologies in the health and human services sector, including clinically relevant or significant modifications and performance across population groups, with a means to communicate product updates to regulators, developers, and users;\n",
      "\n",
      "(C) incorporation of equity principles in AI-enabled technologies used in the health and human services sector, using disaggregated data on affected populations and representative population data sets when developing new models, monitoring algorithmic performance against discrimination and bias in existing models, and helping to identify and mitigate discrimination and bias in current systems;\n",
      "\n",
      "(D) incorporation of safety, privacy, and security standards into the software-development lifecycle for protection of personally identifiable information, including measures to address AI-enhanced cybersecurity threats in the health and human services sector;\n",
      "\n",
      "(E) development, maintenance, and availability of documentation to help users determine appropriate and safe uses of AI in local settings in the health and human services sector;\n",
      "\n",
      "(F) work to be done with State, local, Tribal, and territorial health and human services agencies to advance positive use cases and best practices for use of AI in local settings; and\n",
      "\n",
      "(G) identification of uses of AI to promote workplace efficiency and satisfaction in the health and human services sector, including reducing administrative burdens.\n",
      "\n",
      "(ii) Within 180 days of the date of this order, the Secretary of HHS shall direct HHS components, as the Secretary of HHS deems appropriate, to develop a strategy, in consultation with relevant agencies, to determine whether AI-enabled technologies in the health and human services sector maintain appropriate levels of quality, including, as appropriate, in the areas described in subsection (b)(i) of this section. This work shall include the development of AI assurance policy — to evaluate important aspects of the performance of AI-enabled healthcare tools — and infrastructure needs for enabling pre-market assessment and post-market oversight of AI-enabled healthcare-technology algorithmic system performance against real-world data.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Secretary of HHS shall, in consultation with relevant agencies as the Secretary of HHS deems appropriate, consider appropriate actions to advance the prompt understanding of, and compliance with, Federal nondiscrimination laws by health and human services providers that receive Federal financial assistance, as well as how those laws relate to AI. Such actions may include:\n",
      "\n",
      "(A) convening and providing technical assistance to health and human services providers and payers about their obligations under Federal nondiscrimination and privacy laws as they relate to AI and the potential consequences of noncompliance; and\n",
      "\n",
      "(B) issuing guidance, or taking other action as appropriate, in response to any complaints or other reports of noncompliance with Federal nondiscrimination and privacy laws as they relate to AI.\n",
      "\n",
      "(iv) Within 365 days of the date of this order, the Secretary of HHS shall, in consultation with the Secretary of Defense and the Secretary of Veterans Affairs, establish an AI safety program that, in partnership with voluntary federally listed Patient Safety Organizations:\n",
      "\n",
      "(A) establishes a common framework for approaches to identifying and capturing clinical errors resulting from AI deployed in healthcare settings as well as specifications for a central tracking repository for associated incidents that cause harm, including through bias or discrimination, to patients, caregivers, or other parties;\n",
      "\n",
      "(B) analyzes captured data and generated evidence to develop, wherever appropriate, recommendations, best practices, or other informal guidelines aimed at avoiding these harms; and\n",
      "\n",
      "(C) disseminates those recommendations, best practices, or other informal guidance to appropriate stakeholders, including healthcare providers.\n",
      "\n",
      "(v) Within 365 days of the date of this order, the Secretary of HHS shall develop a strategy for regulating the use of AI or AI-enabled tools in drug-development processes. The strategy shall, at a minimum:\n",
      "\n",
      "(A) define the objectives, goals, and high-level principles required for appropriate regulation throughout each phase of drug development;\n",
      "\n",
      "(B) identify areas where future rulemaking, guidance, or additional statutory authority may be necessary to implement such a regulatory system;\n",
      "\n",
      "(C) identify the existing budget, resources, personnel, and potential for new public/private partnerships necessary for such a regulatory system; and\n",
      "\n",
      "(D) consider risks identified by the actions undertaken to implement section 4 of this order.\n",
      "\n",
      "(c) To promote the safe and responsible development and use of AI in the transportation sector, in consultation with relevant agencies:\n",
      "\n",
      "(i) Within 30 days of the date of this order, the Secretary of Transportation shall direct the Nontraditional and Emerging Transportation Technology (NETT) Council to assess the need for information, technical assistance, and guidance regarding the use of AI in transportation. The Secretary of Transportation shall further direct the NETT Council, as part of any such efforts, to:\n",
      "\n",
      "(A) support existing and future initiatives to pilot transportation-related applications of AI, as they align with policy priorities articulated in the Department of Transportation’s (DOT) Innovation Principles, including, as appropriate, through technical assistance and connecting stakeholders;\n",
      "\n",
      "(B) evaluate the outcomes of such pilot programs in order to assess when DOT, or other Federal or State agencies, have sufficient information to take regulatory actions, as appropriate, and recommend appropriate actions when that information is available; and\n",
      "\n",
      "(C) establish a new DOT Cross-Modal Executive Working Group, which will consist of members from different divisions of DOT and coordinate applicable work among these divisions, to solicit and use relevant input from appropriate stakeholders.\n",
      "\n",
      "(ii) Within 90 days of the date of this order, the Secretary of Transportation shall direct appropriate Federal Advisory Committees of the DOT to provide advice on the safe and responsible use of AI in transportation. The committees shall include the Advanced Aviation Advisory Committee, the Transforming Transportation Advisory Committee, and the Intelligent Transportation Systems Program Advisory Committee.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Secretary of Transportation shall direct the Advanced Research Projects Agency-Infrastructure (ARPA-I) to explore the transportation-related opportunities and challenges of AI — including regarding software-defined AI enhancements impacting autonomous mobility ecosystems. The Secretary of Transportation shall further encourage ARPA-I to prioritize the allocation of grants to those opportunities, as appropriate. The work tasked to ARPA-I shall include soliciting input on these topics through a public consultation process, such as an RFI.\n",
      "\n",
      "(d) To help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI. These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate. They shall also include the development of an “AI toolkit” for education leaders implementing recommendations from the Department of Education’s AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.\n",
      "\n",
      "(e) The Federal Communications Commission is encouraged to consider actions related to how AI will affect communications networks and consumers, including by:\n",
      "\n",
      "(i) examining the potential for AI to improve spectrum management, increase the efficiency of non-Federal spectrum usage, and expand opportunities for the sharing of non-Federal spectrum;\n",
      "\n",
      "(ii) coordinating with the National Telecommunications and Information Administration to create opportunities for sharing spectrum between Federal and non-Federal spectrum operations;\n",
      "\n",
      "(iii) providing support for efforts to improve network security, resiliency, and interoperability using next-generation technologies that incorporate AI, including self-healing networks, 6G, and Open RAN; and\n",
      "\n",
      "(iv) encouraging, including through rulemaking, efforts to combat unwanted robocalls and robotexts that are facilitated or exacerbated by AI and to deploy AI technologies that better serve consumers by blocking unwanted robocalls and robotexts.\n",
      "\n",
      "Sec. 9. Protecting Privacy. (a) To mitigate privacy risks potentially exacerbated by AI — including by AI’s facilitation of the collection or use of information about individuals, or the making of inferences about individuals — the Director of OMB shall:\n",
      "\n",
      "(i) evaluate and take steps to identify commercially available information (CAI) procured by agencies, particularly CAI that contains personally identifiable information and including CAI procured from data brokers and CAI procured and processed indirectly through vendors, in appropriate agency inventory and reporting processes (other than when it is used for the purposes of national security);\n",
      "\n",
      "(ii) evaluate, in consultation with the Federal Privacy Council and the Interagency Council on Statistical Policy, agency standards and procedures associated with the collection, processing, maintenance, use, sharing, dissemination, and disposition of CAI that contains personally identifiable information (other than when it is used for the purposes of national security) to inform potential guidance to agencies on ways to mitigate privacy and confidentiality risks from agencies’ activities related to CAI;\n",
      "\n",
      "(iii) within 180 days of the date of this order, in consultation with the Attorney General, the Assistant to the President for Economic Policy, and the Director of OSTP, issue an RFI to inform potential revisions to guidance to agencies on implementing the privacy provisions of the E-Government Act of 2002 (Public Law 107-347). The RFI shall seek feedback regarding how privacy impact assessments may be more effective at mitigating privacy risks, including those that are further exacerbated by AI; and\n",
      "\n",
      "(iv) take such steps as are necessary and appropriate, consistent with applicable law, to support and advance the near-term actions and long-term strategy identified through the RFI process, including issuing new or updated guidance or RFIs or consulting other agencies or the Federal Privacy Council.\n",
      "\n",
      "(b) Within 365 days of the date of this order, to better enable agencies to use PETs to safeguard Americans’ privacy from the potential threats exacerbated by AI, the Secretary of Commerce, acting through the Director of NIST, shall create guidelines for agencies to evaluate the efficacy of differential-privacy-guarantee protections, including for AI. The guidelines shall, at a minimum, describe the significant factors that bear on differential-privacy safeguards and common risks to realizing differential privacy in practice.\n",
      "\n",
      "(c) To advance research, development, and implementation related to PETs:\n",
      "\n",
      "(i) Within 120 days of the date of this order, the Director of NSF, in collaboration with the Secretary of Energy, shall fund the creation of a Research Coordination Network (RCN) dedicated to advancing privacy research and, in particular, the development, deployment, and scaling of PETs. The RCN shall serve to enable privacy researchers to share information, coordinate and collaborate in research, and develop standards for the privacy-research community.\n",
      "\n",
      "(ii) Within 240 days of the date of this order, the Director of NSF shall engage with agencies to identify ongoing work and potential opportunities to incorporate PETs into their operations. The Director of NSF shall, where feasible and appropriate, prioritize research — including efforts to translate research discoveries into practical applications — that encourage the adoption of leading-edge PETs solutions for agencies’ use, including through research engagement through the RCN described in subsection (c)(i) of this section.\n",
      "\n",
      "(iii) The Director of NSF shall use the results of the United States-United Kingdom PETs Prize Challenge to inform the approaches taken, and opportunities identified, for PETs research and adoption.\n",
      "\n",
      "Sec. 10. Advancing Federal Government Use of AI.\n",
      "\n",
      "10.1. Providing Guidance for AI Management. (a) To coordinate the use of AI across the Federal Government, within 60 days of the date of this order and on an ongoing basis as necessary, the Director of OMB shall convene and chair an interagency council to coordinate the development and use of AI in agencies’ programs and operations, other than the use of AI in national security systems. The Director of OSTP shall serve as Vice Chair for the interagency council. The interagency council’s membership shall include, at minimum, the heads of the agencies identified in 31 U.S.C. 901(b), the Director of National Intelligence, and other agencies as identified by the Chair. Until agencies designate their permanent Chief AI Officers consistent with the guidance described in subsection 10.1(b) of this section, they shall be represented on the interagency council by an appropriate official at the Assistant Secretary level or equivalent, as determined by the head of each agency.\n",
      "\n",
      "(b) To provide guidance on Federal Government use of AI, within 150 days of the date of this order and updated periodically thereafter, the Director of OMB, in coordination with the Director of OSTP, and in consultation with the interagency council established in subsection 10.1(a) of this section, shall issue guidance to agencies to strengthen the effective and appropriate use of AI, advance AI innovation, and manage risks from AI in the Federal Government. The Director of OMB’s guidance shall specify, to the extent appropriate and consistent with applicable law:\n",
      "\n",
      "(i) the requirement to designate at each agency within 60 days of the issuance of the guidance a Chief Artificial Intelligence Officer who shall hold primary responsibility in their agency, in coordination with other responsible officials, for coordinating their agency’s use of AI, promoting AI innovation in their agency, managing risks from their agency’s use of AI, and carrying out the responsibilities described in section 8(c) of Executive Order 13960 of December 3, 2020 (Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government), and section 4(b) of Executive Order 14091;\n",
      "\n",
      "(ii) the Chief Artificial Intelligence Officers’ roles, responsibilities, seniority, position, and reporting structures;\n",
      "\n",
      "(iii) for the agencies identified in 31 U.S.C. 901(b), the creation of internal Artificial Intelligence Governance Boards, or other appropriate mechanisms, at each agency within 60 days of the issuance of the guidance to coordinate and govern AI issues through relevant senior leaders from across the agency;\n",
      "\n",
      "(iv) required minimum risk-management practices for Government uses of AI that impact people’s rights or safety, including, where appropriate, the following practices derived from OSTP’s Blueprint for an AI Bill of Rights and the NIST AI Risk Management Framework: conducting public consultation; assessing data quality; assessing and mitigating disparate impacts and algorithmic discrimination; providing notice of the use of AI; continuously monitoring and evaluating deployed AI; and granting human consideration and remedies for adverse decisions made using AI;\n",
      "\n",
      "(v) specific Federal Government uses of AI that are presumed by default to impact rights or safety;\n",
      "\n",
      "(vi) recommendations to agencies to reduce barriers to the responsible use of AI, including barriers related to information technology infrastructure, data, workforce, budgetary restrictions, and cybersecurity processes;\n",
      "\n",
      "(vii) requirements that agencies identified in 31 U.S.C. 901(b) develop AI strategies and pursue high-impact AI use cases;\n",
      "\n",
      "(viii) in consultation with the Secretary of Commerce, the Secretary of Homeland Security, and the heads of other appropriate agencies as determined by the Director of OMB, recommendations to agencies regarding:\n",
      "\n",
      "(A) external testing for AI, including AI red-teaming for generative AI, to be developed in coordination with the Cybersecurity and Infrastructure Security Agency;\n",
      "\n",
      "(B) testing and safeguards against discriminatory, misleading, inflammatory, unsafe, or deceptive outputs, as well as against producing child sexual abuse material and against producing non-consensual intimate imagery of real individuals (including intimate digital depictions of the body or body parts of an identifiable individual), for generative AI;\n",
      "\n",
      "(C) reasonable steps to watermark or otherwise label output from generative AI;\n",
      "\n",
      "(D) application of the mandatory minimum risk-management practices defined under subsection 10.1(b)(iv) of this section to procured AI;\n",
      "\n",
      "(E) independent evaluation of vendors’ claims concerning both the effectiveness and risk mitigation of their AI offerings;\n",
      "\n",
      "(F) documentation and oversight of procured AI;\n",
      "\n",
      "(G) maximizing the value to agencies when relying on contractors to use and enrich Federal Government data for the purposes of AI development and operation;\n",
      "\n",
      "(H) provision of incentives for the continuous improvement of procured AI; and\n",
      "\n",
      "(I) training on AI in accordance with the principles set out in this order and in other references related to AI listed herein; and\n",
      "\n",
      "(ix) requirements for public reporting on compliance with this guidance.\n",
      "\n",
      "(c) To track agencies’ AI progress, within 60 days of the issuance of the guidance established in subsection 10.1(b) of this section and updated periodically thereafter, the Director of OMB shall develop a method for agencies to track and assess their ability to adopt AI into their programs and operations, manage its risks, and comply with Federal policy on AI. This method should draw on existing related efforts as appropriate and should address, as appropriate and consistent with applicable law, the practices, processes, and capabilities necessary for responsible AI adoption, training, and governance across, at a minimum, the areas of information technology infrastructure, data, workforce, leadership, and risk management.\n",
      "\n",
      "(d) To assist agencies in implementing the guidance to be established in subsection 10.1(b) of this section:\n",
      "\n",
      "(i) within 90 days of the issuance of the guidance, the Secretary of Commerce, acting through the Director of NIST, and in coordination with the Director of OMB and the Director of OSTP, shall develop guidelines, tools, and practices to support implementation of the minimum risk-management practices described in subsection 10.1(b)(iv) of this section; and\n",
      "\n",
      "(ii) within 180 days of the issuance of the guidance, the Director of OMB shall develop an initial means to ensure that agency contracts for the acquisition of AI systems and services align with the guidance described in subsection 10.1(b) of this section and advance the other aims identified in section 7224(d)(1) of the Advancing American AI Act (Public Law 117-263, div. G, title LXXII, subtitle B).\n",
      "\n",
      "(e) To improve transparency for agencies’ use of AI, the Director of OMB shall, on an annual basis, issue instructions to agencies for the collection, reporting, and publication of agency AI use cases, pursuant to section 7225(a) of the Advancing American AI Act. Through these instructions, the Director shall, as appropriate, expand agencies’ reporting on how they are managing risks from their AI use cases and update or replace the guidance originally established in section 5 of Executive Order 13960.\n",
      "\n",
      "(f) To advance the responsible and secure use of generative AI in the Federal Government:\n",
      "\n",
      "(i) As generative AI products become widely available and common in online platforms, agencies are discouraged from imposing broad general bans or blocks on agency use of generative AI. Agencies should instead limit access, as necessary, to specific generative AI services based on specific risk assessments; establish guidelines and limitations on the appropriate use of generative AI; and, with appropriate safeguards in place, provide their personnel and programs with access to secure and reliable generative AI capabilities, at least for the purposes of experimentation and routine tasks that carry a low risk of impacting Americans’ rights. To protect Federal Government information, agencies are also encouraged to employ risk-management practices, such as training their staff on proper use, protection, dissemination, and disposition of Federal information; negotiating appropriate terms of service with vendors; implementing measures designed to ensure compliance with record-keeping, cybersecurity, confidentiality, privacy, and data protection requirements; and deploying other measures to prevent misuse of Federal Government information in generative AI.\n",
      "\n",
      "(ii) Within 90 days of the date of this order, the Administrator of General Services, in coordination with the Director of OMB, and in consultation with the Federal Secure Cloud Advisory Committee and other relevant agencies as the Administrator of General Services may deem appropriate, shall develop and issue a framework for prioritizing critical and emerging technologies offerings in the Federal Risk and Authorization Management Program authorization process, starting with generative AI offerings that have the primary purpose of providing large language model-based chat interfaces, code-generation and debugging tools, and associated application programming interfaces, as well as prompt-based image generators. This framework shall apply for no less than 2 years from the date of its issuance. Agency Chief Information Officers, Chief Information Security Officers, and authorizing officials are also encouraged to prioritize generative AI and other critical and emerging technologies in granting authorities for agency operation of information technology systems and any other applicable release or oversight processes, using continuous authorizations and approvals wherever feasible.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Director of the Office of Personnel Management (OPM), in coordination with the Director of OMB, shall develop guidance on the use of generative AI for work by the Federal workforce.\n",
      "\n",
      "(g) Within 30 days of the date of this order, to increase agency investment in AI, the Technology Modernization Board shall consider, as it deems appropriate and consistent with applicable law, prioritizing funding for AI projects for the Technology Modernization Fund for a period of at least 1 year. Agencies are encouraged to submit to the Technology Modernization Fund project funding proposals that include AI — and particularly generative AI — in service of mission delivery.\n",
      "\n",
      "(h) Within 180 days of the date of this order, to facilitate agencies’ access to commercial AI capabilities, the Administrator of General Services, in coordination with the Director of OMB, and in collaboration with the Secretary of Defense, the Secretary of Homeland Security, the Director of National Intelligence, the Administrator of the National Aeronautics and Space Administration, and the head of any other agency identified by the Administrator of General Services, shall take steps consistent with applicable law to facilitate access to Federal Government-wide acquisition solutions for specified types of AI services and products, such as through the creation of a resource guide or other tools to assist the acquisition workforce. Specified types of AI capabilities shall include generative AI and specialized computing infrastructure.\n",
      "\n",
      "(i) The initial means, instructions, and guidance issued pursuant to subsections 10.1(a)-(h) of this section shall not apply to AI when it is used as a component of a national security system, which shall be addressed by the proposed National Security Memorandum described in subsection 4.8 of this order.\n",
      "\n",
      "10.2. Increasing AI Talent in Government. (a) Within 45 days of the date of this order, to plan a national surge in AI talent in the Federal Government, the Director of OSTP and the Director of OMB, in consultation with the Assistant to the President for National Security Affairs, the Assistant to the President for Economic Policy, the Assistant to the President and Domestic Policy Advisor, and the Assistant to the President and Director of the Gender Policy Council, shall identify priority mission areas for increased Federal Government AI talent, the types of talent that are highest priority to recruit and develop to ensure adequate implementation of this order and use of relevant enforcement and regulatory authorities to address AI risks, and accelerated hiring pathways.\n",
      "\n",
      "(b) Within 45 days of the date of this order, to coordinate rapid advances in the capacity of the Federal AI workforce, the Assistant to the President and Deputy Chief of Staff for Policy, in coordination with the Director of OSTP and the Director of OMB, and in consultation with the National Cyber Director, shall convene an AI and Technology Talent Task Force, which shall include the Director of OPM, the Director of the General Services Administration’s Technology Transformation Services, a representative from the Chief Human Capital Officers Council, the Assistant to the President for Presidential Personnel, members of appropriate agency technology talent programs, a representative of the Chief Data Officer Council, and a representative of the interagency council convened under subsection 10.1(a) of this section. The Task Force’s purpose shall be to accelerate and track the hiring of AI and AI-enabling talent across the Federal Government, including through the following actions:\n",
      "\n",
      "(i) within 180 days of the date of this order, tracking and reporting progress to the President on increasing AI capacity across the Federal Government, including submitting to the President a report and recommendations for further increasing capacity;\n",
      "\n",
      "(ii) identifying and circulating best practices for agencies to attract, hire, retain, train, and empower AI talent, including diversity, inclusion, and accessibility best practices, as well as to plan and budget adequately for AI workforce needs;\n",
      "\n",
      "(iii) coordinating, in consultation with the Director of OPM, the use of fellowship programs and agency technology-talent programs and human-capital teams to build hiring capabilities, execute hires, and place AI talent to fill staffing gaps; and\n",
      "\n",
      "(iv) convening a cross-agency forum for ongoing collaboration between AI professionals to share best practices and improve retention.\n",
      "\n",
      "(c) Within 45 days of the date of this order, to advance existing Federal technology talent programs, the United States Digital Service, Presidential Innovation Fellowship, United States Digital Corps, OPM, and technology talent programs at agencies, with support from the AI and Technology Talent Task Force described in subsection 10.2(b) of this section, as appropriate and permitted by law, shall develop and begin to implement plans to support the rapid recruitment of individuals as part of a Federal Government-wide AI talent surge to accelerate the placement of key AI and AI-enabling talent in high-priority areas and to advance agencies’ data and technology strategies.\n",
      "\n",
      "(d) To meet the critical hiring need for qualified personnel to execute the initiatives in this order, and to improve Federal hiring practices for AI talent, the Director of OPM, in consultation with the Director of OMB, shall:\n",
      "\n",
      "(i) within 60 days of the date of this order, conduct an evidence-based review on the need for hiring and workplace flexibility, including Federal Government-wide direct-hire authority for AI and related data-science and technical roles, and, where the Director of OPM finds such authority is appropriate, grant it; this review shall include the following job series at all General Schedule (GS) levels: IT Specialist (2210), Computer Scientist (1550), Computer Engineer (0854), and Program Analyst (0343) focused on AI, and any subsequently developed job series derived from these job series;\n",
      "\n",
      "(ii) within 60 days of the date of this order, consider authorizing the use of excepted service appointments under 5 C.F.R. 213.3102(i)(3) to address the need for hiring additional staff to implement directives of this order;\n",
      "\n",
      "(iii) within 90 days of the date of this order, coordinate a pooled-hiring action informed by subject-matter experts and using skills-based assessments to support the recruitment of AI talent across agencies;\n",
      "\n",
      "(iv) within 120 days of the date of this order, as appropriate and permitted by law, issue guidance for agency application of existing pay flexibilities or incentive pay programs for AI, AI-enabling, and other key technical positions to facilitate appropriate use of current pay incentives;\n",
      "\n",
      "(v) within 180 days of the date of this order, establish guidance and policy on skills-based, Federal Government-wide hiring of AI, data, and technology talent in order to increase access to those with nontraditional academic backgrounds to Federal AI, data, and technology roles;\n",
      "\n",
      "(vi) within 180 days of the date of this order, establish an interagency working group, staffed with both human-resources professionals and recruiting technical experts, to facilitate Federal Government-wide hiring of people with AI and other technical skills;\n",
      "\n",
      "(vii) within 180 days of the date of this order, review existing Executive Core Qualifications (ECQs) for Senior Executive Service (SES) positions informed by data and AI literacy competencies and, within 365 days of the date of this order, implement new ECQs as appropriate in the SES assessment process;\n",
      "\n",
      "(viii) within 180 days of the date of this order, complete a review of competencies for civil engineers (GS-0810 series) and, if applicable, other related occupations, and make recommendations for ensuring that adequate AI expertise and credentials in these occupations in the Federal Government reflect the increased use of AI in critical infrastructure; and\n",
      "\n",
      "(ix) work with the Security, Suitability, and Credentialing Performance Accountability Council to assess mechanisms to streamline and accelerate personnel-vetting requirements, as appropriate, to support AI and fields related to other critical and emerging technologies.\n",
      "\n",
      "(e) To expand the use of special authorities for AI hiring and retention, agencies shall use all appropriate hiring authorities, including Schedule A(r) excepted service hiring and direct-hire authority, as applicable and appropriate, to hire AI talent and AI-enabling talent rapidly. In addition to participating in OPM-led pooled hiring actions, agencies shall collaborate, where appropriate, on agency-led pooled hiring under the Competitive Service Act of 2015 (Public Law 114-137) and other shared hiring. Agencies shall also, where applicable, use existing incentives, pay-setting authorities, and other compensation flexibilities, similar to those used for cyber and information technology positions, for AI and data-science professionals, as well as plain-language job titles, to help recruit and retain these highly skilled professionals. Agencies shall ensure that AI and other related talent needs (such as technology governance and privacy) are reflected in strategic workforce planning and budget formulation.\n",
      "\n",
      "(f) To facilitate the hiring of data scientists, the Chief Data Officer Council shall develop a position-description library for data scientists (job series 1560) and a hiring guide to support agencies in hiring data scientists.\n",
      "\n",
      "(g) To help train the Federal workforce on AI issues, the head of each agency shall implement — or increase the availability and use of — AI training and familiarization programs for employees, managers, and leadership in technology as well as relevant policy, managerial, procurement, regulatory, ethical, governance, and legal fields. Such training programs should, for example, empower Federal employees, managers, and leaders to develop and maintain an operating knowledge of emerging AI technologies to assess opportunities to use these technologies to enhance the delivery of services to the public, and to mitigate risks associated with these technologies. Agencies that provide professional-development opportunities, grants, or funds for their staff should take appropriate steps to ensure that employees who do not serve in traditional technical roles, such as policy, managerial, procurement, or legal fields, are nonetheless eligible to receive funding for programs and courses that focus on AI, machine learning, data science, or other related subject areas.\n",
      "\n",
      "(h) Within 180 days of the date of this order, to address gaps in AI talent for national defense, the Secretary of Defense shall submit a report to the President through the Assistant to the President for National Security Affairs that includes:\n",
      "\n",
      "(i) recommendations to address challenges in the Department of Defense’s ability to hire certain noncitizens, including at the Science and Technology Reinvention Laboratories;\n",
      "\n",
      "(ii) recommendations to clarify and streamline processes for accessing classified information for certain noncitizens through Limited Access Authorization at Department of Defense laboratories;\n",
      "\n",
      "(iii) recommendations for the appropriate use of enlistment authority under 10 U.S.C. 504(b)(2) for experts in AI and other critical and emerging technologies; and\n",
      "\n",
      "(iv) recommendations for the Department of Defense and the Department of Homeland Security to work together to enhance the use of appropriate authorities for the retention of certain noncitizens of vital importance to national security by the Department of Defense and the Department of Homeland Security.\n",
      "\n",
      "Sec. 11. Strengthening American Leadership Abroad. (a) To strengthen United States leadership of global efforts to unlock AI’s potential and meet its challenges, the Secretary of State, in coordination with the Assistant to the President for National Security Affairs, the Assistant to the President for Economic Policy, the Director of OSTP, and the heads of other relevant agencies as appropriate, shall:\n",
      "\n",
      "(i) lead efforts outside of military and intelligence areas to expand engagements with international allies and partners in relevant bilateral, multilateral, and multi-stakeholder fora to advance those allies’ and partners’ understanding of existing and planned AI-related guidance and policies of the United States, as well as to enhance international collaboration; and\n",
      "\n",
      "(ii) lead efforts to establish a strong international framework for managing the risks and harnessing the benefits of AI, including by encouraging international allies and partners to support voluntary commitments similar to those that United States companies have made in pursuit of these objectives and coordinating the activities directed by subsections (b), (c), (d), and (e) of this section, and to develop common regulatory and other accountability principles for foreign nations, including to manage the risk that AI systems pose.\n",
      "\n",
      "(b) To advance responsible global technical standards for AI development and use outside of military and intelligence areas, the Secretary of Commerce, in coordination with the Secretary of State and the heads of other relevant agencies as appropriate, shall lead preparations for a coordinated effort with key international allies and partners and with standards development organizations, to drive the development and implementation of AI-related consensus standards, cooperation and coordination, and information sharing. In particular, the Secretary of Commerce shall:\n",
      "\n",
      "(i) within 270 days of the date of this order, establish a plan for global engagement on promoting and developing AI standards, with lines of effort that may include:\n",
      "\n",
      "(A) AI nomenclature and terminology;\n",
      "\n",
      "(B) best practices regarding data capture, processing, protection, privacy, confidentiality, handling, and analysis;\n",
      "\n",
      "(C) trustworthiness, verification, and assurance of AI systems; and\n",
      "\n",
      "(D) AI risk management;\n",
      "\n",
      "(ii) within 180 days of the date the plan is established, submit a report to the President on priority actions taken pursuant to the plan; and\n",
      "\n",
      "(iii) ensure that such efforts are guided by principles set out in the NIST AI Risk Management Framework and United States Government National Standards Strategy for Critical and Emerging Technology.\n",
      "\n",
      "(c) Within 365 days of the date of this order, to promote safe, responsible, and rights-affirming development and deployment of AI abroad:\n",
      "\n",
      "(i) The Secretary of State and the Administrator of the United States Agency for International Development, in coordination with the Secretary of Commerce, acting through the director of NIST, shall publish an AI in Global Development Playbook that incorporates the AI Risk Management Framework’s principles, guidelines, and best practices into the social, technical, economic, governance, human rights, and security conditions of contexts beyond United States borders. As part of this work, the Secretary of State and the Administrator of the United States Agency for International Development shall draw on lessons learned from programmatic uses of AI in global development.\n",
      "\n",
      "(ii) The Secretary of State and the Administrator of the United States Agency for International Development, in collaboration with the Secretary of Energy and the Director of NSF, shall develop a Global AI Research Agenda to guide the objectives and implementation of AI-related research in contexts beyond United States borders. The Agenda shall:\n",
      "\n",
      "(A) include principles, guidelines, priorities, and best practices aimed at ensuring the safe, responsible, beneficial, and sustainable global development and adoption of AI; and\n",
      "\n",
      "(B) address AI’s labor-market implications across international contexts, including by recommending risk mitigations.\n",
      "\n",
      "(d) To address cross-border and global AI risks to critical infrastructure, the Secretary of Homeland Security, in coordination with the Secretary of State, and in consultation with the heads of other relevant agencies as the Secretary of Homeland Security deems appropriate, shall lead efforts with international allies and partners to enhance cooperation to prevent, respond to, and recover from potential critical infrastructure disruptions resulting from incorporation of AI into critical infrastructure systems or malicious use of AI.\n",
      "\n",
      "(i) Within 270 days of the date of this order, the Secretary of Homeland Security, in coordination with the Secretary of State, shall develop a plan for multilateral engagements to encourage the adoption of the AI safety and security guidelines for use by critical infrastructure owners and operators developed in section 4.3(a) of this order.\n",
      "\n",
      "(ii) Within 180 days of establishing the plan described in subsection (d)(i) of this section, the Secretary of Homeland Security shall submit a report to the President on priority actions to mitigate cross-border risks to critical United States infrastructure.\n",
      "\n",
      "Sec. 12. Implementation. (a) There is established, within the Executive Office of the President, the White House Artificial Intelligence Council (White House AI Council). The function of the White House AI Council is to coordinate the activities of agencies across the Federal Government to ensure the effective formulation, development, communication, industry engagement related to, and timely implementation of AI-related policies, including policies set forth in this order.\n",
      "\n",
      "(b) The Assistant to the President and Deputy Chief of Staff for Policy shall serve as Chair of the White House AI Council.\n",
      "\n",
      "(c) In addition to the Chair, the White House AI Council shall consist of the following members, or their designees:\n",
      "\n",
      "(i) the Secretary of State;\n",
      "\n",
      "(ii) the Secretary of the Treasury;\n",
      "\n",
      "(iii) the Secretary of Defense;\n",
      "\n",
      "(iv) the Attorney General;\n",
      "\n",
      "(v) the Secretary of Agriculture;\n",
      "\n",
      "(vi) the Secretary of Commerce;\n",
      "\n",
      "(vii) the Secretary of Labor;\n",
      "\n",
      "(viii) the Secretary of HHS;\n",
      "\n",
      "(ix) the Secretary of Housing and Urban Development;\n",
      "\n",
      "(x) the Secretary of Transportation;\n",
      "\n",
      "(xi) the Secretary of Energy;\n",
      "\n",
      "(xii) the Secretary of Education;\n",
      "\n",
      "(xiii) the Secretary of Veterans Affairs;\n",
      "\n",
      "(xiv) the Secretary of Homeland Security;\n",
      "\n",
      "(xv) the Administrator of the Small Business Administration;\n",
      "\n",
      "(xvi) the Administrator of the United States Agency for International Development;\n",
      "\n",
      "(xvii) the Director of National Intelligence;\n",
      "\n",
      "(xviii) the Director of NSF;\n",
      "\n",
      "(xix) the Director of OMB;\n",
      "\n",
      "(xx) the Director of OSTP;\n",
      "\n",
      "(xxi) the Assistant to the President for National Security Affairs;\n",
      "\n",
      "(xxii) the Assistant to the President for Economic Policy;\n",
      "\n",
      "(xxiii) the Assistant to the President and Domestic Policy Advisor;\n",
      "\n",
      "(xxiv) the Assistant to the President and Chief of Staff to the Vice President;\n",
      "\n",
      "(xxv) the Assistant to the President and Director of the Gender Policy Council;\n",
      "\n",
      "(xxvi) the Chairman of the Council of Economic Advisers;\n",
      "\n",
      "(xxvii) the National Cyber Director;\n",
      "\n",
      "(xxviii) the Chairman of the Joint Chiefs of Staff; and\n",
      "\n",
      "(xxix) the heads of such other agencies, independent regulatory agencies, and executive offices as the Chair may from time to time designate or invite to participate.\n",
      "\n",
      "(d) The Chair may create and coordinate subgroups consisting of White House AI Council members or their designees, as appropriate.\n",
      "\n",
      "Sec. 13. General Provisions. (a) Nothing in this order shall be construed to impair or otherwise affect:\n",
      "\n",
      "(i) the authority granted by law to an executive department or agency, or the head thereof; or\n",
      "\n",
      "(ii) the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals.\n",
      "\n",
      "(b) This order shall be implemented consistent with applicable law and subject to the availability of appropriations. (c) This order is not intended to, and does not, create any right or benefit, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person.\n",
      "\n",
      "JOSEPH R. BIDEN JR.\n",
      "\n",
      "THE WHITE HOUSE, October 30, 2023.\n",
      "\n",
      "\n",
      "\n",
      "Stay Connected\n",
      "\n",
      "Opt in to send and receive text messages from President Biden.\n",
      "\n",
      "Share\n",
      "\n",
      "Share this page on Facebook\n",
      "\n",
      "Share this page on Twitter\n",
      "\n",
      "https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/?utm_source=link \n",
      "\n",
      "Metadata: {'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\white_house_executive_order_nov_2023.html'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "path_to_html = r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\white_house_executive_order_nov_2023.html\"\n",
    "\n",
    "html_loader = UnstructuredHTMLLoader(file_path=path_to_html, encoding='utf-8')\n",
    "documents = html_loader.load()\n",
    "\n",
    "print(\"Content: \", documents[0].page_content, \"\\n\")\n",
    "print(\"Metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b43091",
   "metadata": {},
   "source": [
    "## ⭐Text Splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d4b9a",
   "metadata": {},
   "source": [
    "Split large documents into smaller chunks for effective embedding and retrieval.\n",
    "\n",
    "```python \n",
    "from langchain_text_splitters import (\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTextSplitter,\n",
    "    SpacyTextSplitter,\n",
    "    NLTKTextSplitter,\n",
    "    MarkdownTextSplitter,\n",
    "    HTMLTextSplitter,\n",
    "    LatexTextSplitter,\n",
    "    JSONTextSplitter\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0c01930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 323, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning is a fascinating field.\\n    It involves algorithms and models that can learn from data.\\n    These models can then make predictions or decisions without \\n    being explicitly programmed to perform the task.\\n    This capability is increasingly valuable in \\n    various industries, from finance to healthcare.', 'There are many types of machine learning, \\n    including supervised, unsupervised, and reinforcement learning.\\n    Each type has its own \\n    strengths and applications.']\n",
      "[323, 169]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text = \"\"\"Machine learning is a fascinating field.\n",
    "    It involves algorithms and models that can learn from data.\n",
    "    These models can then make predictions or decisions without \n",
    "    being explicitly programmed to perform the task.\n",
    "    This capability is increasingly valuable in \n",
    "    various industries, from finance to healthcare.\n",
    "\n",
    "    There are many types of machine learning, \n",
    "    including supervised, unsupervised, and reinforcement learning.\n",
    "    Each type has its own \n",
    "    strengths and applications.\"\"\"\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "print(chunks)\n",
    "print([len(chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30e8ae",
   "metadata": {},
   "source": [
    "- `\"\\n\\n\"` (Double Newline) –> First, the text is split at paragraph breaks (double newlines), keeping sections intact.\n",
    "- `\"\\n\"` (Single Newline) –> If chunks are still too large, the splitter moves to sentence-level splitting.\n",
    "- `\" \"` (Space) –> If the previous splits are insufficient, it breaks at word boundaries.\n",
    "- `\"\"` (Empty String) –> As a last resort, it splits character-by-character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62f77dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning is a fascinating field.', 'It involves algorithms and models that can learn from data.', 'These models can then make predictions or decisions without', 'being explicitly programmed to perform the task.', 'This capability is increasingly valuable in', 'various industries, from finance to healthcare.', 'There are many types of machine learning,', 'including supervised, unsupervised, and reinforcement learning.\\n    Each type has its own', 'strengths and applications.']\n",
      "[40, 59, 59, 48, 43, 47, 41, 89, 27]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)\n",
    "print(chunks)\n",
    "print([len(chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bb7b21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 0, 'page_label': '1'}, page_content=\"Retrieval Argument Generation: Enhancing Language Model \\n Capabilities Through External Knowledge Integration \\n 1. Introduction to Retrieval Argument Generation (RAG) \\n Retrieval-Augmented Generation (RAG) represents a paradigm shift in how large \\n language models (LLMs) operate, moving beyond the constraints of their pre-trained \\n knowledge by incorporating information from external, authoritative knowledge bases \\n during the response generation process.  1  This  technique fundamentally optimizes the \\n output of LLMs, ensuring that the generated content is not solely reliant on the \\n model's internal parameters but is also grounded in a broader, often more current and \\n specific, set of information.  1  In the realm of natural  language processing (NLP), RAG \\n serves as a powerful tool to enhance text generation by seamlessly integrating data \\n from diverse knowledge repositories, including databases, digital asset libraries, and\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 0, 'page_label': '1'}, page_content=\"serves as a powerful tool to enhance text generation by seamlessly integrating data \\n from diverse knowledge repositories, including databases, digital asset libraries, and \\n comprehensive document repositories.  3  This architectural  pattern within generative AI \\n is specifically designed to elevate the accuracy and relevance of LLM responses by \\n dynamically retrieving pertinent external data precisely when a user issues a prompt.  4 \\n At its core, RAG is an advanced artificial intelligence (AI) technique that masterfully \\n combines the strengths of information retrieval and text generation.  5  This synergistic \\n approach empowers AI models to access and retrieve relevant information from a \\n multitude of knowledge sources and subsequently incorporate this retrieved \\n information directly into the text they generate.  5  Functioning  as an AI framework, \\n RAG's primary aim is to ground LLMs on the most accurate and up-to-date\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 0, 'page_label': '1'}, page_content=\"information directly into the text they generate.  5  Functioning  as an AI framework, \\n RAG's primary aim is to ground LLMs on the most accurate and up-to-date \\n information available within an external knowledge base.  7  This not only improves the \\n factual correctness of the generated content but also provides users with valuable \\n insight into the generative process undertaken by the LLM.  7  By modifying the \\n standard interaction with an LLM, RAG ensures that the model's responses are \\n formulated with direct reference to a specified set of documents, effectively \\n supplementing the information gleaned from its initial training data.  8  This capability is \\n particularly significant as it allows LLMs to leverage domain-specific and recently \\n updated information without requiring a complete model retraining.  8  As a technique, \\n RAG is instrumental in enhancing the overall accuracy and reliability of generative AI\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 0, 'page_label': '1'}, page_content='updated information without requiring a complete model retraining.  8  As a technique, \\n RAG is instrumental in enhancing the overall accuracy and reliability of generative AI \\n models by equipping them with the ability to draw upon specific and relevant data \\n sources.  9 \\n From a machine learning perspective, Retrieval Augmented Generation is a \\n sophisticated technique that harmoniously blends retrieval-based methodologies with \\n generative models.  10  Its application is particularly  prominent within Natural Language \\n Processing (NLP), where it serves to significantly enhance the capabilities of large'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 1, 'page_label': '2'}, page_content='language models (LLMs).  10  RAG achieves this by first fetching relevant documents or \\n precise data snippets in direct response to user queries, and then intelligently utilizing \\n this retrieved information to generate outputs that are not only more accurate but also \\n remarkably contextually relevant.  10  This hybrid approach  strategically employs a \\n retriever model to efficiently sift through vast external data sources and a generator \\n model that skillfully processes the retrieved information to construct coherent and \\n informative responses.  10  In essence, RAG acts as a  smart AI technique that effectively \\n combines the functionalities of a highly skilled information retriever with the creative \\n power of a text generator.  6  This allows LLMs to access and  incorporate real-time, \\n niche data from external sources, thereby substantially enhancing their capacity to \\n deliver accurate and detailed responses.  12  In an architectural  context, RAG can be'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 1, 'page_label': '2'}, page_content='niche data from external sources, thereby substantially enhancing their capacity to \\n deliver accurate and detailed responses.  12  In an architectural  context, RAG can be \\n viewed as an enhancement to the fundamental capabilities of an LLM, such as \\n ChatGPT, by integrating an information retrieval system that provides essential \\n grounding data for the generation process.  14  This architectural  approach significantly \\n improves the efficacy of LLM applications by enabling them to leverage custom data, \\n retrieving pertinent documents or data and providing them as contextual input for the \\n LLM.  15  Furthermore, RAG represents a powerful  natural language processing \\n technique that effectively merges the strengths of both retrieval-based and \\n generative models, utilizing information from a database or a comprehensive \\n knowledge base to enrich the context and improve the accuracy of the generated'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 1, 'page_label': '2'}, page_content=\"generative models, utilizing information from a database or a comprehensive \\n knowledge base to enrich the context and improve the accuracy of the generated \\n text.  16  By leveraging a database to fetch the most contextually  relevant results that \\n directly match a user's query at the precise moment of generation, RAG significantly \\n enhances the performance and accuracy of Generative AI applications.  13  As a \\n powerful technique, RAG enhances language models by seamlessly combining them \\n with external knowledge bases, retrieving relevant information and incorporating it \\n directly into the model's prompt to guide the generation of more informed \\n responses.  17  Finally, RAG effectively combines an information  retrieval component with \\n a sophisticated text generator model, enabling a system to achieve greater factual \\n consistency and overall reliability in its outputs.  11 \\n ●  Insight 1:  The fundamental principle underpinning  Retrieval Argument Generation\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 1, 'page_label': '2'}, page_content='consistency and overall reliability in its outputs.  11 \\n ●  Insight 1:  The fundamental principle underpinning  Retrieval Argument Generation \\n is its capacity to overcome the inherent limitations of LLMs, particularly their \\n reliance on fixed training datasets, by providing them with dynamic access to \\n external, up-to-date, and domain-specific information at the crucial moment of \\n response generation. This innovative hybrid approach is designed to produce \\n outputs that are not only more accurate and relevant but also significantly more \\n trustworthy due to their grounding in verifiable external sources.  1  The evolution of \\n RAG techniques reflects a growing understanding of how to best integrate \\n retrieval and generation for optimal performance in various applications.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 2, 'page_label': '3'}, page_content='●  The motivation behind RAG and its significance: \\n ○  The impetus behind the development of RAG stems from the inherent \\n limitations of LLMs, which can sometimes present inaccurate information \\n when they lack specific knowledge, provide outdated or overly generic \\n responses when users expect current and precise details, and even generate \\n content based on non-authoritative sources.  2  These shortcomings in \\n standalone LLMs underscore the critical need for mechanisms that can \\n augment their knowledge and improve the reliability of their outputs. \\n ○  RAG emerges as a direct response to these challenges, offering a \\n sophisticated approach that redirects the LLM to actively retrieve relevant \\n information from carefully selected, authoritative knowledge sources.  2  This \\n process not only grants organizations greater control over the content \\n generated by their AI systems but also provides users with valuable insights'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 2, 'page_label': '3'}, page_content=\"process not only grants organizations greater control over the content \\n generated by their AI systems but also provides users with valuable insights \\n into the very process by which the LLM formulates its responses.  2 \\n ○  A significant motivation for using RAG is its ability to extend the already \\n considerable capabilities of LLMs to encompass specific domains or an \\n organization's unique internal knowledge base, all without necessitating the \\n computationally intensive and time-consuming process of retraining the entire \\n model.  2  This adaptability makes LLMs far more versatile  and applicable to a \\n wider range of specialized tasks. \\n ○  RAG empowers LLMs to build upon a specialized and curated body of \\n knowledge, enabling them to answer questions with a much higher degree of \\n accuracy and relevance compared to relying solely on their broad, general \\n training.  7  This targeted knowledge access is particularly  beneficial in domains \\n requiring deep expertise.\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 2, 'page_label': '3'}, page_content=\"accuracy and relevance compared to relying solely on their broad, general \\n training.  7  This targeted knowledge access is particularly  beneficial in domains \\n requiring deep expertise. \\n ○  By incorporating information retrieval as a crucial step before generating \\n responses, RAG significantly improves the performance of large language \\n models (LLMs).  8  Unlike traditional LLMs  that are confined to their static \\n training data, RAG actively seeks out and pulls relevant text from a variety of \\n sources, including databases, uploaded documents, and even the vast \\n expanse of the web.  8 \\n ○  This dynamic retrieval capability is instrumental in mitigating the pervasive \\n issue of AI hallucinations, where chatbots might fabricate policies or legal AIs \\n might cite non-existent legal precedents.  8  By grounding  the LLM's responses \\n in verifiable external information, RAG significantly reduces the likelihood of \\n such inaccuracies.\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 2, 'page_label': '3'}, page_content=\"might cite non-existent legal precedents.  8  By grounding  the LLM's responses \\n in verifiable external information, RAG significantly reduces the likelihood of \\n such inaccuracies. \\n ○  The dynamic nature of RAG allows AI systems to provide more accurate and \\n contextually appropriate responses without the need for frequent and costly \\n retraining of the entire underlying model.  8  This  adaptability is a key advantage\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 3, 'page_label': '4'}, page_content='in rapidly evolving information landscapes. \\n ○  Fundamentally, RAG provides a robust solution for generating text that is not \\n only fluent and natural-sounding but also demonstrably factually accurate \\n and rich in relevant information.  5  This dual  benefit addresses a core challenge \\n in the field of natural language generation. \\n ○  RAG directly tackles the inherent information capacity limitations of traditional \\n Language Models (LLMs).  6  While LLMs possess  a form of internal memory \\n derived from their training data, often referred to as \"Parametric memory,\" \\n RAG introduces a complementary \"Non-Parametric memory\" by enabling \\n them to tap into and utilize external knowledge sources.  6  This expansion of \\n accessible knowledge significantly enhances the LLM\\'s ability to handle a \\n wider range of queries and topics. \\n ○  In today\\'s dynamic information landscape, RAG is significant because it \\n provides GenAI applications with access to the most up-to-date information'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 3, 'page_label': '4'}, page_content=\"wider range of queries and topics. \\n ○  In today's dynamic information landscape, RAG is significant because it \\n provides GenAI applications with access to the most up-to-date information \\n available in the world, as well as highly specific data relevant to particular \\n domains.  13  This ensures that AI-driven systems  can provide timely and \\n accurate responses based on the latest available knowledge. \\n ○  The core significance of RAG lies in its ability to overcome the intrinsic \\n information capacity constraints of conventional Language Models (LLMs).  6 \\n By augmenting their parametric memory with access to external knowledge, \\n RAG enables LLMs to generate responses that are not only more informed but \\n also more contextually relevant. \\n ○  Ultimately, RAG is a powerful technique that significantly enhances the \\n capabilities and reliability of AI systems by effectively bridging the gap \\n between the vast general knowledge encoded within language models and\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 3, 'page_label': '4'}, page_content='capabilities and reliability of AI systems by effectively bridging the gap \\n between the vast general knowledge encoded within language models and \\n the need for dynamic, targeted information retrieval from external sources.  17 \\n This capability makes AI systems powered by RAG far more versatile and \\n dependable for a wide array of knowledge-intensive applications. \\n ○  The method of Retrieval Augmented Generation enables greater factual \\n consistency in generated text, improves the overall reliability of the responses, \\n and effectively helps to mitigate the persistent problem of \"hallucination\" in \\n language models.  18  These improvements are  crucial for building trust and \\n ensuring the practical utility of LLMs in real-world scenarios. \\n ○  Insight 2:  The primary driving force behind the  development and adoption of \\n RAG is the critical need to enhance the reliability and trustworthiness of LLM \\n outputs by firmly grounding them in verifiable and current data. This is'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 3, 'page_label': '4'}, page_content=\"RAG is the critical need to enhance the reliability and trustworthiness of LLM \\n outputs by firmly grounding them in verifiable and current data. This is \\n particularly vital in enterprise environments and specialized domains where \\n accuracy and access to proprietary or rapidly changing information are of \\n paramount importance. By addressing the limitations of LLMs' static\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 4, 'page_label': '5'}, page_content=\"knowledge and tendency to hallucinate, RAG significantly expands the range \\n of applications for which these powerful models can be confidently deployed. \\n 2. Architecture and Workflow of a Typical RAG System \\n ●  Detailed explanation of the retrieval component: \\n ○  At the heart of a RAG system lies an information retrieval component that is \\n activated by user input to fetch relevant information from external data \\n sources.  2  This initial step is crucial for providing  the LLM with the necessary \\n context to generate an informed response. \\n ○  This retrieval process often employs semantic search techniques to identify \\n documents that are relevant to the user's query, drawing from a variety of \\n knowledge sources such as cloud data storage and other digital repositories.  3 \\n Semantic search is particularly effective as it goes beyond simple keyword \\n matching to understand the underlying meaning and intent of the query.\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 4, 'page_label': '5'}, page_content=\"Semantic search is particularly effective as it goes beyond simple keyword \\n matching to understand the underlying meaning and intent of the query. \\n ○  To facilitate this search, the user's query is typically transformed into a vector \\n representation, which is then compared against vector databases containing \\n similar representations of the knowledge base.  2  This vectorization process \\n allows for efficient similarity-based searching, enabling the system to quickly \\n identify semantically related information. \\n ○  The creation of these vector representations, often performed by embedding \\n language models, effectively transforms the raw data into a format that \\n generative AI models can understand and process.  2  This knowledge library, \\n usually residing in a vector database, serves as the external memory for the \\n LLM. \\n ○  The determination of relevance during the retrieval phase is achieved through \\n sophisticated mathematical calculations involving these vector\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 4, 'page_label': '5'}, page_content=\"LLM. \\n ○  The determination of relevance during the retrieval phase is achieved through \\n sophisticated mathematical calculations involving these vector \\n representations.  2  These calculations allow  the system to quantify the degree \\n of semantic similarity between the user's query and the documents in the \\n knowledge base. \\n ○  Many RAG systems leverage a combination of both vector search and \\n traditional semantic search methods to maximize the likelihood of retrieving \\n the most precise and contextually appropriate answers to user queries.  4  For \\n instance, platforms like MongoDB's Atlas Search Index support both \\n approaches, allowing for a more comprehensive search of unstructured data. \\n ○  The retrieval model within a RAG system can be conceptualized as a \\n specialized 'librarian' whose primary function is to efficiently locate and pull in \\n relevant information from a vast database or a comprehensive corpus of\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 4, 'page_label': '5'}, page_content=\"specialized 'librarian' whose primary function is to efficiently locate and pull in \\n relevant information from a vast database or a comprehensive corpus of \\n documents in response to a user's request.  5  This analogy helps to illustrate \\n the targeted nature of the retrieval process.\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 5, 'page_label': '6'}, page_content=\"○  During the retrieval phase, sophisticated algorithms are employed to search \\n through the knowledge base and retrieve specific snippets of information that \\n are deemed most relevant to the user's prompt or question.  7  The \\n effectiveness of these algorithms is paramount to the overall performance of \\n the RAG system. \\n ○  The sources of these retrieved facts can vary depending on the application. In \\n open-domain settings, such as consumer-facing applications, the information \\n might be drawn from the vast indexed content of the internet. Conversely, in \\n closed-domain, enterprise environments, the retrieval is typically confined to \\n a more restricted and curated set of sources to ensure added security and \\n reliability of the information.  7 \\n ○  To enable this precise retrieval, LLMs are often enhanced with embedding and \\n reranking models. The knowledge base itself is stored in a vector database,\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 5, 'page_label': '6'}, page_content=\"reliability of the information.  7 \\n ○  To enable this precise retrieval, LLMs are often enhanced with embedding and \\n reranking models. The knowledge base itself is stored in a vector database, \\n optimized for the efficient retrieval of information based on query similarity.  9 \\n The embedding model plays a crucial role in converting both the query and \\n the documents into comparable vector representations. \\n ○  As a fundamental step in the RAG pipeline, the retrieval system is tasked with \\n searching for and identifying relevant information from the knowledge base \\n that directly corresponds to the user's input query.  17  The accuracy of this \\n search is critical for the subsequent generation of a helpful response. \\n ○  The hybrid nature of RAG often involves a dedicated retriever model that is \\n designed to sift through the external data sources, effectively filtering out \\n irrelevant information and identifying the most pertinent content to the user's\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 5, 'page_label': '6'}, page_content=\"designed to sift through the external data sources, effectively filtering out \\n irrelevant information and identifying the most pertinent content to the user's \\n query.  10  This targeted sifting process is essential  for providing the LLM with \\n focused and useful context. \\n ○  The retrieval component often leverages both vector search, which compares \\n the semantic meaning of the query and documents as captured in vectors, \\n and traditional semantic search techniques to ensure a high likelihood of \\n finding the most precise and contextually appropriate answers for the user.  4 \\n This dual approach enhances the robustness of the retrieval process. \\n ○  In the context of enterprise applications, the retrieval component specifically \\n searches through the organization's proprietary data sources to locate and \\n retrieve relevant documents or specific text segments that align with the \\n user's input query or the current conversational context.  30  This capability is\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 5, 'page_label': '6'}, page_content=\"retrieve relevant documents or specific text segments that align with the \\n user's input query or the current conversational context.  30  This capability is \\n vital for accessing internal knowledge and data. \\n ○  The overall quality and accuracy of the final response generated by a RAG \\n system are directly influenced by the quality of the data retrieved during this \\n initial phase.  10  If the retrieval mechanism fails to  identify and fetch the most \\n relevant information, the subsequent steps will be compromised.\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 6, 'page_label': '7'}, page_content=\"○  Therefore, the retrieval process is typically optimized to not only find \\n information that closely matches the user's query but also to prioritize \\n information that originates from credible and authoritative sources.  10  This \\n focus on source credibility helps to ensure the reliability of the retrieved \\n context. \\n ○  A key aspect of the retrieval process is the use of semantic search, which \\n aims to understand and deliver results that align with the user's underlying \\n intent, rather than simply matching keywords in their query.  13  This ability to \\n interpret the meaning behind the words is what makes semantic search so \\n powerful in RAG systems. \\n ○  To achieve precise query retrieval, LLMs in RAG systems are often enhanced \\n with sophisticated embedding and reranking models. These models work \\n together to store knowledge in a vector database, allowing for efficient and \\n accurate retrieval of information based on the semantic similarity between the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 6, 'page_label': '7'}, page_content='together to store knowledge in a vector database, allowing for efficient and \\n accurate retrieval of information based on the semantic similarity between the \\n query and the stored data.  9 \\n ○  The embedding model plays a critical role by comparing the numerical \\n representations (vectors) of the query with the vectors stored in a \\n machine-readable index of the available knowledge base.  9  This comparison is \\n the basis for identifying relevant matches. \\n ○  Once a match, or multiple matches, are identified, the retrieval component \\n fetches the corresponding data, converts it back into human-readable words, \\n and then passes this information on to the LLM for the generation of the final \\n response.  9  This marks the transition from the  retrieval to the generation phase \\n of the RAG workflow. \\n ●  Insight 3:  The retrieval component is the foundational  element of a RAG system, \\n acting as a sophisticated information seeker that leverages techniques such as'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 6, 'page_label': '7'}, page_content=\"of the RAG workflow. \\n ●  Insight 3:  The retrieval component is the foundational  element of a RAG system, \\n acting as a sophisticated information seeker that leverages techniques such as \\n semantic search and vector embeddings to accurately identify and fetch the most \\n relevant information from the knowledge base in response to a user's query. The \\n efficiency and precision of this stage are paramount, as they directly dictate the \\n quality and relevance of the context provided to the LLM for generating the final \\n response. The selection of appropriate embedding models, vector databases, and \\n search strategies are critical design considerations that significantly impact the \\n overall performance of the RAG system. \\n ●  Detailed explanation of the generation component: \\n ○  Following the retrieval of relevant information, the generation component \\n takes over, combining this newly acquired data with the LLM's pre-existing\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 6, 'page_label': '7'}, page_content=\"○  Following the retrieval of relevant information, the generation component \\n takes over, combining this newly acquired data with the LLM's pre-existing \\n knowledge to create a more informative and contextually rich prompt.  2  This \\n augmentation of the prompt is a key step in guiding the LLM towards \\n generating a more accurate and relevant answer.\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 7, 'page_label': '8'}, page_content=\"○  The LLM then utilizes its inherent understanding of language, coupled with \\n the information extracted from the retrieved documents, to generate a \\n comprehensive and contextually appropriate answer to the user's initial \\n query.  2  This stage showcases the LLM's ability  to synthesize information from \\n diverse sources. \\n ○  The RAG system meticulously combines the vector embeddings of the \\n retrieved information with the original user query, effectively augmenting the \\n query with additional context. This enhanced prompt is then passed to the \\n LLM, which leverages this enriched input to generate a natural-language \\n response tailored to the user's needs.  4 \\n ○  Ultimately, the LLM integrates the retrieved information, now in \\n human-readable form, with its own internal knowledge and response to the \\n query, culminating in a final answer presented to the user. Importantly, this \\n final response may also include citations to the sources from which the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 7, 'page_label': '8'}, page_content=\"query, culminating in a final answer presented to the user. Importantly, this \\n final response may also include citations to the sources from which the \\n retrieved information was obtained, enhancing transparency and verifiability.  9 \\n ○  A crucial part of the RAG system is the generator model, which is responsible \\n for processing the retrieved information and constructing a coherent and \\n relevant response to the user's query.  10  The effectiveness  of this model in \\n synthesizing the retrieved data is critical. \\n ○  The augmented prompt, now enriched with valuable information from the \\n external knowledge base, is then delivered to the generative model, typically \\n an LLM. This model then synthesizes its own internal knowledge with the \\n newly retrieved data to produce a final response that directly addresses the \\n user's query.  12 \\n ○  The LLMs then utilize the retrieved data as a foundation to craft responses\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 7, 'page_label': '8'}, page_content=\"newly retrieved data to produce a final response that directly addresses the \\n user's query.  12 \\n ○  The LLMs then utilize the retrieved data as a foundation to craft responses \\n that are specifically tailored to the user's query and the provided context.  19 \\n This ensures that the generated answers are well-informed and relevant. \\n ○  A key step in the RAG pipeline is the incorporation of the retrieved information \\n directly into the prompt that is sent to the LLM.  17  This integration provides the \\n LLM with the necessary context to formulate an appropriate response. \\n ○  In many RAG implementations, the retrieved documents are simply \\n concatenated and appended to the original input prompt. This combined \\n input is then fed into the text generator, which is responsible for producing \\n the final output based on both the original query and the added contextual \\n information.  18 \\n ○  The generator model plays a vital role in refining or expanding upon the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 7, 'page_label': '8'}, page_content='the final output based on both the original query and the added contextual \\n information.  18 \\n ○  The generator model plays a vital role in refining or expanding upon the \\n retrieved information, ensuring that the final response is not only accurate but \\n also contextually appropriate and fluent in its language.  11  This refinement \\n process adds significant value to the output.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 8, 'page_label': '9'}, page_content=\"○  In some RAG architectures, a reader component is employed to process the \\n retrieved documents, extracting the most pertinent information which is then \\n used by the language model during the generation phase.  30  This extraction \\n step helps to focus the LLM on the most relevant parts of the retrieved \\n context. \\n ●  Insight 4:  The generation component of a  RAG system is responsible for taking \\n the augmented prompt, which includes both the user's query and the relevant \\n information retrieved from the external knowledge base, and utilizing the LLM to \\n produce a natural language response. The LLM skillfully integrates its pre-trained \\n knowledge with the newly provided context to formulate an answer that is not \\n only accurate and relevant to the user's query but also coherent and fluent. The \\n effectiveness of this generation phase is heavily influenced by the quality of the \\n preceding retrieval step and the techniques used to incorporate the retrieved\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 8, 'page_label': '9'}, page_content=\"effectiveness of this generation phase is heavily influenced by the quality of the \\n preceding retrieval step and the techniques used to incorporate the retrieved \\n information into the prompt, often leveraging prompt engineering strategies to \\n guide the LLM in effectively utilizing the provided context. \\n ●  The data ingestion and indexing process: \\n ○  The foundation of a RAG system lies in its ability to access and process \\n external data that was not part of the LLM's original training dataset. This \\n external data can originate from a multitude of sources, including APIs, \\n various types of databases, and diverse document repositories, and may exist \\n in a wide array of formats such as simple files, structured database records, \\n or lengthy textual documents.  2  The versatility  in handling different data \\n sources is a key strength of RAG. \\n ○  To make this data accessible and searchable by generative AI models, a\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 8, 'page_label': '9'}, page_content='or lengthy textual documents.  2  The versatility  in handling different data \\n sources is a key strength of RAG. \\n ○  To make this data accessible and searchable by generative AI models, a \\n crucial step involves using embedding language models to convert the raw \\n data into numerical representations, known as embeddings. These \\n embeddings are then stored in a specialized vector database, effectively \\n creating a comprehensive knowledge library that the AI models can readily \\n understand and query.  2  This process of vectorization  is essential for efficient \\n retrieval. \\n ○  The initial stage of preparing the data involves gathering external data \\n sources, such as document repositories or APIs. The documents are then \\n typically segmented into smaller, more manageable units called chunks. These \\n chunks are subsequently passed through an embedding model to generate \\n their vector representations, which are then stored in the vector database for'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 8, 'page_label': '9'}, page_content='chunks are subsequently passed through an embedding model to generate \\n their vector representations, which are then stored in the vector database for \\n later retrieval.  4  Chunking is a common strategy to  handle the context window \\n limitations of LLMs. \\n ○  Before the external knowledge can be utilized, it must undergo a preparation \\n phase known as ingestion. During this stage, the raw external data is carefully'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 9, 'page_label': '10'}, page_content='cleaned and transformed into a format that the LLM can effectively process \\n and understand.  12  This pre-processing is  vital for ensuring data quality and \\n compatibility. \\n ○  A key part of the ingestion process is vectorization, where text or even image \\n data is transformed from its original format into embeddings. Once these \\n embeddings are generated, they are stored in a vector database, which is \\n specifically designed to allow for quick and efficient retrieval of the \\n information for various downstream tasks within the RAG pipeline.  12  The \\n choice of vector database can significantly impact retrieval performance. \\n ○  To streamline the interaction with the generative model, prompt templates are \\n often employed. These templates provide a structured framework for creating \\n standardized prompts into which various user queries and relevant contextual \\n data can be inserted. In a RAG pipeline, the retrieved data is inserted into'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 9, 'page_label': '10'}, page_content='standardized prompts into which various user queries and relevant contextual \\n data can be inserted. In a RAG pipeline, the retrieved data is inserted into \\n these prompt templates, effectively augmenting the prompt with the \\n necessary external knowledge.  12 \\n ○  For enterprise-level RAG solutions, the indexing strategies must be robust \\n enough to handle large volumes of content and to efficiently load and refresh \\n this content at the required frequency.  14  This ensures  that the knowledge base \\n remains up-to-date and scalable. \\n ○  The process of setting up the data for a RAG solution often involves utilizing \\n features provided by search engines, such as Azure AI Search, to create and \\n load an index. This index typically includes fields that either duplicate or \\n represent the content from the original data sources, making it searchable.  14 \\n ○  The initial step in a RAG pipeline involves ingesting raw data from a variety of'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 9, 'page_label': '10'}, page_content='represent the content from the original data sources, making it searchable.  14 \\n ○  The initial step in a RAG pipeline involves ingesting raw data from a variety of \\n sources, including databases, documents, and even live data feeds. To \\n prepare this data, libraries like LangChain offer document loaders that can \\n handle data in many different formats from numerous sources.  19  These \\n loaders simplify the process of bringing data into the system. \\n ○  Once the data has been processed and the embeddings have been \\n generated, they are stored in specialized vector databases. These databases \\n are specifically optimized for handling vectorized data, which enables rapid \\n and efficient search and retrieval operations when a user submits a query.  19 \\n ○  A significant challenge in optimizing RAG performance is dealing with data \\n that lacks structure or a clear format. When data is not properly formatted, it'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 9, 'page_label': '10'}, page_content=\"○  A significant challenge in optimizing RAG performance is dealing with data \\n that lacks structure or a clear format. When data is not properly formatted, it \\n becomes difficult to segment it into meaningful chunks, which can hinder the \\n RAG system's ability to retrieve relevant information efficiently.  31 \\n Well-organized data is crucial for effective chunking. \\n ○  Data preprocessing is a critical step in ensuring the accuracy and efficiency of \\n RAG systems. Clean, structured data significantly improves the retrieval\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 10, 'page_label': '11'}, page_content='process and ultimately leads to more relevant responses. One essential \\n preprocessing technique is data normalization, which standardizes the format \\n of data from different sources.  24 \\n ○  For optimal performance, RAG systems rely on adequate data preparation and \\n indexing techniques. Data that is properly structured ensures that the \\n retrieval mechanisms can access relevant information with high precision, \\n thereby minimizing noise and redundancy in the retrieved context.  24 \\n ○  A notable example of effective data preparation is the use of chunking \\n techniques, such as those employed by OpenAI, which divide large \\n documents into smaller units that are semantically coherent. This approach \\n helps to manage the context window limitations of LLMs and improves \\n retrieval accuracy.  24 \\n ○  Metadata tagging is another crucial technique that allows retrieval \\n mechanisms to prioritize information based on its contextual significance. This'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 10, 'page_label': '11'}, page_content='retrieval accuracy.  24 \\n ○  Metadata tagging is another crucial technique that allows retrieval \\n mechanisms to prioritize information based on its contextual significance. This \\n is similar to how a librarian uses categories and tags to help users discover \\n relevant books.  24 \\n ○  To continuously improve the performance of RAG systems, organizations \\n should adopt iterative indexing strategies that incorporate user feedback to \\n dynamically refine the data structures. This adaptability ensures that the \\n system remains responsive to evolving queries and enhances its long-term \\n reliability.  24 \\n ●  Insight 5:  The process of preparing data  for a RAG system is a critical multi-stage \\n pipeline that transforms raw, often unstructured, data from diverse sources into a \\n highly searchable knowledge base. This typically involves a series of steps \\n including data cleaning and structuring, segmenting the data into manageable'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 10, 'page_label': '11'}, page_content='highly searchable knowledge base. This typically involves a series of steps \\n including data cleaning and structuring, segmenting the data into manageable \\n chunks, converting these chunks into dense vector embeddings using specialized \\n embedding models, and finally, storing these embeddings in optimized vector \\n databases. Effective indexing strategies are then applied to ensure rapid and \\n accurate retrieval of relevant information during the RAG process. The quality and \\n thoroughness of this data ingestion and indexing phase are paramount, as they \\n directly impact the overall performance, accuracy, and efficiency of the entire \\n RAG system. \\n ●  The flow of information from query to response: \\n ○  The RAG workflow typically begins when a user poses a question or makes a \\n request, which serves as the initial prompt for the system.  4  This user input is \\n the catalyst that initiates the entire process.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 10, 'page_label': '11'}, page_content=\"request, which serves as the initial prompt for the system.  4  This user input is \\n the catalyst that initiates the entire process. \\n ○  In some implementations, such as those utilizing Azure AI Search, the user's \\n prompt is directly sent to the search engine to identify and retrieve relevant \\n information from the indexed knowledge base.  14  This step focuses on finding\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 11, 'page_label': '12'}, page_content=\"the data that can help answer the query. \\n ○  The search engine then returns the top-ranked search results, which are \\n deemed most relevant to the user's query, to the LLM.  14  These results provide \\n the LLM with the external context it needs. \\n ○  The LLM then leverages its natural language understanding and reasoning \\n capabilities to process both the original user prompt and the retrieved \\n information, ultimately generating a comprehensive and contextually \\n appropriate response.  14  This is where the LLM  synthesizes the information. \\n ○  More specifically, the LLM receives both the original user prompt and the \\n search results from the retrieval engine. It then analyzes these inputs to \\n formulate a response that addresses the user's query, taking into account the \\n additional context provided by the search results.  14 \\n ○  In a general RAG pattern, when a user submits a query, a document retriever \\n is employed to search through the available knowledge sources for relevant\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 11, 'page_label': '12'}, page_content=\"○  In a general RAG pattern, when a user submits a query, a document retriever \\n is employed to search through the available knowledge sources for relevant \\n content. This retrieved information is then incorporated into the model's \\n response generation process.  8  This dynamic integration  ensures that the \\n response is informed by the most relevant data. \\n ○  The dynamic integration of relevant data allows LLMs in a RAG system to \\n generate responses that are not only more informed but also more \\n contextually grounded, providing a richer and more accurate user \\n experience.  8 \\n ○  The RAG process can be broken down into a series of steps, starting with \\n receiving the user's prompt or query.  10  The system  then proceeds to search \\n for relevant information within its source data.  10  Upon finding this information, \\n it retrieves the most pertinent pieces to add as context to the original \\n prompt.  10  This augmented prompt is then  submitted to the Large Language\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 11, 'page_label': '12'}, page_content=\"it retrieves the most pertinent pieces to add as context to the original \\n prompt.  10  This augmented prompt is then  submitted to the Large Language \\n Model.  10  Finally, the LLM processes this enriched  prompt to deliver an \\n improved and more informative response back to the user.  10 \\n ○  Another perspective on the flow involves the system first receiving an input \\n query from the user.  17  The retrieval system is  then engaged to search for and \\n identify relevant information based on this query.  17  The retrieved information  is \\n subsequently incorporated into the prompt that is sent to the LLM.  17  Finally, \\n the LLM generates a response that directly leverages the context provided by \\n the retrieved information.  17 \\n ○  The entire RAG process can also be viewed from the user's perspective, \\n starting with the submission of a query to the system.  33  Based on this query, \\n the RAG system initiates a search within its connected database to find the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 11, 'page_label': '12'}, page_content='starting with the submission of a query to the system.  33  Based on this query, \\n the RAG system initiates a search within its connected database to find the \\n most relevant data.  33  This retrieved data  is then used to augment the prompt \\n sent to the LLM, which ultimately generates the response.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 12, 'page_label': '13'}, page_content=\"●  Insight 6:  The flow of information in a RAG system is a sequential process \\n initiated by a user's query. This query triggers the retrieval component to search \\n and fetch relevant information from the external knowledge base. The retrieved \\n information is then combined with the original query to create an augmented \\n prompt, which is subsequently fed into the LLM. The LLM processes this enriched \\n prompt, leveraging both its internal knowledge and the provided external context, \\n to generate a final response that is more accurate, relevant, and informative for \\n the user. The use of vector embeddings and semantic search facilitates efficient \\n retrieval, while prompt augmentation ensures the LLM effectively utilizes the \\n retrieved information during the generation phase. \\n 3. Key Benefits and Advantages of Using RAG \\n ●  Enhanced accuracy and reduced hallucinations: \\n ○  A significant advantage of employing RAG is that it ensures the language\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 12, 'page_label': '13'}, page_content=\"3. Key Benefits and Advantages of Using RAG \\n ●  Enhanced accuracy and reduced hallucinations: \\n ○  A significant advantage of employing RAG is that it ensures the language \\n model has access to the most current and reliable facts available.  7  By \\n grounding the model's responses in verifiable external knowledge, RAG \\n significantly improves the accuracy of the generated text. \\n ○  This grounding in factual information directly helps LLMs to adhere to the \\n truth and substantially reduces the occurrence of AI hallucinations, where the \\n model might generate plausible but incorrect or fabricated information.  8  By \\n minimizing reliance on the LLM's potentially outdated or incomplete internal \\n knowledge, RAG enhances the overall reliability of the AI system. \\n ○  By basing its responses on retrieved, factual information, RAG plays a crucial \\n role in minimizing the generation of false or invented details.  17  This direct link\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 12, 'page_label': '13'}, page_content='○  By basing its responses on retrieved, factual information, RAG plays a crucial \\n role in minimizing the generation of false or invented details.  17  This direct link \\n to external sources of truth bolsters the credibility of the LLM\\'s output. \\n ○  Consequently, RAG enhances both the accuracy and the overall relevance of \\n the responses that are generated by large language models.  4  The ability to \\n incorporate up-to-date and contextually appropriate information leads to \\n more meaningful and useful interactions. \\n ○  RAG guarantees that the generated responses are not only relevant to the \\n context of the query but also reflect the most current data available at the \\n time of the request.  10  This real-time access to  information ensures that the \\n LLM\\'s knowledge is always up-to-date. \\n ○  One of the key benefits of RAG is its ability to reduce the issue of \\n \"hallucinations\" by firmly anchoring the generation process in retrieved'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 12, 'page_label': '13'}, page_content='LLM\\'s knowledge is always up-to-date. \\n ○  One of the key benefits of RAG is its ability to reduce the issue of \\n \"hallucinations\" by firmly anchoring the generation process in retrieved \\n documents that have been verified as relevant and accurate.  10  This grounding \\n mechanism provides a strong foundation for the generated content. \\n ○  Ultimately, RAG offers a robust solution for generating text that is not only \\n fluent and natural-sounding but also demonstrably factually accurate and rich'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 13, 'page_label': '14'}, page_content='in relevant information, addressing a core challenge in the field of natural \\n language generation.  5 \\n ○  By providing the LLM with pertinent and factual information retrieved from \\n external sources, RAG significantly reduces the likelihood of the model \\n generating faulty or fabricated responses, commonly known as \\n hallucinations.  19  This makes the LLM a more trustworthy  and reliable source of \\n information. \\n ○  The use of premium, licensed data sources within a RAG framework further \\n ensures the trustworthiness of the information retrieved, thereby contributing \\n to the overall accuracy and reliability of the generated responses.  22  The \\n quality of the data source directly impacts the quality of the output. \\n ○  RAG can also enhance the user experience by offering concise and precise \\n responses that directly address the query, without overwhelming the user \\n with irrelevant or extraneous information. This is achieved by carefully'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 13, 'page_label': '14'}, page_content=\"responses that directly address the query, without overwhelming the user \\n with irrelevant or extraneous information. This is achieved by carefully \\n curating the content based on its relevance to the user's need.  22 \\n ○  The retrieval step in RAG provides a solid and dependable foundation of \\n relevant information, directly addressing concerns related to the factual \\n accuracy of the LLM's output.  11  This ensures  that the generated content is \\n based on verifiable facts. \\n ○  By actively fetching relevant external documents and seamlessly integrating \\n them into the text generation process, RAG significantly enhances the factual \\n consistency of the generated content.  26  This  integration ensures that the \\n LLM's responses are well-supported by external evidence. \\n ○  At its core, RAG grounds the entire text generation process in retrieved, \\n factual information, ensuring that the LLM's output is firmly rooted in reality\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 13, 'page_label': '14'}, page_content=\"○  At its core, RAG grounds the entire text generation process in retrieved, \\n factual information, ensuring that the LLM's output is firmly rooted in reality \\n rather than relying solely on its internal, potentially flawed, knowledge.  26 \\n ○  RAG models have the capability to produce outputs that are not only more \\n factual and grounded but also based on proprietary information, which is \\n particularly valuable for enterprise applications where access to and \\n utilization of internal knowledge is crucial, all while reducing the risk of factual \\n inconsistencies.  30 \\n ○  Insight 7:  The most compelling advantage of RAG  is its ability to significantly \\n improve the accuracy and factual consistency of LLM-generated text by \\n grounding responses in external, authoritative knowledge sources. This \\n mechanism drastically reduces the occurrence of hallucinations, a major \\n concern with standalone LLMs, thereby making AI systems more reliable and\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 13, 'page_label': '14'}, page_content='mechanism drastically reduces the occurrence of hallucinations, a major \\n concern with standalone LLMs, thereby making AI systems more reliable and \\n trustworthy for knowledge-intensive tasks and critical enterprise applications \\n where accuracy is paramount. The use of high-quality and licensed data \\n sources further reinforces the reliability of the information and the credibility'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 14, 'page_label': '15'}, page_content=\"of the generated responses. \\n ●  Access to up-to-date and domain-specific knowledge: \\n ○  A key benefit of RAG is that it provides the language model with direct access \\n to the most current information available at the time of the query.  7  This \\n overcomes the inherent limitation of LLMs, which are trained on static \\n datasets and may lack knowledge of recent events or developments. \\n ○  RAG effectively extends the capabilities of LLMs to encompass specific \\n domains or an organization's unique internal knowledge base.  2  This allows for \\n the deployment of LLMs in specialized applications where access to \\n domain-specific information is crucial for providing relevant and accurate \\n responses. \\n ○  Through RAG, LLMs gain the ability to utilize both domain-specific \\n information, which might not have been part of their original training, and \\n information that has been updated since their last training cycle.  8  This ensures\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 14, 'page_label': '15'}, page_content=\"information, which might not have been part of their original training, and \\n information that has been updated since their last training cycle.  8  This ensures \\n that the model's knowledge is both relevant to the context and current. \\n ○  RAG systems can address queries that require the most current information \\n by dynamically matching input parameters with real-time data sources.  4  This \\n capability is essential for applications such as providing up-to-the-minute \\n news or stock market updates. \\n ○  By enabling LLMs to leverage domain-specific knowledge bases, RAG allows \\n these general-purpose models to function as experts in particular fields, \\n providing highly specialized and informed responses.  17 \\n ○  A significant advantage of RAG is that it allows language models to access \\n and utilize the very latest information without requiring the costly and \\n time-consuming process of retraining the entire model.  18  This ability to bypass\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 14, 'page_label': '15'}, page_content=\"and utilize the very latest information without requiring the costly and \\n time-consuming process of retraining the entire model.  18  This ability to bypass \\n retraining and still access current data is invaluable in dynamic environments. \\n ○  RAG empowers LLM-based solutions with real-time access to data, ensuring \\n that the information they use is always current and relevant to the user's \\n needs.  19  This real-time access is a critical factor  in many practical \\n applications. \\n ○  RAG can seamlessly incorporate real-time updates and fresh information from \\n external sources without the need for extensive model retraining, ensuring \\n that the external knowledge base remains current and accurate over time.  6 \\n This dynamic updating capability is a major strength of RAG. \\n ○  RAG provides GenAI applications with access to both up-to-date information \\n about the world at large and highly specific data that pertains to particular\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 14, 'page_label': '15'}, page_content='○  RAG provides GenAI applications with access to both up-to-date information \\n about the world at large and highly specific data that pertains to particular \\n domains of knowledge.  13  This dual access ensures  comprehensive and \\n relevant responses. \\n ○  For organizations, RAG offers the ability to automatically provide their existing'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 15, 'page_label': '16'}, page_content='LLMs with access to the most current and relevant proprietary data, unlocking \\n new artificial intelligence opportunities that are more trustworthy, pertinent, \\n and timely.  16  This is particularly important for  leveraging internal knowledge \\n and improving business processes. \\n ○  Through RAG, LLMs can access and utilize the latest data available, ensuring \\n that their responses are always current and reflective of the most recent \\n information.  17  This is crucial for maintaining  the relevance and accuracy of \\n AI-driven systems. \\n ○  RAG has the capability to integrate external knowledge bases in a seamless \\n manner, which is particularly valuable in situations where having access to \\n information from a specific, curated knowledge base is crucial for generating \\n accurate and contextually relevant responses.  11 \\n ○  The framework of RAG is designed to leverage both internal, private data \\n sources and external, publicly accessible data, providing a comprehensive'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 15, 'page_label': '16'}, page_content=\"○  The framework of RAG is designed to leverage both internal, private data \\n sources and external, publicly accessible data, providing a comprehensive \\n range of information that the LLM can draw upon.  25 \\n ○  By dynamically retrieving and integrating external knowledge into the \\n generation process, RAG allows language models to access and utilize \\n up-to-date information without requiring the resource-intensive process of \\n retraining the entire model.  26  This dynamic access  to current information is a \\n significant advantage in rapidly changing fields. \\n ○  Insight 8:  A significant advantage of RAG  is its ability to provide LLMs with \\n immediate access to the most current information and highly specific, \\n domain-relevant knowledge. This capability effectively addresses the \\n limitations of LLMs' static training data, allowing them to provide accurate, \\n up-to-date, and contextually appropriate responses in dynamic environments\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 15, 'page_label': '16'}, page_content=\"limitations of LLMs' static training data, allowing them to provide accurate, \\n up-to-date, and contextually appropriate responses in dynamic environments \\n and specialized fields without the need for costly and time-consuming \\n retraining. \\n ●  Cost-effectiveness compared to retraining: \\n ○  Implementing RAG is generally a more cost-effective strategy for enhancing \\n an LLM's knowledge with new data compared to the significant computational \\n and financial investment required for retraining foundation models.  2  This \\n makes advanced AI capabilities more accessible. \\n ○  RAG reduces the need for continuous retraining of the model on new data and \\n the associated updates to its parameters as information evolves over time.  7 \\n This lowers the operational costs and complexities associated with \\n maintaining a knowledgeable AI system. \\n ○  In enterprise settings, RAG can significantly lower the computational and\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 15, 'page_label': '16'}, page_content='This lowers the operational costs and complexities associated with \\n maintaining a knowledgeable AI system. \\n ○  In enterprise settings, RAG can significantly lower the computational and \\n financial costs associated with running LLM-powered chatbots and other AI \\n applications.  7  This makes it a more practical  and scalable solution for many'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 16, 'page_label': '17'}, page_content='businesses. \\n ○  Given the high operational costs of running large language models, RAG offers \\n a cost-efficient alternative by contextualizing prompts with relevant \\n domain-specific information, thereby reducing the number of calls made to \\n the LLM and the total number of tokens processed, which often translates \\n directly to lower expenses.  4 \\n ○  With a RAG architecture, organizations can utilize virtually any LLM model and \\n augment it with their own data to return highly relevant results without \\n incurring the substantial costs and time involved in fine-tuning or pretraining \\n the model.  15  This flexibility and cost savings  are major drivers for RAG \\n adoption. \\n ○  Unlike solutions that require extensive computational infrastructure, RAG does \\n not necessitate a dedicated data center, which can lead to significant cost \\n reductions in terms of hardware and energy consumption.  9 \\n ○  Compared to fine-tuning, RAG is generally more cost-efficient as it primarily'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 16, 'page_label': '17'}, page_content='reductions in terms of hardware and energy consumption.  9 \\n ○  Compared to fine-tuning, RAG is generally more cost-efficient as it primarily \\n leverages existing data and eliminates the need for extensive and \\n resource-intensive training stages.  33  This  makes RAG a more accessible option \\n for organizations with budget constraints. \\n ○  In contrast to the complexities and potential costs associated with RAG \\n implementation, basic prompt engineering can be a simpler and more \\n cost-effective approach, as it leverages existing generative models without \\n the need for additional infrastructure or complex data pipelines.  25 \\n ○  Prompt engineering often requires fewer computational resources compared \\n to both RAG implementations, which involve retrieval processes, and the \\n extensive computations needed for fine-tuning entire language models, \\n making it a more resource-efficient option for certain use cases.  30'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 16, 'page_label': '17'}, page_content='extensive computations needed for fine-tuning entire language models, \\n making it a more resource-efficient option for certain use cases.  30 \\n ○  Insight 9:  RAG presents a more economical approach  to enhancing the \\n knowledge and performance of LLMs compared to the computationally \\n intensive and time-consuming processes of retraining or fine-tuning. By \\n leveraging existing pre-trained models and augmenting them with external \\n knowledge at the point of inference, organizations can achieve significant \\n improvements in accuracy and relevance without incurring the high costs \\n associated with extensive model training. This cost-effectiveness makes RAG \\n a particularly attractive option for a wide range of applications and \\n organizations. \\n ●  Improved transparency and explainability: \\n ○  A notable advantage of RAG is that it provides users with insights into the \\n process by which the LLM generates its responses. This is because RAG'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 16, 'page_label': '17'}, page_content='●  Improved transparency and explainability: \\n ○  A notable advantage of RAG is that it provides users with insights into the \\n process by which the LLM generates its responses. This is because RAG \\n explicitly directs the LLM to retrieve information from specific external'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 17, 'page_label': '18'}, page_content=\"sources, making the basis of the answer more transparent.  2 \\n ○  Retrieval-augmented generation enhances the explainability of AI outputs by \\n providing models with the ability to cite the sources they used to formulate \\n their responses, much like the footnotes in a research paper. This allows users \\n to easily check the claims made by the model, fostering greater trust in the AI \\n system.  9 \\n ○  RAG further improves transparency by allowing GenAI applications to cite the \\n specific sources of information they utilized, thereby enhancing the \\n auditability of the generated content.  13  This  traceability is crucial for verifying \\n the accuracy and reliability of the AI's output. \\n ○  By enabling end users to directly access the source documents that the LLM \\n consulted when creating its answers, RAG makes the inner workings of GenAI \\n applications more understandable and easier to audit.  13  This level of\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 17, 'page_label': '18'}, page_content='consulted when creating its answers, RAG makes the inner workings of GenAI \\n applications more understandable and easier to audit.  13  This level of \\n transparency is particularly valuable in sensitive or critical applications. \\n ○  The retrieval layer inherent in RAG ensures that the generated content can be \\n traced back to a specific source of truth within the knowledge base.  10  This \\n traceability enhances accountability and allows for verification of the \\n information. \\n ○  Overall, enhanced transparency is recognized as a significant benefit offered \\n by Retrieval Augmented Generation, making AI systems more understandable \\n and trustworthy for users.  20 \\n ○  Insight 10:  RAG significantly enhances the transparency  and explainability of \\n LLM outputs by explicitly connecting the generated responses to the external \\n knowledge sources from which the information was retrieved. This ability to \\n cite sources and trace the information back to its origin allows users to'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 17, 'page_label': '18'}, page_content='knowledge sources from which the information was retrieved. This ability to \\n cite sources and trace the information back to its origin allows users to \\n understand the basis for the model\\'s answers and verify their accuracy, \\n fostering greater trust and making RAG systems more auditable and \\n accountable compared to traditional LLMs that operate as \"black boxes.\" \\n 5. Challenges and Limitations Associated with RAG \\n ●  Quality and relevance of retrieved documents: \\n ○  The overall effectiveness of a RAG model is heavily contingent upon the \\n quality and relevance of the information retrieved from the external \\n knowledge base. If the retrieved documents or specific passages are not \\n directly relevant to the user\\'s query or if they contain inaccuracies, the quality \\n of the generated responses can be significantly compromised.  20  This \\n highlights a critical dependency on the retrieval mechanism. \\n ○  Research indicates that retrieval precision can experience a notable drop,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 17, 'page_label': '18'}, page_content='highlights a critical dependency on the retrieval mechanism. \\n ○  Research indicates that retrieval precision can experience a notable drop, \\n potentially as high as 30%, when dealing with datasets that contain a'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 18, 'page_label': '19'}, page_content='significant amount of noise or irrelevant information.  21  This sensitivity to data \\n quality underscores the importance of a clean and well-maintained \\n knowledge base. \\n ○  While innovative in their approach, basic or \"naive\" RAG systems often \\n struggle to achieve precise and contextually relevant results, particularly when \\n faced with complex queries or extensive enterprise-level datasets.  38  This \\n suggests that more sophisticated retrieval strategies are often necessary for \\n real-world applications. \\n ○  One potential issue arises from semantic ambiguity, where the system might \\n misinterpret words with multiple meanings, such as \"apple\" referring to either \\n a fruit or a technology company, leading to the retrieval of incorrect or \\n irrelevant information.  38  This highlights the  need for robust semantic \\n understanding in the retrieval process. \\n ○  Another limitation is that the retrieval system might sometimes match'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 18, 'page_label': '19'}, page_content=\"irrelevant information.  38  This highlights the  need for robust semantic \\n understanding in the retrieval process. \\n ○  Another limitation is that the retrieval system might sometimes match \\n documents based on broad similarities to the query, overlooking the specific \\n nuances and details that the user is actually seeking.  38  This lack of specificity \\n can result in retrieved information that is related but not directly helpful. \\n ○  In scenarios involving large volumes of data, the system may encounter \\n difficulties in accurately distinguishing between closely related topics, \\n potentially leading to the retrieval of less precise or even unrelated matches.  38 \\n This challenge emphasizes the need for fine-grained retrieval capabilities. \\n ○  Furthermore, the retrieval system might often miss the finer, more nuanced \\n contextual details embedded within a user's query, focusing instead on the \\n broader aspects of the request.  38  This can result  in retrieved information that\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 18, 'page_label': '19'}, page_content='contextual details embedded within a user\\'s query, focusing instead on the \\n broader aspects of the request.  38  This can result  in retrieved information that \\n lacks the specific context required for a comprehensive answer. \\n ○  A primary concern revolves around the quality and accuracy of the \\n information that is retrieved to augment the LLM\\'s prompt. Given that RAG \\n systems rely on external sources, the quality of the generated response is \\n inherently limited by the quality of the data that is pulled in. If the retrieval \\n system provides irrelevant or inaccurate documents, the final response is \\n likely to be similarly flawed.  20  The principle of \"garbage  in, garbage out\" \\n directly applies here. \\n ○  Ensuring that the retrieval process yields high-quality results often \\n necessitates careful fine-tuning of the retrieval models and regular updates to \\n the knowledge base to maintain its relevance and accuracy over time.  20'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 18, 'page_label': '19'}, page_content='necessitates careful fine-tuning of the retrieval models and regular updates to \\n the knowledge base to maintain its relevance and accuracy over time.  20 \\n Continuous maintenance and optimization are essential for sustained \\n performance. \\n ○  The effectiveness of RAG can be significantly hampered by poorly curated \\n knowledge bases or user queries that are ambiguous or unclear.  21  The quality'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 19, 'page_label': '20'}, page_content='of both the input and the knowledge source are critical determinants of \\n success. \\n ○  Ultimately, the success of any RAG system is heavily dependent on the \\n precision of its retrieval mechanism.  21  Accurate  retrieval is the cornerstone \\n upon which the rest of the process relies. \\n ○  Finding the right balance in the amount of information retrieved is also a \\n challenge. Retrieving too little information might lead to incomplete or \\n superficial responses, while retrieving an excessive amount can introduce \\n noise and make it harder for the LLM to focus on the most relevant parts.  24 \\n ○  The quality of the outputs generated by a RAG system is directly tied to the \\n accuracy, relevance, and completeness of its underlying data sources. \\n Consequently, regular updates and maintenance of these knowledge bases \\n are crucial, which can lead to higher operational overhead.  25 \\n ○  The curation and ongoing maintenance of the knowledge base are essential'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 19, 'page_label': '20'}, page_content=\"are crucial, which can lead to higher operational overhead.  25 \\n ○  The curation and ongoing maintenance of the knowledge base are essential \\n aspects of RAG, as the system's performance is directly dependent on the \\n quality of the data it retrieves.  30  A well-maintained  knowledge base is a \\n prerequisite for effective RAG. \\n ○  Insight 12:  A significant hurdle in implementing  effective RAG systems is \\n ensuring the quality and relevance of the retrieved documents. The generated \\n response is fundamentally limited by the information that the retrieval \\n component is able to access and provide. Challenges such as semantic \\n ambiguity in user queries, mismatches in granularity between the query and \\n the knowledge base, the presence of irrelevant or noisy data, and the \\n difficulty in capturing the complete context of a query can all contribute to the \\n retrieval of suboptimal information, which in turn negatively impacts the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 19, 'page_label': '20'}, page_content=\"difficulty in capturing the complete context of a query can all contribute to the \\n retrieval of suboptimal information, which in turn negatively impacts the \\n accuracy and utility of the final response. Overcoming these challenges \\n requires the implementation of sophisticated retrieval strategies, the \\n meticulous curation of the knowledge base, and continuous efforts to refine \\n and optimize the retrieval process. \\n ●  Potential for generating irrelevant or contradictory information: \\n ○  If the data retrieved by the RAG system is flawed or if the process of \\n augmenting the prompt with this data is inadequate, the subsequent \\n generation phase can lead to responses that are misleading, incomplete, or \\n not contextually aligned with the user's original query.  38  The quality of the \\n retrieved information directly influences the quality of the generated output. \\n ○  The system might encounter difficulties in seamlessly integrating the context\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 19, 'page_label': '20'}, page_content='retrieved information directly influences the quality of the generated output. \\n ○  The system might encounter difficulties in seamlessly integrating the context \\n provided by the retrieved data with the primary task of generating a response, \\n potentially resulting in outputs that feel disjointed or lack coherence.  38 \\n Smooth integration of external knowledge is a non-trivial challenge.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 20, 'page_label': '21'}, page_content='○  The retrieval process might inadvertently fetch the same piece of information \\n multiple times, leading to redundancy and repetition in the generated \\n response, which can detract from its clarity and conciseness.  38  Avoiding such \\n repetition requires careful management of the retrieval results. \\n ○  Deciding which portions of the retrieved information are most pertinent and \\n should be prioritized for inclusion in the generated response can be a \\n complex task, and failures in this prioritization can lead to less effective \\n answers.  38  Effective prioritization is key  to a focused response. \\n ○  When the retrieved information originates from diverse sources, it may exhibit \\n varying writing styles and tones, and harmonizing these differences in the \\n generated response can be challenging, potentially affecting the overall \\n consistency.  38  Maintaining a consistent tone  is important for user experience.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 20, 'page_label': '21'}, page_content='generated response can be challenging, potentially affecting the overall \\n consistency.  38  Maintaining a consistent tone  is important for user experience. \\n ○  The coherence and overall consistency of the generated output can be \\n negatively impacted by the nature and quality of the retrieved information, \\n especially if the retrieved context is fragmented or poorly organized.  38  A \\n well-structured response relies on well-structured input. \\n ○  In some cases, the LLM might oversimplify or make overly broad \\n generalizations based on the retrieved context, leading to a loss of important \\n specifics or nuances in the response.  38  Avoiding  over-generalization is \\n important for accuracy. \\n ○  Errors that occur during the initial retrieval phase can propagate through the \\n system and manifest as inaccuracies or misleading statements in the final \\n generated response.  38  This error propagation highlights  the \\n interconnectedness of the RAG pipeline.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 20, 'page_label': '21'}, page_content=\"system and manifest as inaccuracies or misleading statements in the final \\n generated response.  38  This error propagation highlights  the \\n interconnectedness of the RAG pipeline. \\n ○  The retrieved documents might themselves contain contradictory information, \\n and the RAG system might struggle to identify and resolve these conflicts, \\n potentially leading to a response that includes inconsistent or opposing \\n viewpoints.  38  Handling conflicting information  is a significant challenge. \\n ○  Finally, the LLM might not fully understand or effectively utilize the retrieved \\n context, leading to responses that, while perhaps relevant to the original \\n query, do not adequately incorporate or leverage the information that was \\n specifically provided to enhance the answer.  38  Ensuring proper context \\n utilization is crucial for RAG's success. \\n ○  Insight 13:  Even when the retrieval component  successfully fetches relevant\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 20, 'page_label': '21'}, page_content=\"utilization is crucial for RAG's success. \\n ○  Insight 13:  Even when the retrieval component  successfully fetches relevant \\n information, there remains a potential for the RAG system to generate \\n irrelevant or even contradictory information. This can arise from challenges in \\n seamlessly integrating the retrieved context into the prompt, difficulties in \\n prioritizing the most relevant information, inconsistencies in style or tone \\n across different sources, and the inherent complexities of synthesizing\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 21, 'page_label': '22'}, page_content='information from multiple documents, especially when those documents \\n might contain conflicting details. Ensuring coherence, consistency, and \\n relevance in the generated output requires sophisticated mechanisms for \\n managing and processing the retrieved context. \\n ●  Computational cost and latency: \\n ○  Unlike standalone LLMs, RAG systems necessitate the operation of both a \\n retrieval mechanism and an LLM capable of effectively integrating the \\n retrieved information, which can lead to increased computational demands \\n and overall system complexity.  20  The addition  of the retrieval step inherently \\n increases resource consumption. \\n ○  This heightened computational load can result in slower response times, \\n particularly when dealing with large volumes of data that require extensive \\n searching and processing in real time.  20  Latency can be a significant concern \\n for applications requiring immediate responses.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 21, 'page_label': '22'}, page_content='searching and processing in real time.  20  Latency can be a significant concern \\n for applications requiring immediate responses. \\n ○  RAG systems introduce additional computational overhead due to the \\n necessity of performing real-time data retrieval and processing for each user \\n query. This retrieval operation must be executed swiftly to maintain \\n acceptable response times, especially in user-facing applications where \\n speed is critical.  10 \\n ○  The real-time nature of retrieval in RAG can lead to latency bottlenecks, \\n especially as the size of the knowledge base grows. For instance, large-scale \\n deployments have been observed to experience a substantial increase in \\n response times if optimization techniques such as asynchronous retrieval or \\n vector quantization are not implemented.  21  Scalability can exacerbate these \\n latency issues. \\n ○  Managing the trade-offs between accuracy and computational efficiency is a'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 21, 'page_label': '22'}, page_content='vector quantization are not implemented.  21  Scalability can exacerbate these \\n latency issues. \\n ○  Managing the trade-offs between accuracy and computational efficiency is a \\n key consideration in RAG system design. While more sophisticated \\n architectures and processes can enhance accuracy, they often come with \\n higher costs and increased computational requirements, including expenses \\n related to embedding generation, vector database storage, and retrieval \\n speeds.  37 \\n ○  The incorporation of retrieval and reading components in RAG can potentially \\n lead to increased computational complexity and latency in the generative \\n process, which might limit its applicability in real-time scenarios where \\n immediate responses are required.  30 \\n ○  Insight 14:  The integration of a retrieval component  into the generation \\n process of RAG systems introduces an inherent computational overhead and \\n can potentially increase the latency of response generation. This trade-off'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 21, 'page_label': '22'}, page_content='process of RAG systems introduces an inherent computational overhead and \\n can potentially increase the latency of response generation. This trade-off \\n between enhanced accuracy and potential delays needs careful'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 22, 'page_label': '23'}, page_content='consideration, particularly for applications where rapid response times are \\n crucial for user experience. The complexity of the retrieval mechanism, the \\n size and structure of the knowledge base, and the efficiency of the indexing \\n and search algorithms all contribute to the overall computational cost and \\n latency of the system. Optimizing these factors is essential for deploying RAG \\n systems effectively in real-world scenarios. \\n ●  Handling noisy or unstructured data: \\n ○  For RAG systems to deliver accurate and reliable results, they require access \\n to up-to-date and relevant content. Therefore, it is essential to eliminate \\n outdated and redundant files from the knowledge base to ensure that the \\n retrieval process focuses on the most pertinent information.  3  Data quality and \\n relevance are paramount. \\n ○  Working with unstructured data formats such as complex PDFs that contain \\n embedded tables and charts can pose a significant challenge for RAG'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 22, 'page_label': '23'}, page_content='relevance are paramount. \\n ○  Working with unstructured data formats such as complex PDFs that contain \\n embedded tables and charts can pose a significant challenge for RAG \\n systems. Extracting meaningful information from these documents often \\n requires sophisticated parsing logic to handle inconsistent layouts and \\n formatting.  23 \\n ○  The data ingestion process can also be complicated by the presence of \\n unstructured data, such as free-flowing text or natural language, which may \\n not conform to easily processable formats.  23  Handling this type of data \\n effectively requires specialized techniques. \\n ○  While raw data can often be unreliable, structured and unified data sources \\n significantly enhance the performance of RAG systems.  36  However, a practical \\n challenge is that not all commercially available data is well-structured, which \\n can limit the effectiveness of RAG in certain applications.  36'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 22, 'page_label': '23'}, page_content=\"challenge is that not all commercially available data is well-structured, which \\n can limit the effectiveness of RAG in certain applications.  36 \\n ○  One of the primary challenges in optimizing RAG performance is managing \\n data that lacks a clear structure or consistent formatting. When data is not \\n properly organized, it becomes difficult to segment it into meaningful chunks, \\n which in turn can hinder the RAG system's ability to efficiently retrieve relevant \\n information.  31 \\n ○  The overall quality of the data within the knowledge base is a significant \\n factor affecting the performance of RAG systems. Outdated or conflicting \\n data can mislead the system, resulting in responses that are based on invalid \\n or inaccurate context.  31  Maintaining high data  quality is crucial for reliable RAG \\n performance. Poor data quality can also lead to inaccurate retrieval results, \\n decreased model performance, and increased computational overhead.  40\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 22, 'page_label': '23'}, page_content='performance. Poor data quality can also lead to inaccurate retrieval results, \\n decreased model performance, and increased computational overhead.  40 \\n ○  Insight 15:  The effectiveness of RAG systems is  intrinsically linked to the \\n quality and structure of the data within their knowledge bases. Noisy, \\n unstructured, outdated, or poorly formatted data can significantly impede the'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 23, 'page_label': '24'}, page_content='retrieval process, leading to inaccurate or irrelevant responses. Overcoming \\n these challenges requires robust data preprocessing pipelines, sophisticated \\n parsing techniques, and ongoing efforts to ensure the quality, consistency, \\n and relevance of the data sources. The principle of \"garbage in, garbage out\" \\n holds particularly true for RAG, emphasizing the importance of investing in \\n data management and quality assurance. \\n ●  Difficulties in extracting the correct answer from retrieved context: \\n ○  A common challenge in RAG systems is that even when relevant documents \\n are retrieved, the LLM might fail to accurately pinpoint and extract the \\n specific answer to the user\\'s query from the provided context. This can occur \\n due to the presence of noise or conflicting information within the retrieved \\n documents, making it difficult for the LLM to isolate the correct answer.  23 \\n ○  Another issue that can arise is that the output generated by the LLM might'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 23, 'page_label': '24'}, page_content=\"documents, making it difficult for the LLM to isolate the correct answer.  23 \\n ○  Another issue that can arise is that the output generated by the LLM might \\n not conform to the desired format specified in the user's query, such as a \\n table or a list, even if the necessary information is present in the retrieved \\n context.  40  This highlights a limitation in the  LLM's ability to structure the \\n extracted information according to specific requirements. \\n ○  In some instances, the model might return answers that are only partially \\n correct, missing some relevant information that is indeed available within the \\n knowledge base but was not effectively extracted from the retrieved \\n context.  40  This indicates a need for more  precise information extraction \\n capabilities. \\n ○  The retrieved data might not always provide the specific context needed to \\n generate an accurate and complete response, even if it is broadly related to\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 23, 'page_label': '24'}, page_content=\"capabilities. \\n ○  The retrieved data might not always provide the specific context needed to \\n generate an accurate and complete response, even if it is broadly related to \\n the user's query.  23  This issue of insufficient  contextual specificity can hinder \\n the LLM's ability to formulate a precise answer. \\n ○  The retrieval system might sometimes fail to include essential documents that \\n contain the direct answer to the user's query in the top-ranked results, \\n leading to a situation where the LLM does not have access to the necessary \\n information.  23  This underscores the importance  of an effective retrieval \\n ranking mechanism. \\n ○  Finally, the generated responses might lack the precision required to \\n adequately address the specific context of the user's query, even if relevant \\n information was retrieved. This can result in answers that are too general or \\n do not directly target the user's specific need.  23\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 23, 'page_label': '24'}, page_content=\"information was retrieved. This can result in answers that are too general or \\n do not directly target the user's specific need.  23 \\n ○  Insight 16:  Even when the retrieval component  successfully identifies and \\n fetches relevant documents, a significant challenge remains in ensuring that \\n the LLM can accurately extract the specific answer to the user's query from \\n the retrieved context. Factors such as noise, conflicting information, the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 24, 'page_label': '25'}, page_content=\"length and complexity of the retrieved text, and the LLM's limitations in \\n understanding the nuances of the context can all hinder its ability to pinpoint \\n and synthesize the precise information needed to provide a complete and \\n accurate response. This necessitates the development of more sophisticated \\n techniques for information extraction and context utilization within RAG \\n systems. \\n 6. Techniques and Strategies to Improve RAG Performance and Effectiveness \\n ●  Optimizing retrieval strategies (e.g., semantic search, vector databases): \\n ○  To enhance the performance of RAG systems, it is crucial to prioritize the use \\n of robust metadata tagging and domain-specific retrieval strategies. This \\n ensures that the system focuses on retrieving information that is highly \\n relevant and accurate for the given context.  21 \\n ○  Leveraging the power of semantic search is essential for understanding the \\n underlying intent behind user queries, going beyond simple keyword matching\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 24, 'page_label': '25'}, page_content=\"○  Leveraging the power of semantic search is essential for understanding the \\n underlying intent behind user queries, going beyond simple keyword matching \\n to find information that truly aligns with the user's needs.  5 \\n ○  Employing vector databases for the efficient indexing, storage, and retrieval of \\n information is a key technique for improving the speed and scalability of RAG \\n systems.  7  These databases are optimized for handling  the vector embeddings \\n used to represent the meaning of text. \\n ○  To further accelerate the retrieval process, advanced indexing techniques can \\n be implemented within the RAG system. These techniques help to organize \\n the knowledge base in a way that allows for quicker identification of relevant \\n documents or passages.  39 \\n ○  Fine-tuning the retrieval models themselves can lead to significant \\n improvements in both the relevance and the precision of the retrieved\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 24, 'page_label': '25'}, page_content=\"documents or passages.  39 \\n ○  Fine-tuning the retrieval models themselves can lead to significant \\n improvements in both the relevance and the precision of the retrieved \\n information. This involves adjusting the model's parameters to better align \\n with the specific characteristics of the knowledge base and the types of \\n queries expected.  36 \\n ○  Careful consideration should be given to the methods used for chunking \\n documents, as this can significantly impact retrieval effectiveness. Different \\n text splitters based on document type or strategies like chunking based on \\n titles and metadata might be more appropriate depending on the nature of \\n the data.  24 \\n ○  Selecting the right embedding model is also crucial. Depending on the \\n specific application and the nature of the language used in the knowledge \\n base, different models will perform with varying degrees of effectiveness. For \\n specialized terminology or industry-specific language, fine-tuning the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 24, 'page_label': '25'}, page_content='base, different models will perform with varying degrees of effectiveness. For \\n specialized terminology or industry-specific language, fine-tuning the \\n embedding model might be beneficial.  37'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 25, 'page_label': '26'}, page_content=\"○  The field of RAG is constantly evolving, and exploring novel architectures and \\n processes designed to enhance the accuracy and efficiency of the retrieval \\n component is an ongoing area of research and development.  37 \\n ○  Implementing query rewriting strategies can significantly boost the relevance \\n and accuracy of the information retrieved by the RAG system. By \\n reformulating the user's query in a way that better matches the content of the \\n knowledge base, the system can improve its retrieval performance.  31 \\n ○  For more complex queries that might involve multiple facets or sub-questions, \\n employing a multi-query RAG approach can be beneficial. This involves \\n segmenting the original query into several sub-queries, retrieving information \\n for each, and then aggregating the results to provide a more comprehensive \\n answer.  31 \\n ○  To handle inquiries that span multiple sources or require reasoning across\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 25, 'page_label': '26'}, page_content=\"for each, and then aggregating the results to provide a more comprehensive \\n answer.  31 \\n ○  To handle inquiries that span multiple sources or require reasoning across \\n different pieces of information, advancing RAG with multi-hop retrieval \\n techniques can be effective.  31  This allows  the system to perform a sequence \\n of retrieval steps, using the results of one to inform the next. \\n ○  Integrating the use of external tools into RAG systems can further enhance \\n their retrieval capabilities, allowing them to access and process information \\n from a wider range of sources and in more sophisticated ways.  31 \\n ○  To improve the ranking of retrieved information, techniques such as relevance \\n prediction can be used to assess how relevant each retrieved paragraph or \\n document is to the user's query.  42  This allows  the system to prioritize the most \\n pertinent content. \\n ○  Further refinement of the ranking can be achieved by predicting the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 25, 'page_label': '26'}, page_content=\"document is to the user's query.  42  This allows  the system to prioritize the most \\n pertinent content. \\n ○  Further refinement of the ranking can be achieved by predicting the \\n supportiveness and usefulness of each retrieved piece of information in \\n relation to the user's query. This helps to ensure that the LLM is provided with \\n the most valuable context for generating its response.  42 \\n ○  Employing knowledge reorganization algorithms can also be beneficial. These \\n algorithms work to decompose and recombine the retrieved knowledge in a \\n way that improves its relevance and coherence for the LLM.  42 \\n ○  In some cases, integrating web search capabilities directly into the RAG \\n process can provide access to a vast and up-to-date source of information, \\n supplementing the primary knowledge base.  42 \\n ○  Analyzing the structure of user queries, through techniques like tokenization \\n (breaking the query into individual words or phrases) and named entity\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 25, 'page_label': '26'}, page_content=\"○  Analyzing the structure of user queries, through techniques like tokenization \\n (breaking the query into individual words or phrases) and named entity \\n recognition (identifying key entities like people, places, and organizations), \\n can help the system to better understand the query's intent and improve \\n retrieval accuracy.  42 \\n ○  Correcting errors in user queries, such as spelling or grammatical mistakes,\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 26, 'page_label': '27'}, page_content=\"can also enhance retrieval performance by ensuring that the system is \\n searching for the intended terms.  42 \\n ○  Techniques for associating query semantics, such as query rewriting methods \\n like HyDE (Hypothetical Document Embeddings) and RAG-Fusion, can make \\n the query more expressive and effective for retrieval by leveraging existing \\n information to generate more informative search queries.  41 \\n ○  Expanding the context of the user's query by addressing omissions or \\n resolving references can also lead to more relevant retrieval results, ensuring \\n that the system has a complete understanding of the user's needs.  42 \\n ○  Increasing the dimensions and value precision of vector embeddings can \\n enhance the vectorization process, allowing the embeddings to capture more \\n nuanced features of the words and phrases in the knowledge base, leading to \\n more accurate retrieval.  32 \\n ○  Incorporating multiple diverse data sources into the RAG system can provide a\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 26, 'page_label': '27'}, page_content='nuanced features of the words and phrases in the knowledge base, leading to \\n more accurate retrieval.  32 \\n ○  Incorporating multiple diverse data sources into the RAG system can provide a \\n richer and more comprehensive context for the LLM, ultimately leading to \\n better and more accurate responses.  39  This  is known as augmentation \\n optimization. \\n ○  Exploring and implementing different retrieval techniques, such as dense \\n retrieval (which focuses on semantic similarity) and sparse retrieval (which \\n often relies on keyword matching), can help to optimize the system for \\n different types of queries and knowledge bases.  39 \\n ○  For certain types of queries, considering retrieval strategies like small-to-big \\n sentence window retrieval (where initially small context windows are \\n considered and expanded if needed) and recursive retrieval (where retrieval is \\n performed iteratively) might improve performance.  23'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 26, 'page_label': '27'}, page_content=\"considered and expanded if needed) and recursive retrieval (where retrieval is \\n performed iteratively) might improve performance.  23 \\n ○  Finally, utilizing semantic similarity scoring to rank the retrieved documents \\n based on their semantic relatedness to the user's query can help to prioritize \\n the most relevant information for the LLM.  23 \\n ○  Insight 17:  Optimizing the retrieval component  is a multifaceted endeavor \\n crucial for enhancing the overall performance of RAG systems. This involves a \\n strategic combination of advanced search techniques such as semantic \\n search and leveraging the efficiency of vector databases, coupled with \\n meticulous data management practices including effective chunking and \\n indexing. Furthermore, refining the retrieval process through techniques like \\n query rewriting, sophisticated ranking algorithms, and the exploration of novel \\n retrieval strategies are all essential elements in achieving high-performing\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 26, 'page_label': '27'}, page_content='query rewriting, sophisticated ranking algorithms, and the exploration of novel \\n retrieval strategies are all essential elements in achieving high-performing \\n RAG systems capable of delivering accurate and relevant information. \\n ●  Enhancing data preprocessing and indexing: \\n ○  A fundamental step in improving RAG performance is to thoroughly audit the'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 27, 'page_label': '28'}, page_content=\"existing document repositories and eliminate any outdated or redundant files. \\n This ensures that the retrieval process focuses on the most current and \\n relevant information available.  3 \\n ○  Adding relevant tags and categories to the content within the knowledge base \\n can significantly enhance its discoverability and facilitate more accurate \\n retrieval and processing by RAG tools.  3  Well-defined  metadata provides \\n crucial context for the retrieval mechanism. \\n ○  Ensuring that the data is well-organized and clearly formatted is essential for \\n the RAG system to effectively segment it into meaningful chunks, which is a \\n critical step for efficient and accurate retrieval.  31  Consistent formatting \\n improves the system's ability to process and understand the data. \\n ○  Establishing a robust quality assurance mechanism is vital to ensure that only \\n accurate and up-to-date information is ingested into the vector store. This\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 27, 'page_label': '28'}, page_content='○  Establishing a robust quality assurance mechanism is vital to ensure that only \\n accurate and up-to-date information is ingested into the vector store. This \\n helps to prevent the system from relying on flawed or outdated data when \\n generating responses.  31 \\n ○  Implementing regular audits and updates of the data within the knowledge \\n base, along with establishing fallback mechanisms for human intervention to \\n address any gaps or inaccuracies, can help maintain the comprehensiveness \\n and relevance of the data over time.  31 \\n ○  To optimize RAG systems, it is crucial to properly structure the data in a way \\n that allows the retrieval mechanisms to access relevant information with \\n precision, thereby minimizing noise and redundancy in the retrieved context.  24 \\n A well-structured knowledge base is essential for effective retrieval. \\n ○  Employing comprehensive data preprocessing steps, such as deduplication'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 27, 'page_label': '28'}, page_content='A well-structured knowledge base is essential for effective retrieval. \\n ○  Employing comprehensive data preprocessing steps, such as deduplication \\n (removing duplicate entries), normalization (standardizing formats), and \\n metadata tagging (adding descriptive information), is critical for preparing the \\n data for efficient and accurate retrieval.  24 \\n ○  Adopting iterative indexing strategies that incorporate user feedback to \\n dynamically refine the data structures can further enhance the performance \\n of RAG systems. This allows the system to adapt to evolving query patterns \\n and improve its long-term reliability.  24 \\n ○  Data normalization, which involves standardizing formats across different data \\n sources, is a key preprocessing technique that improves the consistency and \\n usability of the data for the RAG system.  24 \\n ○  Implementing artifact removal, which involves eliminating unnecessary \\n elements from documents such as headers, watermarks, and special symbols,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 27, 'page_label': '28'}, page_content='usability of the data for the RAG system.  24 \\n ○  Implementing artifact removal, which involves eliminating unnecessary \\n elements from documents such as headers, watermarks, and special symbols, \\n can prevent these elements from interfering with the retrieval process and \\n improve the accuracy of the results.  24 \\n ○  Utilizing semantic deduplication techniques to identify and merge redundant'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 28, 'page_label': '29'}, page_content='data based on its meaning, rather than just exact matches, can help to reduce \\n noise in the knowledge base and improve the precision of retrieval.  24 \\n ○  Experimenting with different chunking strategies, such as sliding window \\n chunking, document-based chunking, semantic chunking (based on \\n meaning), and agent chunking (where an AI agent decides how to chunk), can \\n help to find the optimal approach for a given task or dataset, improving the \\n effectiveness of retrieval.  32 \\n ○  Leveraging metadata filters, which allow the system to selectively filter, \\n weight, or prioritize retrieved information based on available metadata like the \\n source of the information, timestamps, or topic labels, can significantly \\n improve the relevance and quality of the generated responses.  32 \\n ○  Insight 18:  High-quality data preprocessing and  indexing are fundamental to \\n the effectiveness of RAG systems. This involves a meticulous approach to'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 28, 'page_label': '29'}, page_content=\"○  Insight 18:  High-quality data preprocessing and  indexing are fundamental to \\n the effectiveness of RAG systems. This involves a meticulous approach to \\n cleaning, structuring, and organizing the data within the knowledge base to \\n ensure that the retrieval component can efficiently identify and access the \\n most relevant information. Techniques such as chunking, the generation of \\n embeddings, and the strategic use of metadata tagging play crucial roles in \\n this process, ultimately leading to more accurate and reliable responses from \\n the LLM. \\n ●  Query rewriting and transformation: \\n ○  One effective strategy to improve the performance of RAG systems is to \\n rewrite the user's original query to better align with the content and structure \\n of the knowledge base, thereby enhancing the relevance and accuracy of the \\n retrieved information.  31 \\n ○  For complex queries that might encompass multiple aspects or\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 28, 'page_label': '29'}, page_content=\"of the knowledge base, thereby enhancing the relevance and accuracy of the \\n retrieved information.  31 \\n ○  For complex queries that might encompass multiple aspects or \\n sub-questions, deploying a multi-query RAG approach can be beneficial. This \\n involves breaking down the initial query into several distinct sub-queries, \\n allowing the system to retrieve information relevant to each aspect and then \\n synthesize a comprehensive response.  31 \\n ○  An advanced technique involves transforming the user's query along with a \\n hypothetical answer into embeddings. These embeddings are then used to \\n retrieve documents from the vector space that closely match this combined \\n representation, a method known as HyDE (Hypothetical Document \\n Embeddings).  41  This can sometimes lead to the  retrieval of documents that are \\n semantically related but might not contain the exact keywords of the query. \\n ○  For particularly intricate user queries, it can be helpful to divide them into a\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 28, 'page_label': '29'}, page_content='semantically related but might not contain the exact keywords of the query. \\n ○  For particularly intricate user queries, it can be helpful to divide them into a \\n sequence of smaller, more manageable sub-questions. This multi-step query \\n transformation allows the RAG system to process each sub-question \\n individually and then combine the retrieved information to address the overall'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 29, 'page_label': '30'}, page_content=\"query more effectively.  41 \\n ○  Insight 19:  Modifying or expanding the original  user query through \\n techniques like query rewriting and transformation can significantly enhance \\n the retrieval of relevant documents from the knowledge base. These \\n strategies help to bridge the gap between the user's natural language input \\n and the way information is organized and indexed within the system, \\n ultimately leading to more effective information retrieval and improved \\n response quality. \\n ●  Re-ranking techniques: \\n ○  After the initial set of documents or passages has been retrieved based on \\n the user's query, applying re-ranking techniques can further refine the results \\n by prioritizing the data chunks that are most relevant to the query. This helps \\n to filter out less pertinent information and ensures that the LLM focuses on \\n the most important context.  31 \\n ○  One approach to re-ranking involves using specialized re-ranking models as\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 29, 'page_label': '30'}, page_content=\"to filter out less pertinent information and ensures that the LLM focuses on \\n the most important context.  31 \\n ○  One approach to re-ranking involves using specialized re-ranking models as \\n an alternative to traditional embedding models. These re-ranking models take \\n the user's query and the retrieved context as input and return similarity \\n scores, allowing the system to order the results based on a more nuanced \\n understanding of relevance.  41 \\n ○  Large language models themselves can be utilized for re-ranking purposes. \\n By leveraging the LLM's ability to understand the semantic information within \\n the retrieved documents more efficiently, the system can achieve a more \\n accurate assessment of relevance and prioritize the most important content.  41 \\n ○  Specific re-ranking models, such as FlagEmbeddingReranker and \\n RankGPTRerank, have been developed and can be effectively employed to \\n improve the performance of RAG systems by providing a more sophisticated\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 29, 'page_label': '30'}, page_content='RankGPTRerank, have been developed and can be effectively employed to \\n improve the performance of RAG systems by providing a more sophisticated \\n way to order the retrieved information based on its relevance to the query.  41 \\n ○  Insight 20:  Following the initial retrieval of documents,  the application of \\n re-ranking techniques serves as a crucial step in further refining the results \\n and ensuring that the most relevant information is prioritized for the \\n generation phase. By employing specialized models or even the LLM itself to \\n assess the semantic relevance of the retrieved content, RAG systems can \\n filter out less pertinent information and provide the LLM with a more focused \\n and high-quality context, ultimately leading to improved response accuracy \\n and user satisfaction. \\n ●  Advanced RAG techniques (e.g., multi-hop retrieval, self-RAG, corrective \\n RAG): \\n ○  For handling complex inquiries that necessitate reasoning across multiple'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 29, 'page_label': '30'}, page_content='and user satisfaction. \\n ●  Advanced RAG techniques (e.g., multi-hop retrieval, self-RAG, corrective \\n RAG): \\n ○  For handling complex inquiries that necessitate reasoning across multiple \\n documents or facts, employing multi-hop retrieval techniques can'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 30, 'page_label': '31'}, page_content='significantly enhance the capability of RAG systems to provide comprehensive \\n and accurate answers.  31  This allows the system  to perform a series of \\n interconnected retrieval steps to gather all the necessary information. \\n ○  Self-RAG is an advanced approach that incorporates a mechanism for \\n self-reflection and iterative learning from evaluations. This technique typically \\n involves using three distinct models: a retriever, a critic, and a generator, \\n allowing the system to refine its retrieval and generation processes over time \\n based on its own assessments.  44 \\n ○  Corrective RAG (CRAG) introduces an evaluation step into the standard RAG \\n pipeline to check the accuracy and relevance of the retrieved information. If \\n the retrieved content does not meet a predefined threshold of quality, the \\n system is designed to look elsewhere, potentially returning to the data source \\n or even searching the web for more suitable information.  41'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 30, 'page_label': '31'}, page_content='system is designed to look elsewhere, potentially returning to the data source \\n or even searching the web for more suitable information.  41 \\n ○  Exploring techniques like late chunking, where larger documents are initially \\n retrieved and only chunked just before being passed to the LLM, can help to \\n preserve more of the original context and potentially improve retrieval \\n accuracy in certain scenarios.  41 \\n ○  Speculative RAG is another advanced technique that involves a two-step \\n process: first, the system drafts a potential answer based on the retrieved \\n information, and then it performs a verification step to ensure the accuracy \\n and completeness of the draft before presenting it to the user.  41 \\n ○  Implementing Corrective RAG (CRAG) in conjunction with frameworks like \\n LangGraph, which facilitates the creation of complex conversational AI \\n agents, can further enhance the performance of RAG systems by'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 30, 'page_label': '31'}, page_content='LangGraph, which facilitates the creation of complex conversational AI \\n agents, can further enhance the performance of RAG systems by \\n incorporating self-assessment of retrieved documents to improve the \\n accuracy and relevance of the generated responses.  41 \\n ○  Insight 21:  The ongoing evolution of RAG  technology has led to the \\n development of several advanced techniques aimed at addressing specific \\n limitations and further enhancing performance. Methods like multi-hop \\n retrieval, self-RAG, and corrective RAG introduce more sophisticated \\n architectures and workflows that enable RAG systems to handle more \\n complex queries, improve accuracy through self-evaluation and iterative \\n refinement, and ultimately deliver more reliable and comprehensive \\n responses. These advancements represent the cutting edge of research in the \\n field and promise to significantly expand the capabilities of RAG in various \\n applications.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 30, 'page_label': '31'}, page_content='responses. These advancements represent the cutting edge of research in the \\n field and promise to significantly expand the capabilities of RAG in various \\n applications. \\n 7. Recent Research Papers and Articles on Advancements and Current Trends in \\n RAG'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 31, 'page_label': '32'}, page_content='●  Discussion of cutting-edge research from venues like ACL, EMNLP, and \\n arXiv: \\n ○  Recent research is exploring the concept of hidden rationale retrieval, a more \\n challenging task where the query and the relevant document are not \\n semantically similar on the surface but are connected through underlying \\n reasoning chains, logical relationships, or empirical experiences.  45  This \\n expands the scope of retrieval beyond simple semantic matching. \\n ○  To enhance the performance of pioneering LLM-based retrievers, a novel \\n approach involves transforming the retrieval task into a generative one by \\n prompting the LLM to answer a binary-choice question. The model can then \\n be effectively fine-tuned using direct preference optimization (DPO). This \\n framework also prioritizes computational efficiency without sacrificing \\n performance.  45 \\n ○  Studies are increasingly focusing on understanding the impact of various \\n components and configurations within Retrieval-Augmented Generation'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 31, 'page_label': '32'}, page_content='performance.  45 \\n ○  Studies are increasingly focusing on understanding the impact of various \\n components and configurations within Retrieval-Augmented Generation \\n systems to enable more precise tailoring of these systems for complex and \\n diverse retrieval tasks.  46  A deeper understanding  of these elements is crucial \\n for optimizing RAG performance across different applications. \\n ○  To facilitate a more granular evaluation of RAG systems, researchers are \\n developing custom evaluation frameworks designed to assess the individual \\n contributions and impact of different RAG components and their specific \\n configurations.  46  These frameworks aim  to provide a more nuanced \\n understanding of what makes a RAG system effective. \\n ○  Current research highlights various strategies for optimizing the retrieval \\n components of RAG systems, with a particular focus on enhancing document \\n indexing and retrieval algorithms to minimize latency without compromising'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 31, 'page_label': '32'}, page_content='components of RAG systems, with a particular focus on enhancing document \\n indexing and retrieval algorithms to minimize latency without compromising \\n the accuracy of the retrieved information.  46  Balancing speed and accuracy is a \\n key area of investigation. \\n ○  Researchers are also examining the architectural decisions that can \\n significantly enhance the efficacy of RAG systems. This includes exploring the \\n optimal selection of the knowledge corpus, determining the appropriate \\n retrieval depth (i.e., how many documents to retrieve), and optimizing the \\n overall response time of the system.  46 \\n ○  The task of Hybrid Document RAG, which aims to seamlessly integrate both \\n textual and hierarchical tabular data for more comprehensive retrieval and \\n generation in complex scenarios, is an emerging area of interest. However, \\n there is a current lack of dedicated datasets specifically designed to support \\n research in this area.  47'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 31, 'page_label': '32'}, page_content='generation in complex scenarios, is an emerging area of interest. However, \\n there is a current lack of dedicated datasets specifically designed to support \\n research in this area.  47 \\n ○  Novel RAG techniques are continuously being explored with the primary goal'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 32, 'page_label': '33'}, page_content='of improving retrieval accuracy and overall enhancing the capabilities of \\n existing RAG frameworks to handle more challenging tasks and data types.  47 \\n ○  Advancements in RAG techniques are specifically aimed at improving not only \\n the accuracy of retrieval but also the efficiency and robustness of these \\n techniques in the context of knowledge-intensive tasks.  47  This reflects a drive \\n towards more practical and scalable RAG solutions. \\n ○  Recent research is extending the application of RAG beyond traditional \\n text-based data to encompass multimodal data, including knowledge graphs, \\n structured databases, and various forms of multimedia content.  47  This \\n expansion opens up new possibilities for RAG in diverse application domains. \\n ○  Retrieval-augmented strategies are increasingly being integrated into the field \\n of computer vision (CV) with the aim of improving both the understanding and \\n the generation capabilities of vision models by leveraging external'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 32, 'page_label': '33'}, page_content='of computer vision (CV) with the aim of improving both the understanding and \\n the generation capabilities of vision models by leveraging external \\n knowledge.  48  This interdisciplinary  approach holds promise for enhancing \\n visual AI tasks. \\n ○  In the domain of visual understanding, researchers are systematically \\n reviewing the application of retrieval-augmented methods to a wide range of \\n tasks, from basic image recognition to more complex applications such as the \\n generation of medical reports from images and multimodal question \\n answering.  48 \\n ○  RAG is also being explored for its potential in visual content generation tasks, \\n including the generation of images, videos, and even 3D models, by providing \\n these generative models with relevant external visual or contextual \\n information.  48 \\n ○  Emerging research is also focusing on the integration of retrieval-augmented \\n strategies into embodied AI, particularly in applications related to planning,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 32, 'page_label': '33'}, page_content='information.  48 \\n ○  Emerging research is also focusing on the integration of retrieval-augmented \\n strategies into embodied AI, particularly in applications related to planning, \\n task execution, multimodal perception, and interaction with environments, as \\n well as in specialized domains requiring specific knowledge.  48 \\n ○  A novel approach, known as CoRAG, is being developed for training RAG \\n models to perform retrieval and reasoning over relevant information in a \\n step-by-step manner before generating the final answer. This contrasts with \\n conventional RAG methods that typically perform a single retrieval step.  43 \\n ○  To facilitate the training of CoRAG models, researchers are utilizing rejection \\n sampling to automatically generate intermediate retrieval chains. This method \\n helps to augment existing RAG datasets that typically only provide the final \\n answer without detailing the intermediate retrieval steps taken.  43'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 32, 'page_label': '33'}, page_content='helps to augment existing RAG datasets that typically only provide the final \\n answer without detailing the intermediate retrieval steps taken.  43 \\n ○  Current research is undertaking comprehensive reviews of all significant \\n techniques involved in Retrieval-Augmented Generation, with a particular \\n emphasis on the retriever component and the various methods for fusing the'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 33, 'page_label': '34'}, page_content=\"retrieved information with the generation process.  35 \\n ○  Different training strategies for RAG systems are being investigated, including \\n approaches that involve updating the datastore (knowledge base) during \\n training and those that do not, to understand the impact of these strategies \\n on the final model performance.  35 \\n ○  Various techniques for retrieval fusion, which aim to effectively leverage the \\n retrieved information to enhance the generation process, are being \\n categorized into three major types: query-based fusion, latent fusion, and \\n logits-based fusion, each representing a different way of integrating retrieved \\n knowledge.  35 \\n ○  Studies are beginning to address the critical issue of predictive uncertainty in \\n RAG systems, which refers to the likelihood that a RAG model's prediction is \\n incorrect. This is important for managing potential risks in real-world \\n applications where the reliability of the output is paramount.  50\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 33, 'page_label': '34'}, page_content='incorrect. This is important for managing potential risks in real-world \\n applications where the reliability of the output is paramount.  50 \\n ○  To guide RAG models in assessing their own confidence in their predictions, \\n based on the quality of the retrieved results and how these results are utilized, \\n researchers are developing counterfactual prompting frameworks. These \\n frameworks induce the models to consider alternative scenarios and analyze \\n the effect on their answers.  50 \\n ○  For a more comprehensive evaluation of risk-aware RAG systems, researchers \\n are proposing new risk-related metrics such as risk, carefulness, alignment, \\n and coverage, which go beyond traditional effectiveness metrics like \\n accuracy.  50 \\n ○  A growing body of research is surveying methods that augment generative \\n models by retrieving knowledge in various formats beyond just text, including \\n images, code snippets, tables, graphs, and audio.  49  This highlights the'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 33, 'page_label': '34'}, page_content='models by retrieving knowledge in various formats beyond just text, including \\n images, code snippets, tables, graphs, and audio.  49  This highlights the \\n expanding scope of retrieval-augmented generation. \\n ○  The application of Audio RAG is being explored for specific audio-language \\n tasks, such as generating captions for music, creating music from text and \\n vice versa, and improving speech recognition. Additionally, the use of audio \\n RAG for augmenting audio data has shown promise in mitigating the \\n challenges posed by the limited availability of audio-text training data.  49 \\n ○  To address the scarcity of training data for text-audio tasks, researchers are \\n investigating techniques like SpokenVocab, which aims to convert machine \\n translation data into synthetic speech translation data by retrieving and \\n stitching together audio snippets corresponding to words in a translated \\n sentence.  49  This innovative approach leverages  existing resources to'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 33, 'page_label': '34'}, page_content='stitching together audio snippets corresponding to words in a translated \\n sentence.  49  This innovative approach leverages  existing resources to \\n overcome data limitations. \\n ○  Insight 22:  Current research in Retrieval Argument  Generation is'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 34, 'page_label': '35'}, page_content='characterized by a strong focus on addressing its inherent limitations, \\n expanding its capabilities to handle more complex data and tasks, and \\n exploring novel applications across various domains. Key trends include \\n efforts to enhance retrieval accuracy and efficiency, extend RAG to \\n multimodal data such as images and audio, improve the reasoning abilities of \\n RAG systems, and develop methods for assessing and mitigating uncertainty \\n in generated responses. The emergence of new techniques like hidden \\n rationale retrieval and the development of specialized evaluation frameworks \\n indicate a dynamic and rapidly advancing field. \\n ●  Emerging trends and future directions in RAG: \\n ○  Future research and development in RAG should prioritize the implementation \\n of iterative feedback loops, where the outputs of the retrieval component are \\n dynamically refined based on the performance of the generation component. \\n This ensures a more cohesive and reliable pipeline.  24'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 34, 'page_label': '35'}, page_content='dynamically refined based on the performance of the generation component. \\n This ensures a more cohesive and reliable pipeline.  24 \\n ○  To enhance the efficiency of RAG systems, future strategies should focus on \\n achieving real-time alignment between the retriever and the generator \\n components, as well as incorporating adaptive learning mechanisms that \\n allow the system to improve its performance over time.  24 \\n ○  The development of hybrid models that effectively balance the accuracy of \\n information retrieval with the flexibility and creativity of the generative model \\n will be a key focus in the future of RAG.  24  This  balance is crucial for creating \\n robust and versatile AI applications. \\n ○  In the domain of computer vision, future research directions for RAG include \\n optimizing retrieval for real-time applications, exploring methods for \\n cross-modal retrieval fusion (e.g., combining image and text retrieval),'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 34, 'page_label': '35'}, page_content=\"optimizing retrieval for real-time applications, exploring methods for \\n cross-modal retrieval fusion (e.g., combining image and text retrieval), \\n developing privacy-aware retrieval techniques, and advancing retrieval-based \\n generative modeling approaches.  48 \\n ○  The CoRAG approach, which involves step-by-step retrieval and reasoning \\n before generation, presents a promising avenue for future research in the \\n RAG domain, particularly in its potential to mitigate the issue of hallucination \\n in model-generated content.  43 \\n ○  Looking ahead, future research in RAG for natural language processing will \\n likely focus on exploring and addressing the main challenges that currently \\n limit the technology's full potential, aiming to further enhance its capabilities \\n and broaden its applicability.  35 \\n ○  Insight 23:  The future trajectory of RAG  technology points towards the \\n development of more dynamic, adaptive, and intelligent systems. Emerging\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 34, 'page_label': '35'}, page_content='and broaden its applicability.  35 \\n ○  Insight 23:  The future trajectory of RAG  technology points towards the \\n development of more dynamic, adaptive, and intelligent systems. Emerging \\n trends suggest a greater emphasis on creating RAG pipelines that can learn \\n and improve through continuous feedback and real-time coordination'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 35, 'page_label': '36'}, page_content='between retrieval and generation. Further exploration of multimodal RAG, \\n advancements in reasoning capabilities, and a focus on addressing current \\n limitations will likely shape the future of this rapidly evolving field. \\n ●  Integration of RAG with multimodal data: \\n ○  A significant emerging trend in the field is the integration of \\n retrieval-augmented strategies into domains beyond natural language \\n processing, most notably in computer vision (CV).  48  This involves enhancing \\n vision models with the ability to access and utilize external visual and \\n contextual knowledge. \\n ○  RAG is being increasingly applied in computer vision for tasks related to visual \\n understanding, such as image recognition and the generation of medical \\n reports from visual data, as well as for visual content generation, including the \\n creation of new images, videos, and 3D models based on retrieved \\n information.  48'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 35, 'page_label': '36'}, page_content='reports from visual data, as well as for visual content generation, including the \\n creation of new images, videos, and 3D models based on retrieved \\n information.  48 \\n ○  The concept of Audio RAG is also gaining traction, with researchers exploring \\n its use in various audio-language tasks, such as music captioning and speech \\n recognition, and even for augmenting audio data itself to improve model \\n training.  49 \\n ○  Another important area of development is the focus on RAG for handling the \\n combined modality of tables and text within documents, known as Hybrid \\n Document RAG. This aims to create systems that can effectively retrieve and \\n reason over information presented in both textual and structured tabular \\n formats.  47 \\n ○  Insight 24:  The application of RAG is expanding  beyond its traditional focus \\n on textual data to encompass a wider range of modalities, including images, \\n audio, and structured data like tables. This integration of RAG with multimodal'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 35, 'page_label': '36'}, page_content=\"on textual data to encompass a wider range of modalities, including images, \\n audio, and structured data like tables. This integration of RAG with multimodal \\n data opens up exciting new possibilities for creating more comprehensive and \\n context-aware AI systems capable of understanding and generating content \\n across different types of information. This trend reflects the growing \\n recognition that real-world knowledge is often conveyed through a \\n combination of different formats, and AI systems need to be able to process \\n and utilize this information effectively. \\n 8. Comparison and Contrast of RAG with Other Related Concepts in NLP \\n ●  RAG vs. Fine-tuning: \\n ○  Definition and Approach:  Retrieval-Augmented  Generation (RAG) is a \\n technique that enhances a natural language processing (NLP) model by \\n connecting it to an organization's proprietary database, allowing the model to \\n retrieve relevant information at the time of a user query to improve the\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 36, 'page_label': '37'}, page_content=\"context for generating a response.  4  In contrast, fine-tuning is the process of \\n optimizing pre-trained deep learning models for specific, domain-related \\n tasks by training them further on a narrower, task-specific dataset.  28 \\n ○  Goals:  While both RAG and fine-tuning aim  to improve the performance of \\n language models to maximize their value for the enterprise, they achieve this \\n through different means.  28  RAG's primary goal is  to guide a model towards \\n producing more relevant and accurate outputs by providing it with access to \\n current, often private, data at the time of the query.  25  Fine-tuning, on the \\n other hand, focuses on retraining a pre-trained model on a more focused set \\n of external data to enhance its performance in very specific use cases and to \\n improve its understanding of domain-specific terminology.  28 \\n ○  Data Requirements:  RAG relies on an organization's  internal data sources,\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 36, 'page_label': '37'}, page_content=\"improve its understanding of domain-specific terminology.  28 \\n ○  Data Requirements:  RAG relies on an organization's  internal data sources, \\n which need to be well-organized and maintained to allow for efficient \\n real-time retrieval.  28  This often involves establishing  enterprise data storage \\n solutions, segmenting and embedding documents, and implementing robust \\n data protection measures.  28  Fine-tuning,  however, requires a carefully curated \\n and focused set of external data that is specific to the task for which the \\n model is being optimized, often domain-specific.  28 \\n ○  Update Mechanism:  A significant advantage  of RAG is its ability to \\n dynamically update the model's knowledge by leveraging the most current \\n data from the external knowledge base without requiring any retraining of the \\n underlying model.  2  In contrast, a fine-tuned model's  knowledge is limited to \\n the data it was trained on during the fine-tuning process, and incorporating\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 36, 'page_label': '37'}, page_content=\"underlying model.  2  In contrast, a fine-tuned model's  knowledge is limited to \\n the data it was trained on during the fine-tuning process, and incorporating \\n new information typically requires repeating the fine-tuning process with \\n updated data.  28 \\n ○  Cost and Resources:  Implementing RAG  generally requires more \\n computational resources at runtime due to the added step of querying the \\n external database. There are also costs associated with setting up and \\n maintaining the data infrastructure, including embedding and vector database \\n costs.  4  However, RAG typically requires less  upfront work and fewer \\n specialized AI skills compared to fine-tuning.  34  Fine-tuning, on the other hand, \\n demands more upfront effort and is computationally intensive during the \\n training phase, making it potentially more expensive initially.  29  Once a \\n fine-tuned model is deployed, its runtime resource requirements are generally\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 36, 'page_label': '37'}, page_content='training phase, making it potentially more expensive initially.  29  Once a \\n fine-tuned model is deployed, its runtime resource requirements are generally \\n similar to the base model.  34  Fine-tuning also  necessitates expertise in natural \\n language processing, deep learning, and model configuration.  34 \\n ○  Primary Use Cases:  RAG is particularly well-suited  for scenarios where \\n access to local and very current data is essential, in specialized industries \\n where data privacy and security are paramount, and in situations where'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 37, 'page_label': '38'}, page_content=\"runtime resources might be limited.  4  Common applications include technical \\n support, inventory lookup, and personalized recommendations.  34  Fine-tuning \\n is the preferred method when an LLM needs to develop a deep understanding \\n of a specific domain, where controlling the tone and manner of responses is \\n important, and for tasks requiring consistent, high-quality performance within \\n a specialized area such as medicine or coding.  34 \\n ○  Strengths and Weaknesses:  RAG's key strengths  include enhanced security \\n and data privacy due to the data remaining in the external database, \\n cost-efficiency and scalability for handling large and changing knowledge \\n bases, and the ability to provide trustworthy results by leveraging the latest \\n curated datasets.  4  A potential weakness is that  the language models are not \\n specifically trained for accuracy in any particular domain; they primarily rely\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 37, 'page_label': '38'}, page_content=\"curated datasets.  4  A potential weakness is that  the language models are not \\n specifically trained for accuracy in any particular domain; they primarily rely \\n on the general knowledge from their initial training.  34  Fine-tuning's strengths \\n lie in its ability to enable a model to better understand specific domains and \\n their terminology, leading to more accurate and contextually appropriate \\n responses with greater control over the style and tone of the generated \\n content.  28  A limitation of fine-tuning  is that the model's knowledge is tied to \\n the static snapshot of the training dataset used, and it can become outdated \\n over time.  51 \\n ○  Combinations:  It is important to note that RAG  and fine-tuning are not \\n mutually exclusive techniques and can indeed be used in combination. For \\n instance, a model could be fine-tuned on a specific domain to better \\n understand its nuances, while RAG could be employed to provide access to\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 37, 'page_label': '38'}, page_content=\"instance, a model could be fine-tuned on a specific domain to better \\n understand its nuances, while RAG could be employed to provide access to \\n the most up-to-date information within that domain.  26  Fine-tuning might help \\n a model master specific policies, while RAG could retrieve relevant cases or \\n documents.  57 \\n ○  Insight 25:  RAG and fine-tuning represent  two distinct yet potentially \\n complementary strategies for enhancing the performance of large language \\n models. RAG focuses on augmenting the LLM with external knowledge at the \\n time of inference, making it particularly suitable for tasks requiring access to \\n dynamic data and offering a cost-effective way to keep the model's \\n knowledge current. Fine-tuning, conversely, involves adapting the LLM's \\n internal parameters through further training on domain-specific data, which \\n can lead to improved performance in specialized tasks and greater control\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 37, 'page_label': '38'}, page_content='internal parameters through further training on domain-specific data, which \\n can lead to improved performance in specialized tasks and greater control \\n over the style and tone of the output. The optimal choice between these two \\n approaches, or the decision to use them in conjunction, depends on the \\n specific requirements of the application, the nature of the available data, and \\n the resources at hand.'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 38, 'page_label': '39'}, page_content='○  Table 1: Comparison of RAG and Fine-tuning \\n Feature  RAG  Fine-tunin \\n g \\n Approach  Augments \\n LLM with \\n external \\n data at \\n query time \\n Retrains a \\n pre-trained \\n model on a \\n specific \\n dataset \\n Data \\n Source \\n External \\n knowledge \\n base \\n (dynamic, \\n proprietary \\n ) \\n Domain-sp \\n ecific \\n training \\n data \\n (static) \\n Knowledg \\n e Update \\n Real-time, \\n dynamic \\n updates \\n through the \\n knowledge \\n base \\n Requires \\n retraining \\n for new \\n information \\n Computati \\n onal Cost \\n Higher at \\n inference \\n time \\n (retrieval), \\n lower \\n upfront \\n Higher \\n upfront \\n (training), \\n lower at \\n inference \\n time \\n Data \\n Requireme \\n nts \\n Requires \\n well-organi \\n zed and \\n accessible \\n knowledge \\n base \\n Requires a \\n curated, \\n task-specifi \\n c dataset \\n Expertise \\n Required \\n Data \\n engineering \\n , some NLP \\n Strong NLP, \\n deep \\n learning, \\n model \\n configurati'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 39, 'page_label': '40'}, page_content=\"on \\n Primary \\n Use Cases \\n Up-to-date \\n information \\n , \\n knowledge- \\n intensive \\n tasks, \\n reducing \\n hallucinatio \\n ns \\n Domain-sp \\n ecific tasks, \\n style/tone \\n control, \\n consistent \\n performanc \\n e \\n Security  Data \\n remains in \\n the external \\n knowledge \\n base with \\n access \\n controls \\n Data \\n becomes \\n part of the \\n model's \\n parameters \\n Scalability  More \\n scalable for \\n handling \\n large and \\n changing \\n knowledge \\n bases \\n Requires \\n retraining \\n for new \\n tasks or \\n domains \\n ●  RAG vs. Prompt Engineering: \\n ○  Definition and Approach:  Retrieval-Augmented  Generation (RAG) enhances \\n LLM responses by retrieving relevant information from external knowledge \\n sources and incorporating it into the prompt, leveraging both internal and \\n external data.  25  Prompt engineering, on the other  hand, focuses on the art of \\n crafting effective input prompts to guide pre-trained models towards \\n generating desired outputs without making any changes to the underlying\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 39, 'page_label': '40'}, page_content='crafting effective input prompts to guide pre-trained models towards \\n generating desired outputs without making any changes to the underlying \\n model itself.  25 \\n ○  Goals:  While both RAG and prompt engineering  aim to improve the \\n performance of language models, they do so with different objectives.  25  RAG \\n is primarily focused on achieving precise, knowledge-driven outputs that are \\n based on up-to-date information retrieved from external sources.  25  Prompt \\n engineering seeks to exploit the inherent capabilities of the LLM to fulfill a \\n wider range of needs, including more diverse and creative tasks, by carefully \\n optimizing the input prompts.  25'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 40, 'page_label': '41'}, page_content='○  Resource Requirements:  RAG typically requires a significant amount of data \\n science expertise to organize and manage the datasets and to build the \\n necessary data pipelines for efficient information retrieval, often involving \\n vector databases and embedding models.  28  The retrieval  process can also \\n introduce higher computational overhead and latency.  10  In contrast, prompt \\n engineering is generally the least resource-intensive of the three techniques, \\n with basic prompt engineering often being done manually without requiring \\n additional computational resources.  25 \\n ○  Flexibility and Adaptability:  RAG provides a  high degree of flexibility by \\n allowing the language model to dynamically access and utilize external \\n information, ensuring that it can stay current with the latest data without \\n needing to be retrained.  6  Prompt engineering  also offers flexibility and can \\n yield immediate results through the iterative refinement of prompts. However,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 40, 'page_label': '41'}, page_content=\"needing to be retrained.  6  Prompt engineering  also offers flexibility and can \\n yield immediate results through the iterative refinement of prompts. However, \\n it is ultimately limited by the pre-trained knowledge of the underlying LLM, \\n and finding the most effective prompts can sometimes be a process of trial \\n and error.  25  Furthermore, even small changes in  prompts can sometimes lead \\n to unpredictable variations in the model's outputs.  25 \\n ○  Primary Use Cases:  RAG is particularly effective  for applications that require \\n answering complex questions that necessitate access to specific, up-to-date, \\n or external information, such as scientific research, legal documents, or \\n company databases. It is also well-suited for enhancing customer support \\n through real-time access to relevant data, providing personalized \\n recommendations, offering educational assistance, and delivering specialized\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 40, 'page_label': '41'}, page_content='through real-time access to relevant data, providing personalized \\n recommendations, offering educational assistance, and delivering specialized \\n expertise in various domains.  25  Prompt engineering,  on the other hand, excels \\n in tasks such as creative content generation, debugging AI outputs, creating \\n interactive experiences, performing data transformation, and simulating \\n various scenarios.  25 \\n ○  Interplay:  Prompt engineering is often an essential  and integral component of \\n RAG systems. It is used to guide the retrieval system in identifying the most \\n relevant information from the knowledge base and to instruct the LLM on how \\n to effectively process and incorporate this retrieved data to generate better, \\n more informed responses.  26  In fact, effective  prompt engineering is widely \\n recognized as a key factor in realizing the full potential of RAG technology.  27 \\n ○  Insight 26:  RAG and prompt engineering represent  two distinct but often'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 40, 'page_label': '41'}, page_content=\"recognized as a key factor in realizing the full potential of RAG technology.  27 \\n ○  Insight 26:  RAG and prompt engineering represent  two distinct but often \\n complementary approaches to enhancing the capabilities of large language \\n models. While RAG focuses on augmenting the LLM's knowledge by retrieving \\n and incorporating external information relevant to the user's query, prompt \\n engineering centers on the strategic design of input prompts to elicit more \\n desirable and accurate responses from the model without altering its\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 41, 'page_label': '42'}, page_content=\"underlying parameters or knowledge base. RAG is particularly valuable in \\n scenarios where access to up-to-date and factual information is critical, \\n whereas prompt engineering is more about skillfully guiding the model's \\n inherent abilities to achieve specific outcomes, whether they be factual, \\n creative, or task-oriented. The synergy between these two techniques is often \\n leveraged in advanced AI applications, where well-crafted prompts can \\n significantly improve the effectiveness of the retrieval process in RAG and the \\n quality of the generated responses based on that retrieved information. \\n 9. Conclusion \\n Retrieval-Augmented Generation (RAG) has emerged as a powerful and versatile \\n technique for enhancing the capabilities of large language models by integrating \\n external knowledge into the response generation process. This report has explored \\n the definition, architecture, benefits, applications, challenges, and recent\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 41, 'page_label': '42'}, page_content='external knowledge into the response generation process. This report has explored \\n the definition, architecture, benefits, applications, challenges, and recent \\n advancements in RAG, as well as its relationship with other key concepts in NLP like \\n fine-tuning and prompt engineering. The analysis indicates that RAG offers significant \\n advantages, particularly in improving the accuracy and factual consistency of LLM \\n outputs, providing access to up-to-date and domain-specific information, and \\n offering a more cost-effective alternative to full model retraining for many use cases. \\n Its ability to provide transparency and explainability in AI responses also contributes \\n to increased user trust. \\n The applications of RAG span a wide range of domains, from enhancing question \\n answering systems and intelligent chatbots to automating content creation, \\n personalizing recommendations, and providing specialized expertise in fields like'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 41, 'page_label': '42'}, page_content='answering systems and intelligent chatbots to automating content creation, \\n personalizing recommendations, and providing specialized expertise in fields like \\n healthcare, law, and finance. However, the effectiveness of RAG is not without its \\n challenges. The quality and relevance of retrieved documents are critical, and issues \\n such as the potential for generating irrelevant or contradictory information, \\n computational costs, and the handling of noisy data need careful consideration. \\n Researchers and practitioners are actively developing various techniques and \\n strategies to mitigate these limitations and improve the performance of RAG systems, \\n including optimizing retrieval strategies, enhancing data preprocessing, employing \\n query rewriting and re-ranking techniques, and exploring advanced RAG \\n architectures. \\n Recent research trends highlight a focus on extending RAG to handle multimodal data,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 41, 'page_label': '42'}, page_content='query rewriting and re-ranking techniques, and exploring advanced RAG \\n architectures. \\n Recent research trends highlight a focus on extending RAG to handle multimodal data, \\n such as images and audio, and on developing more sophisticated retrieval and \\n reasoning mechanisms. The future outlook for RAG technology is promising, with \\n ongoing efforts aimed at creating more dynamic, adaptive, and intelligent systems'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 42, 'page_label': '43'}, page_content='that can learn and improve over time. The integration of RAG with other NLP \\n techniques, particularly prompt engineering, will likely continue to be a key area of \\n development, allowing for more nuanced control over AI behavior and output quality. \\n While RAG and fine-tuning serve different primary purposes, their potential for \\n synergistic use suggests a future where both techniques are strategically employed to \\n maximize the benefits of large language models across a diverse array of applications. \\n Works cited \\n 1.  aws.amazon.com, accessed on April 16, 2025, \\n https://aws.amazon.com/what-is/retrieval-augmented-generation/#:~:text=Retrie \\n val%2DAugmented%20Generation%20(RAG),sources%20before%20generating \\n %20a%20response. \\n 2.  What is RAG? - Retrieval-Augmented Generation AI Explained - AWS, accessed \\n on April 16, 2025, \\n https://aws.amazon.com/what-is/retrieval-augmented-generation/ \\n 3.  What is retrieval-augmented generation (RAG)? - Box, accessed on April 16, 2025,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 42, 'page_label': '43'}, page_content='on April 16, 2025, \\n https://aws.amazon.com/what-is/retrieval-augmented-generation/ \\n 3.  What is retrieval-augmented generation (RAG)? - Box, accessed on April 16, 2025, \\n https://www.box.com/resources/what-is-retrieval-augmented-generation \\n 4.  What is Retrieval Augmented Generation (RAG)? | Confluent, accessed on April \\n 16, 2025,  https://www.confluent.io/learn/retrieval-augmented-generation-rag/ \\n 5.  Retrieval-Augmented Generation (RAG) Guide: What is RAG? - DataStax, \\n accessed on April 16, 2025, \\n https://www.datastax.com/guides/what-is-retrieval-augmented-generation \\n 6.  What is Retrieval-Augmented Generation (RAG)? - Analytics Vidhya, accessed on \\n April 16, 2025, \\n https://www.analyticsvidhya.com/blog/2023/09/retrieval-augmented-generation- \\n rag-in-ai/ \\n 7.  What is retrieval-augmented generation (RAG)? - IBM Research, accessed on \\n April 16, 2025, \\n https://research.ibm.com/blog/retrieval-augmented-generation-RAG'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 42, 'page_label': '43'}, page_content='rag-in-ai/ \\n 7.  What is retrieval-augmented generation (RAG)? - IBM Research, accessed on \\n April 16, 2025, \\n https://research.ibm.com/blog/retrieval-augmented-generation-RAG \\n 8.  Retrieval-augmented generation - Wikipedia, accessed on April 16, 2025, \\n https://en.wikipedia.org/wiki/Retrieval-augmented_generation \\n 9.  What Is Retrieval-Augmented Generation aka RAG - NVIDIA Blog, accessed on \\n April 16, 2025, \\n https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/ \\n 10.  Understanding RAG: 6 Steps of Retrieval Augmented Generation (RAG) - Acorn \\n Labs, accessed on April 16, 2025, \\n https://www.acorn.io/resources/learning-center/retrieval-augmented-generation/ \\n 11.  What is Retrieval Augmented Generation? Definition and FAQs - Gretel.ai, \\n accessed on April 16, 2025, \\n https://gretel.ai/technical-glossary/what-is-retrieval-augmented-generation-rag \\n 12.  Introduction to Retrieval Augmented Generation (RAG) - Weaviate, accessed on'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 42, 'page_label': '43'}, page_content='accessed on April 16, 2025, \\n https://gretel.ai/technical-glossary/what-is-retrieval-augmented-generation-rag \\n 12.  Introduction to Retrieval Augmented Generation (RAG) - Weaviate, accessed on \\n April 16, 2025,  https://weaviate.io/blog/introduction-to-rag \\n 13.  Retrieval Augmented Generation (RAG) - Pinecone, accessed on April 16, 2025,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 43, 'page_label': '44'}, page_content='https://www.pinecone.io/learn/retrieval-augmented-generation/ \\n 14.  Retrieval Augmented Generation (RAG) in Azure AI Search - Learn Microsoft, \\n accessed on April 16, 2025, \\n https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation- \\n overview \\n 15.  What is Retrieval Augmented Generation (RAG)? - Databricks, accessed on April \\n 16, 2025, \\n https://www.databricks.com/glossary/retrieval-augmented-generation-rag \\n 16.  What Is Retrieval-Augmented Generation (RAG)? | Salesforce US, accessed on \\n April 16, 2025,  https://www.salesforce.com/agentforce/what-is-rag/ \\n 17.  Retrieval augmented generation (RAG) -   LangChain, accessed on April 16, 2025, \\n https://python.langchain.com/docs/concepts/rag/ \\n 18.  Retrieval Augmented Generation (RAG) - Prompt Engineering Guide, accessed \\n on April 16, 2025,  https://www.promptingguide.ai/techniques/rag \\n 19.  RAG 101: Demystifying Retrieval-Augmented Generation Pipelines | NVIDIA \\n Technical Blog, accessed on April 16, 2025,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 43, 'page_label': '44'}, page_content=\"on April 16, 2025,  https://www.promptingguide.ai/techniques/rag \\n 19.  RAG 101: Demystifying Retrieval-Augmented Generation Pipelines | NVIDIA \\n Technical Blog, accessed on April 16, 2025, \\n https://developer.nvidia.com/blog/rag-101-demystifying-retrieval-augmented-ge \\n neration-pipelines/ \\n 20.  What Is RAG? Use Cases, Limitations, and Challenges - Bright Data, accessed on \\n April 16, 2025,  https://brightdata.com/blog/web-data/rag-explained \\n 21.  Retrieval-Augmented Generation: Challenges & Solutions - Chitika, accessed on \\n April 16, 2025,  https://www.chitika.com/rag-challenges-and-solution/ \\n 22.  AI has limitations. Here's how Retrieval-Augmented Generation (RAG) helps solve \\n them., accessed on April 16, 2025, \\n https://signal-ai.com/insights/ai-has-limitations-heres-how-retrieval-augmented- \\n generation-rag-helps-solve-them/ \\n 23.  12 RAG Framework Challenges for Effective LLM Applications - Data Science \\n Dojo, accessed on April 16, 2025,\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 43, 'page_label': '44'}, page_content='generation-rag-helps-solve-them/ \\n 23.  12 RAG Framework Challenges for Effective LLM Applications - Data Science \\n Dojo, accessed on April 16, 2025, \\n https://datasciencedojo.com/blog/rag-framework-challenges-in-llm/ \\n 24.  How to Get Really Good at Retrieval-Augmented Generation (RAG) - Chitika, \\n accessed on April 16, 2025,  https://www.chitika.com/how-to-get-good-at-rag/ \\n 25.  RAG vs Prompt Engineering: Getting the Best of Both Worlds - K2view, accessed \\n on April 16, 2025,  https://www.k2view.com/blog/rag-vs-prompt-engineering/ \\n 26.  Prompt Engineering and Retrieval Augmented Generation (RAG) - RagaAI- Blog, \\n accessed on April 16, 2025,  https://raga.ai/blogs/rag-prompt-engineering \\n 27.  RAG vs Fine-Tuning vs Prompt Engineering: And the Winner is... - K2view, \\n accessed on April 16, 2025, \\n https://www.k2view.com/blog/rag-vs-fine-tuning-vs-prompt-engineering/ \\n 28.  RAG vs. Fine-tuning - IBM, accessed on April 16, 2025, \\n https://www.ibm.com/think/topics/rag-vs-fine-tuning'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 43, 'page_label': '44'}, page_content='https://www.k2view.com/blog/rag-vs-fine-tuning-vs-prompt-engineering/ \\n 28.  RAG vs. Fine-tuning - IBM, accessed on April 16, 2025, \\n https://www.ibm.com/think/topics/rag-vs-fine-tuning \\n 29.  RAG vs fine-tuning vs. prompt engineering - IBM, accessed on April 16, 2025, \\n https://www.ibm.com/think/topics/rag-vs-fine-tuning-vs-prompt-engineering \\n 30.  Generative AI: RAG Implementation vs. Prompt Engineering - DZone, accessed on \\n April 16, 2025, \\n https://dzone.com/articles/rag-implementation-vs-prompt-engineering'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 44, 'page_label': '45'}, page_content='31.  6 Ways for Optimizing RAG Performance - Hyperight, accessed on April 16, 2025, \\n https://hyperight.com/6-ways-for-optimizing-rag-performance/ \\n 32.  Techniques to Enhance Retrieval Augmented Generation (RAG) - \\n Community.aws, accessed on April 16, 2025, \\n https://community.aws/content/2gp2m3BJcl9mSMWT6njCIQNiz0e/techniques-to \\n -enhance-retrieval-augmented-generation-rag \\n 33.  RAG Vs Fine Tuning: How To Choose The Right Method - Monte Carlo Data, \\n accessed on April 16, 2025, \\n https://www.montecarlodata.com/blog-rag-vs-fine-tuning/ \\n 34.  RAG vs. Fine-Tuning: How to Choose - Oracle, accessed on April 16, 2025, \\n https://www.oracle.com/artificial-intelligence/generative-ai/retrieval-augmented- \\n generation-rag/rag-fine-tuning/ \\n 35.  Retrieval-Augmented Generation for Natural Language Processing: A Survey - \\n arXiv, accessed on April 16, 2025,  https://arxiv.org/pdf/2407.13193 \\n 36.  Challenges with RAG : r/Rag - Reddit, accessed on April 16, 2025,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 44, 'page_label': '45'}, page_content='arXiv, accessed on April 16, 2025,  https://arxiv.org/pdf/2407.13193 \\n 36.  Challenges with RAG : r/Rag - Reddit, accessed on April 16, 2025, \\n https://www.reddit.com/r/Rag/comments/1ex94nj/challenges_with_rag/ \\n 37.  Navigating Retrieval Augmented Generation (RAG) Challenges and \\n Opportunities, accessed on April 16, 2025, \\n https://www.flybridge.com/ideas/navigating-retrieval-augmented-generation-rag \\n -challenges-and-opportunities \\n 38.  Rise and Limits of Basic Retrieval-Augmented Generation - Artiquare, accessed \\n on April 16, 2025, \\n https://www.artiquare.com/limits-of-retrieval-augmented-generation/ \\n 39.  How to improve the performance of a RAG model - DataScienceCentral.com, \\n accessed on April 16, 2025, \\n https://www.datasciencecentral.com/how-to-improve-the-performance-of-a-ra \\n g-model/ \\n 40.  Top 7 Challenges with Retrieval-Augmented Generation - Valprovia, accessed on \\n April 16, 2025, \\n https://www.valprovia.com/en/blog/top-7-challenges-with-retrieval-augmented-'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 44, 'page_label': '45'}, page_content='g-model/ \\n 40.  Top 7 Challenges with Retrieval-Augmented Generation - Valprovia, accessed on \\n April 16, 2025, \\n https://www.valprovia.com/en/blog/top-7-challenges-with-retrieval-augmented- \\n generation \\n 41.  How to Improve RAG Performance: 5 Key Techniques with Examples | DataCamp, \\n accessed on April 16, 2025, \\n https://www.datacamp.com/tutorial/how-to-improve-rag-performance-5-key-te \\n chniques-with-examples \\n 42.  An Overview of Methods to Effectively Improve RAG Performance - Alibaba \\n Cloud, accessed on April 16, 2025, \\n https://www.alibabacloud.com/blog/an-overview-of-methods-to-effectively-impr \\n ove-rag-performance_601725 \\n 43.  Chain-of-Retrieval Augmented Generation - arXiv, accessed on April 16, 2025, \\n https://arxiv.org/html/2501.14342v1 \\n 44.  Four retrieval techniques to improve RAG you need to know | Thoughtworks \\n United States, accessed on April 16, 2025, \\n https://www.thoughtworks.com/en-us/insights/blog/generative-ai/four-retrieval-t \\n echniques-improve-rag'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 45, 'page_label': '46'}, page_content='45.  Large Language Model Can Be a Foundation for Hidden Rationale-Based Retrieval \\n - arXiv, accessed on April 16, 2025,  https://arxiv.org/html/2412.16615v2 \\n 46.  Enhancing Retrieval-Augmented Generation: A Study of Best Practices - arXiv, \\n accessed on April 16, 2025,  https://arxiv.org/html/2501.07391v1 \\n 47.  HD-RAG: Retrieval-Augmented Generation for Hybrid Documents Containing \\n Text and Hierarchical Tables - arXiv, accessed on April 16, 2025, \\n https://arxiv.org/html/2504.09554v1 \\n 48.  Retrieval Augmented Generation and Understanding in Vision: A Survey and New \\n Outlook, accessed on April 16, 2025,  https://arxiv.org/html/2503.18016v1 \\n 49.  Retrieving Multimodal Information for Augmented Generation: A Survey - arXiv, \\n accessed on April 16, 2025,  https://arxiv.org/html/2303.10868 \\n 50.  Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting \\n Framework - ACL Anthology, accessed on April 16, 2025,'), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 45, 'page_label': '46'}, page_content=\"50.  Controlling Risk of Retrieval-augmented Generation: A Counterfactual Prompting \\n Framework - ACL Anthology, accessed on April 16, 2025, \\n https://aclanthology.org/2024.findings-emnlp.133.pdf \\n 51.  Retrieval-Augmented Generation vs Fine-Tuning: What's Right for You? - K2view, \\n accessed on April 16, 2025, \\n https://www.k2view.com/blog/retrieval-augmented-generation-vs-fine-tuning/ \\n 52.  Fine-tuning vs. RAG: Understanding the Difference - FinetuneDB, accessed on \\n April 16, 2025,  https://finetunedb.com/blog/fine-tuning-vs-rag/ \\n 53.  What's the difference between RAG and Fine-Tuning? - Lengoo, accessed on \\n April 16, 2025, \\n https://www.lengoo.com/blog/whats-the-difference-between-rag-and-fine-tunin \\n g \\n 54.  RAG vs Fine-Tuning , What would you pick and why? : r/LLMDevs - Reddit, \\n accessed on April 16, 2025, \\n https://www.reddit.com/r/LLMDevs/comments/1j5fzjn/rag_vs_finetuning_what_wo \\n uld_you_pick_and_why/\"), Document(metadata={'producer': 'Skia/PDF m135', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0', 'creationdate': '2025-04-15T19:09:13+00:00', 'title': 'RAG: Definition and Applications - Google Docs', 'moddate': '2025-04-15T19:09:13+00:00', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\RAG.pdf', 'total_pages': 46, 'page': 45, 'page_label': '46'}, page_content=\"accessed on April 16, 2025, \\n https://www.reddit.com/r/LLMDevs/comments/1j5fzjn/rag_vs_finetuning_what_wo \\n uld_you_pick_and_why/ \\n 55.  The Contrast Between RAG and Fine-Tuning Models for Tech Enthusiasts — AI \\n Simplified, accessed on April 16, 2025, \\n https://geekyants.com/blog/the-contrast-between-rag-and-fine-tuning-models- \\n for-tech-enthusiasts--ai-simplified \\n 56.  RAG, Prompt Engineering, Fine Tuning: What's the Difference? - New Horizons, \\n accessed on April 16, 2025, \\n https://www.newhorizons.com/resources/blog/rag-vs-prompt-engineering-vs-fin \\n e-funing \\n 57.  RAG vs Fine-Tuning vs Prompt Engineering: Optimizing AI Models - YouTube, \\n accessed on April 16, 2025,  https://www.youtube.com/watch?v=zYGDpG-pTho \\n 58.  Prompt engineering for RAG - OpenAI Developer Forum, accessed on April 16, \\n 2025,  https://community.openai.com/t/prompt-engineering-for-rag/621495\")]\n",
      "[945, 943, 935, 614, 978, 916, 981, 788, 940, 986, 949, 425, 993, 978, 991, 377, 939, 986, 936, 286, 919, 970, 978, 522, 976, 976, 939, 353, 971, 930, 973, 383, 976, 935, 963, 420, 954, 949, 921, 529, 959, 938, 921, 376, 999, 986, 976, 301, 963, 942, 952, 499, 958, 941, 956, 385, 942, 958, 945, 339, 986, 951, 924, 345, 988, 930, 951, 273, 923, 990, 993, 212, 946, 996, 949, 399, 968, 944, 960, 392, 928, 970, 937, 511, 933, 941, 986, 213, 973, 924, 963, 386, 977, 943, 935, 447, 992, 921, 978, 194, 931, 959, 975, 416, 977, 932, 966, 357, 945, 929, 992, 397, 949, 928, 987, 386, 956, 983, 963, 254, 959, 929, 937, 255, 999, 975, 951, 264, 987, 978, 947, 377, 966, 969, 976, 248, 987, 938, 964, 333, 917, 984, 972, 933, 981, 942, 539, 916, 957, 929, 409, 871, 981, 669, 984, 918, 974, 538, 947, 947, 920, 417, 994, 941, 961, 341, 997, 963, 996, 518, 969, 991, 993, 946, 929, 883]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "path_to_pdf =  r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\RAG.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path=path_to_pdf)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(chunks)\n",
    "print([len(chunk.page_content) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c147b9f1",
   "metadata": {},
   "source": [
    "## Embedding and Storage\n",
    "Embedding represents chunks in vector form to enable similarity search. LangChain supports OpenAI and ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bcf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    api_key=openai_api_key,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2ce6fa",
   "metadata": {},
   "source": [
    "## Building LCEL Retrieval Chain\n",
    "LangChain Expression Language (LCEL) allows declarative pipeline construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0339092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, say that you don't know.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a07244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=\"...\", temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a439e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"question\": \"What are the key findings or results presented in the paper?\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
