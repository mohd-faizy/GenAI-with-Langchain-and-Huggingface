{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3154b31c",
   "metadata": {},
   "source": [
    "# **Retrieval-Augmented Generation (RAG)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b92ba7",
   "metadata": {},
   "source": [
    "## ‚≠êIntroduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b2fda6",
   "metadata": {},
   "source": [
    "RAG is a powerful technique used in Large Language Model (LLM) applications to **enhance responses** by **retrieving relevant context** from external sources like `document stores`, `knowledge bases`, or `databases`.\n",
    "\n",
    "### üß† **RAG Workflow (inshort)**\n",
    "\n",
    "1. üü° **User Prompt**\n",
    "   * The user provides a natural language question or prompt.\n",
    "\n",
    "2. üî§ **Embedding Model**\n",
    "   * The prompt is passed into an **embedding model**, which converts it into a **vector** (numerical representation of semantic meaning).\n",
    "\n",
    "3. üì¶ **Vector Database**\n",
    "   * The vector is sent to a **vector database** that contains pre-embedded document chunks.\n",
    "   * It performs a **similarity search** to find the **most relevant document chunks**.\n",
    "\n",
    "4. üìÑ **Most Similar Documents**\n",
    "   * The top-matching chunks (based on vector similarity) are retrieved.\n",
    "\n",
    "5. üßæ **Prompt Template Construction**\n",
    "   * A **prompt template** is created that includes:\n",
    "\n",
    "     * üîπ Instructions (optional)\n",
    "     * üîπ The original **user prompt**\n",
    "     * üîπ The **retrieved document chunks** (context)\n",
    "\n",
    "6. ü§ñ **LLM (Large Language Model)**\n",
    "   * The complete prompt is passed to the **LLM**.\n",
    "   * The LLM uses both the prompt and the retrieved context to generate a **context-aware response**.\n",
    "\n",
    "7. ‚úÖ **Output**\n",
    "   * The final, enriched answer is returned to the user.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ **Feedback Loop (Optional)**\n",
    "\n",
    "* The output can also be fed back to the system for:\n",
    "\n",
    "  * Further refinement\n",
    "  * Re-ranking\n",
    "  * Memory-based updates\n",
    "\n",
    "\n",
    "\n",
    "> This workflow helps RAG **bridge the gap between static LLM knowledge and dynamic, up-to-date external information**, improving factual accuracy and relevance.\n",
    "\n",
    "![RAG Workflow](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_Developing_LLMs_Applications_with_LangChain/_img/0301.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5df07",
   "metadata": {},
   "source": [
    "### üß© **Key Components of a RAG Workflow**\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå 1. Embeddings for Semantic Retrieval\n",
    "\n",
    "- üî∏ Converts text into **dense vector representations** using an embedding model.\n",
    "- üî∏ These vectors capture **semantic meaning**, not just keywords.\n",
    "- üî∏ Used to compare and retrieve similar content from a document store.\n",
    "\n",
    "##### ‚úÖ Common Embedding Models:\n",
    "- `OpenAI` ‚Üí `text-embedding-3-small`\n",
    "- `Gemini` ‚Üí `gemini-1.5-flash`\n",
    "- `SentenceTransformers` ‚Üí `all-MiniLM-L6-v2`\n",
    "- `Hugging Face` ‚Üí `intfloat/e5-large`, `BAAI/bge-large-en`\n",
    "\n",
    "##### üß™ Code Example:\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "query_vector = embedding.embed_query(\"User prompt\")\n",
    "\n",
    "from langchain_google import GeminiEmbeddings\n",
    "embedding = GeminiEmbeddings(model=\"gemini-1.5-flash\")\n",
    "query_vector = embedding.embed_query(\"User prompt\")\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "#### üóÉÔ∏è 2. Vector Database for Storage & Retrieval\n",
    "\n",
    "* üî∏ Stores document embeddings.\n",
    "* üî∏ Supports **similarity search** to fetch the most relevant chunks.\n",
    "\n",
    "##### ‚úÖ Popular Vector Stores:\n",
    "\n",
    "* `Chroma` (LangChain-native)\n",
    "* `FAISS` (open-source, local)\n",
    "* `Pinecone` (cloud, scalable)\n",
    "* `Weaviate`, `Qdrant`, `Milvus` (advanced features)\n",
    "\n",
    "##### üß™ Code Example:\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "docsearch = FAISS.from_documents(documents, embedding)\n",
    "results = docsearch.similarity_search(\"User prompt\", k=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### üßæ 3. Prompt Engineering & Chaining\n",
    "\n",
    "* üî∏ Retrieved documents are merged with the user's question.\n",
    "* üî∏ A **prompt template** is used to structure this input to the LLM.\n",
    "\n",
    "##### üß± Prompt Template Example:\n",
    "\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"Answer based on context:\\n{context}\\n\\nQuestion: {question}\"\n",
    ")\n",
    "```\n",
    "\n",
    "##### üîó Chain With LLM:\n",
    "\n",
    "```python\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=OpenAI(), prompt=template)\n",
    "response = chain.run({\"context\": retrieved_docs, \"question\": user_prompt})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### üìÇ 4. Document Loaders\n",
    "\n",
    "* üî∏ Load documents of various formats into LangChain.\n",
    "* üî∏ Extract text for further processing and embedding.\n",
    "\n",
    "##### ‚úÖ Supported Formats:\n",
    "\n",
    "`.pdf`, `.csv`, `.docx`, `.html`, `.md`, `.pptx`, `.email`, etc.\n",
    "\n",
    "##### üß™ Code Example:\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"document.pdf\")\n",
    "documents = loader.load()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÇÔ∏è 5. Document Splitting (Chunking)\n",
    "\n",
    "* üî∏ LLMs have limited context windows ‚Äî so long documents must be split.\n",
    "* üî∏ Splitters create **overlapping chunks** to preserve context.\n",
    "\n",
    "##### ‚úÖ Common Text Splitters:\n",
    "\n",
    "* `CharacterTextSplitter`\n",
    "* `RecursiveCharacterTextSplitter` (preferred for preserving semantics)\n",
    "* `TokenTextSplitter` (based on token count)\n",
    "\n",
    "##### üß™ Code Example:\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(documents)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03350fce",
   "metadata": {},
   "source": [
    "**Key Topics Covered:**\n",
    "- Document loaders\n",
    "- Text splitting strategies\n",
    "- Vector databases\n",
    "- Prompt chaining\n",
    "- End-to-end RAG example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76915855",
   "metadata": {},
   "source": [
    "## ‚≠ê1. Integrating Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2210130",
   "metadata": {},
   "source": [
    "**Concept Overview:**\n",
    "- LangChain provides document loader classes to load data from different formats.\n",
    "- Supported formats include `.pdf`, `.csv`, `.html`, and third-party sources.\n",
    "- This step is essential for feeding content into your LLM applications.\n",
    "\n",
    "**Supported Loaders:**\n",
    "- `PyPDFLoader` for PDF files\n",
    "- `CSVLoader` for CSV files\n",
    "- `UnstructuredHTMLLoader` for HTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294598ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Loader Example\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Use r\"...\" for Windows paths to handle backslashes, or use forward slashes /.\n",
    "path = r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\attention_is_all_you_need.pdf\"\n",
    "\n",
    "# Load the PDF document\n",
    "loader = PyPDFLoader(path)\n",
    "\n",
    "data = loader.load()\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Loader Example\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "path = r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\fifa_countries_audience.csv\"\n",
    "\n",
    "loader = CSVLoader(path)\n",
    "data = loader.load()\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585d19b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='October 30, 2023\n",
      "\n",
      "Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence\n",
      "\n",
      "By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows:\n",
      "\n",
      "Section 1. Purpose. Artificial intelligence (AI) holds extraordinary potential for both promise and peril. Responsible AI use has the potential to help solve urgent challenges while making our world more prosperous, productive, innovative, and secure. At the same time, irresponsible use could exacerbate societal harms such as fraud, discrimination, bias, and disinformation; displace and disempower workers; stifle competition; and pose risks to national security. Harnessing AI for good and realizing its myriad benefits requires mitigating its substantial risks. This endeavor demands a society-wide effort that includes government, the private sector, academia, and civil society.\n",
      "\n",
      "My Administration places the highest urgency on governing the development and use of AI safely and responsibly, and is therefore advancing a coordinated, Federal Government-wide approach to doing so. The rapid speed at which AI capabilities are advancing compels the United States to lead in this moment for the sake of our security, economy, and society.\n",
      "\n",
      "In the end, AI reflects the principles of the people who build it, the people who use it, and the data upon which it is built. I firmly believe that the power of our ideals; the foundations of our society; and the creativity, diversity, and decency of our people are the reasons that America thrived in past eras of rapid change. They are the reasons we will succeed again in this moment. We are more than capable of harnessing AI for justice, security, and opportunity for all.\n",
      "\n",
      "Sec. 2. Policy and Principles. It is the policy of my Administration to advance and govern the development and use of AI in accordance with eight guiding principles and priorities. When undertaking the actions set forth in this order, executive departments and agencies (agencies) shall, as appropriate and consistent with applicable law, adhere to these principles, while, as feasible, taking into account the views of other agencies, industry, members of academia, civil society, labor unions, international allies and partners, and other relevant organizations:\n",
      "\n",
      "(a) Artificial Intelligence must be safe and secure. Meeting this goal requires robust, reliable, repeatable, and standardized evaluations of AI systems, as well as policies, institutions, and, as appropriate, other mechanisms to test, understand, and mitigate risks from these systems before they are put to use. It also requires addressing AI systems‚Äô most pressing security risks ‚Äî including with respect to biotechnology, cybersecurity, critical infrastructure, and other national security dangers ‚Äî while navigating AI‚Äôs opacity and complexity. Testing and evaluations, including post-deployment performance monitoring, will help ensure that AI systems function as intended, are resilient against misuse or dangerous modifications, are ethically developed and operated in a secure manner, and are compliant with applicable Federal laws and policies. Finally, my Administration will help develop effective labeling and content provenance mechanisms, so that Americans are able to determine when content is generated using AI and when it is not. These actions will provide a vital foundation for an approach that addresses AI‚Äôs risks without unduly reducing its benefits.\n",
      "\n",
      "(b) Promoting responsible innovation, competition, and collaboration will allow the United States to lead in AI and unlock the technology‚Äôs potential to solve some of society‚Äôs most difficult challenges. This effort requires investments in AI-related education, training, development, research, and capacity, while simultaneously tackling novel intellectual property (IP) questions and other problems to protect inventors and creators. Across the Federal Government, my Administration will support programs to provide Americans the skills they need for the age of AI and attract the world‚Äôs AI talent to our shores ‚Äî not just to study, but to stay ‚Äî so that the companies and technologies of the future are made in America. The Federal Government will promote a fair, open, and competitive ecosystem and marketplace for AI and related technologies so that small developers and entrepreneurs can continue to drive innovation. Doing so requires stopping unlawful collusion and addressing risks from dominant firms‚Äô use of key assets such as semiconductors, computing power, cloud storage, and data to disadvantage competitors, and it requires supporting a marketplace that harnesses the benefits of AI to provide new opportunities for small businesses, workers, and entrepreneurs.\n",
      "\n",
      "(c) The responsible development and use of AI require a commitment to supporting American workers. As AI creates new jobs and industries, all workers need a seat at the table, including through collective bargaining, to ensure that they benefit from these opportunities. My Administration will seek to adapt job training and education to support a diverse workforce and help provide access to opportunities that AI creates. In the workplace itself, AI should not be deployed in ways that undermine rights, worsen job quality, encourage undue worker surveillance, lessen market competition, introduce new health and safety risks, or cause harmful labor-force disruptions. The critical next steps in AI development should be built on the views of workers, labor unions, educators, and employers to support responsible uses of AI that improve workers‚Äô lives, positively augment human work, and help all people safely enjoy the gains and opportunities from technological innovation.\n",
      "\n",
      "(d) Artificial Intelligence policies must be consistent with my Administration‚Äôs dedication to advancing equity and civil rights. My Administration cannot ‚Äî and will not ‚Äî tolerate the use of AI to disadvantage those who are already too often denied equal opportunity and justice. From hiring to housing to healthcare, we have seen what happens when AI use deepens discrimination and bias, rather than improving quality of life. Artificial Intelligence systems deployed irresponsibly have reproduced and intensified existing inequities, caused new types of harmful discrimination, and exacerbated online and physical harms. My Administration will build on the important steps that have already been taken ‚Äî such as issuing the Blueprint for an AI Bill of Rights, the AI Risk Management Framework, and Executive Order 14091 of February 16, 2023 (Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government) ‚Äî in seeking to ensure that AI complies with all Federal laws and to promote robust technical evaluations, careful oversight, engagement with affected communities, and rigorous regulation. It is necessary to hold those developing and deploying AI accountable to standards that protect against unlawful discrimination and abuse, including in the justice system and the Federal Government. Only then can Americans trust AI to advance civil rights, civil liberties, equity, and justice for all.\n",
      "\n",
      "(e) The interests of Americans who increasingly use, interact with, or purchase AI and AI-enabled products in their daily lives must be protected. Use of new technologies, such as AI, does not excuse organizations from their legal obligations, and hard-won consumer protections are more important than ever in moments of technological change. The Federal Government will enforce existing consumer protection laws and principles and enact appropriate safeguards against fraud, unintended bias, discrimination, infringements on privacy, and other harms from AI. Such protections are especially important in critical fields like healthcare, financial services, education, housing, law, and transportation, where mistakes by or misuse of AI could harm patients, cost consumers or small businesses, or jeopardize safety or rights. At the same time, my Administration will promote responsible uses of AI that protect consumers, raise the quality of goods and services, lower their prices, or expand selection and availability.\n",
      "\n",
      "(f) Americans‚Äô privacy and civil liberties must be protected as AI continues advancing. Artificial Intelligence is making it easier to extract, re-identify, link, infer, and act on sensitive information about people‚Äôs identities, locations, habits, and desires. Artificial Intelligence‚Äôs capabilities in these areas can increase the risk that personal data could be exploited and exposed. To combat this risk, the Federal Government will ensure that the collection, use, and retention of data is lawful, is secure, and mitigates privacy and confidentiality risks. Agencies shall use available policy and technical tools, including privacy-enhancing technologies (PETs) where appropriate, to protect privacy and to combat the broader legal and societal risks ‚Äî including the chilling of First Amendment rights ‚Äî that result from the improper collection and use of people‚Äôs data.\n",
      "\n",
      "(g) It is important to manage the risks from the Federal Government‚Äôs own use of AI and increase its internal capacity to regulate, govern, and support responsible use of AI to deliver better results for Americans. These efforts start with people, our Nation‚Äôs greatest asset. My Administration will take steps to attract, retain, and develop public service-oriented AI professionals, including from underserved communities, across disciplines ‚Äî including technology, policy, managerial, procurement, regulatory, ethical, governance, and legal fields ‚Äî and ease AI professionals‚Äô path into the Federal Government to help harness and govern AI. The Federal Government will work to ensure that all members of its workforce receive adequate training to understand the benefits, risks, and limitations of AI for their job functions, and to modernize Federal Government information technology infrastructure, remove bureaucratic obstacles, and ensure that safe and rights-respecting AI is adopted, deployed, and used.\n",
      "\n",
      "(h) The Federal Government should lead the way to global societal, economic, and technological progress, as the United States has in previous eras of disruptive innovation and change. This leadership is not measured solely by the technological advancements our country makes. Effective leadership also means pioneering those systems and safeguards needed to deploy technology responsibly ‚Äî and building and promoting those safeguards with the rest of the world. My Administration will engage with international allies and partners in developing a framework to manage AI‚Äôs risks, unlock AI‚Äôs potential for good, and promote common approaches to shared challenges. The Federal Government will seek to promote responsible AI safety and security principles and actions with other nations, including our competitors, while leading key global conversations and collaborations to ensure that AI benefits the whole world, rather than exacerbating inequities, threatening human rights, and causing other harms.\n",
      "\n",
      "Sec. 3. Definitions. For purposes of this order:\n",
      "\n",
      "(a) The term ‚Äúagency‚Äù means each agency described in 44 U.S.C. 3502(1), except for the independent regulatory agencies described in 44 U.S.C. 3502(5).\n",
      "\n",
      "(b) The term ‚Äúartificial intelligence‚Äù or ‚ÄúAI‚Äù has the meaning set forth in 15 U.S.C. 9401(3): a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action.\n",
      "\n",
      "(c) The term ‚ÄúAI model‚Äù means a component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs.\n",
      "\n",
      "(d) The term ‚ÄúAI red-teaming‚Äù means a structured testing effort to find flaws and vulnerabilities in an AI system, often in a controlled environment and in collaboration with developers of AI. Artificial Intelligence red-teaming is most often performed by dedicated ‚Äúred teams‚Äù that adopt adversarial methods to identify flaws and vulnerabilities, such as harmful or discriminatory outputs from an AI system, unforeseen or undesirable system behaviors, limitations, or potential risks associated with the misuse of the system.\n",
      "\n",
      "(e) The term ‚ÄúAI system‚Äù means any data system, software, hardware, application, tool, or utility that operates in whole or in part using AI.\n",
      "\n",
      "(f) The term ‚Äúcommercially available information‚Äù means any information or data about an individual or group of individuals, including an individual‚Äôs or group of individuals‚Äô device or location, that is made available or obtainable and sold, leased, or licensed to the general public or to governmental or non-governmental entities.\n",
      "\n",
      "(g) The term ‚Äúcrime forecasting‚Äù means the use of analytical techniques to attempt to predict future crimes or crime-related information. It can include machine-generated predictions that use algorithms to analyze large volumes of data, as well as other forecasts that are generated without machines and based on statistics, such as historical crime statistics.\n",
      "\n",
      "(h) The term ‚Äúcritical and emerging technologies‚Äù means those technologies listed in the February 2022 Critical and Emerging Technologies List Update issued by the National Science and Technology Council (NSTC), as amended by subsequent updates to the list issued by the NSTC.\n",
      "\n",
      "(i) The term ‚Äúcritical infrastructure‚Äù has the meaning set forth in section 1016(e) of the USA PATRIOT Act of 2001, 42 U.S.C. 5195c(e).\n",
      "\n",
      "(j) The term ‚Äúdifferential-privacy guarantee‚Äù means protections that allow information about a group to be shared while provably limiting the improper access, use, or disclosure of personal information about particular entities.\n",
      "\n",
      "(k) The term ‚Äúdual-use foundation model‚Äù means an AI model that is trained on broad data; generally uses self-supervision; contains at least tens of billions of parameters; is applicable across a wide range of contexts; and that exhibits, or could be easily modified to exhibit, high levels of performance at tasks that pose a serious risk to security, national economic security, national public health or safety, or any combination of those matters, such as by:\n",
      "\n",
      "(i) substantially lowering the barrier of entry for non-experts to design, synthesize, acquire, or use chemical, biological, radiological, or nuclear (CBRN) weapons;\n",
      "\n",
      "(ii) enabling powerful offensive cyber operations through automated vulnerability discovery and exploitation against a wide range of potential targets of cyber attacks; or\n",
      "\n",
      "(iii) permitting the evasion of human control or oversight through means of deception or obfuscation.\n",
      "\n",
      "Models meet this definition even if they are provided to end users with technical safeguards that attempt to prevent users from taking advantage of the relevant unsafe capabilities.\n",
      "\n",
      "(l) The term ‚ÄúFederal law enforcement agency‚Äù has the meaning set forth in section 21(a) of Executive Order 14074 of May 25, 2022 (Advancing Effective, Accountable Policing and Criminal Justice Practices To Enhance Public Trust and Public Safety).\n",
      "\n",
      "(m) The term ‚Äúfloating-point operation‚Äù means any mathematical operation or assignment involving floating-point numbers, which are a subset of the real numbers typically represented on computers by an integer of fixed precision scaled by an integer exponent of a fixed base.\n",
      "\n",
      "(n) The term ‚Äúforeign person‚Äù has the meaning set forth in section 5(c) of Executive Order 13984 of January 19, 2021 (Taking Additional Steps To Address the National Emergency With Respect to Significant Malicious Cyber-Enabled Activities).\n",
      "\n",
      "(o) The terms ‚Äúforeign reseller‚Äù and ‚Äúforeign reseller of United States Infrastructure as a Service Products‚Äù mean a foreign person who has established an Infrastructure as a Service Account to provide Infrastructure as a Service Products subsequently, in whole or in part, to a third party.\n",
      "\n",
      "(p) The term ‚Äúgenerative AI‚Äù means the class of AI models that emulate the structure and characteristics of input data in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital content.\n",
      "\n",
      "(q) The terms ‚ÄúInfrastructure as a Service Product,‚Äù ‚ÄúUnited States Infrastructure as a Service Product,‚Äù ‚ÄúUnited States Infrastructure as a Service Provider,‚Äù and ‚ÄúInfrastructure as a Service Account‚Äù each have the respective meanings given to those terms in section 5 of Executive Order 13984.\n",
      "\n",
      "(r) The term ‚Äúinteger operation‚Äù means any mathematical operation or assignment involving only integers, or whole numbers expressed without a decimal point.\n",
      "\n",
      "(s) The term ‚ÄúIntelligence Community‚Äù has the meaning given to that term in section 3.5(h) of Executive Order 12333 of December 4, 1981 (United States Intelligence Activities), as amended.\n",
      "\n",
      "(t) The term ‚Äúmachine learning‚Äù means a set of techniques that can be used to train AI algorithms to improve performance at a task based on data.\n",
      "\n",
      "(u) The term ‚Äúmodel weight‚Äù means a numerical parameter within an AI model that helps determine the model‚Äôs outputs in response to inputs.\n",
      "\n",
      "(v) The term ‚Äúnational security system‚Äù has the meaning set forth in 44 U.S.C. 3552(b)(6).\n",
      "\n",
      "(w) The term ‚Äúomics‚Äù means biomolecules, including nucleic acids, proteins, and metabolites, that make up a cell or cellular system.\n",
      "\n",
      "(x) The term ‚ÄúOpen RAN‚Äù means the Open Radio Access Network approach to telecommunications-network standardization adopted by the O-RAN Alliance, Third Generation Partnership Project, or any similar set of published open standards for multi-vendor network equipment interoperability.\n",
      "\n",
      "(y) The term ‚Äúpersonally identifiable information‚Äù has the meaning set forth in Office of Management and Budget (OMB) Circular No. A-130.\n",
      "\n",
      "(z) The term ‚Äúprivacy-enhancing technology‚Äù means any software or hardware solution, technical process, technique, or other technological means of mitigating privacy risks arising from data processing, including by enhancing predictability, manageability, disassociability, storage, security, and confidentiality. These technological means may include secure multiparty computation, homomorphic encryption, zero-knowledge proofs, federated learning, secure enclaves, differential privacy, and synthetic-data-generation tools. This is also sometimes referred to as ‚Äúprivacy-preserving technology.‚Äù\n",
      "\n",
      "(aa) The term ‚Äúprivacy impact assessment‚Äù has the meaning set forth in OMB Circular No. A-130.\n",
      "\n",
      "(bb) The term ‚ÄúSector Risk Management Agency‚Äù has the meaning set forth in 6 U.S.C. 650(23).\n",
      "\n",
      "(cc) The term ‚Äúself-healing network‚Äù means a telecommunications network that automatically diagnoses and addresses network issues to permit self-restoration.\n",
      "\n",
      "(dd) The term ‚Äúsynthetic biology‚Äù means a field of science that involves redesigning organisms, or the biomolecules of organisms, at the genetic level to give them new characteristics. Synthetic nucleic acids are a type of biomolecule redesigned through synthetic-biology methods.\n",
      "\n",
      "(ee) The term ‚Äúsynthetic content‚Äù means information, such as images, videos, audio clips, and text, that has been significantly modified or generated by algorithms, including by AI.\n",
      "\n",
      "(ff) The term ‚Äútestbed‚Äù means a facility or mechanism equipped for conducting rigorous, transparent, and replicable testing of tools and technologies, including AI and PETs, to help evaluate the functionality, usability, and performance of those tools or technologies.\n",
      "\n",
      "(gg) The term ‚Äúwatermarking‚Äù means the act of embedding information, which is typically difficult to remove, into outputs created by AI ‚Äî including into outputs such as photos, videos, audio clips, or text ‚Äî for the purposes of verifying the authenticity of the output or the identity or characteristics of its provenance, modifications, or conveyance. Sec. 4. Ensuring the Safety and Security of AI Technology.\n",
      "\n",
      "4.1. Developing Guidelines, Standards, and Best Practices for AI Safety and Security. (a) Within 270 days of the date of this order, to help ensure the development of safe, secure, and trustworthy AI systems, the Secretary of Commerce, acting through the Director of the National Institute of Standards and Technology (NIST), in coordination with the Secretary of Energy, the Secretary of Homeland Security, and the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall:\n",
      "\n",
      "(i) Establish guidelines and best practices, with the aim of promoting consensus industry standards, for developing and deploying safe, secure, and trustworthy AI systems, including:\n",
      "\n",
      "(A) developing a companion resource to the AI Risk Management Framework, NIST AI 100-1, for generative AI;\n",
      "\n",
      "(B) developing a companion resource to the Secure Software Development Framework to incorporate secure development practices for generative AI and for dual-use foundation models; and\n",
      "\n",
      "(C) launching an initiative to create guidance and benchmarks for evaluating and auditing AI capabilities, with a focus on capabilities through which AI could cause harm, such as in the areas of cybersecurity and biosecurity.\n",
      "\n",
      "(ii) Establish appropriate guidelines (except for AI used as a component of a national security system), including appropriate procedures and processes, to enable developers of AI, especially of dual-use foundation models, to conduct AI red-teaming tests to enable deployment of safe, secure, and trustworthy systems. These efforts shall include:\n",
      "\n",
      "(A) coordinating or developing guidelines related to assessing and managing the safety, security, and trustworthiness of dual-use foundation models; and\n",
      "\n",
      "(B) in coordination with the Secretary of Energy and the Director of the National Science Foundation (NSF), developing and helping to ensure the availability of testing environments, such as testbeds, to support the development of safe, secure, and trustworthy AI technologies, as well as to support the design, development, and deployment of associated PETs, consistent with section 9(b) of this order.\n",
      "\n",
      "(b) Within 270 days of the date of this order, to understand and mitigate AI security risks, the Secretary of Energy, in coordination with the heads of other Sector Risk Management Agencies (SRMAs) as the Secretary of Energy may deem appropriate, shall develop and, to the extent permitted by law and available appropriations, implement a plan for developing the Department of Energy‚Äôs AI model evaluation tools and AI testbeds. The Secretary shall undertake this work using existing solutions where possible, and shall develop these tools and AI testbeds to be capable of assessing near-term extrapolations of AI systems‚Äô capabilities. At a minimum, the Secretary shall develop tools to evaluate AI capabilities to generate outputs that may represent nuclear, nonproliferation, biological, chemical, critical infrastructure, and energy-security threats or hazards. The Secretary shall do this work solely for the purposes of guarding against these threats, and shall also develop model guardrails that reduce such risks. The Secretary shall, as appropriate, consult with private AI laboratories, academia, civil society, and third-party evaluators, and shall use existing solutions.\n",
      "\n",
      "4.2. Ensuring Safe and Reliable AI. (a) Within 90 days of the date of this order, to ensure and verify the continuous availability of safe, reliable, and effective AI in accordance with the Defense Production Act, as amended, 50 U.S.C. 4501 et seq., including for the national defense and the protection of critical infrastructure, the Secretary of Commerce shall require:\n",
      "\n",
      "(i) Companies developing or demonstrating an intent to develop potential dual-use foundation models to provide the Federal Government, on an ongoing basis, with information, reports, or records regarding the following:\n",
      "\n",
      "(A) any ongoing or planned activities related to training, developing, or producing dual-use foundation models, including the physical and cybersecurity protections taken to assure the integrity of that training process against sophisticated threats;\n",
      "\n",
      "(B) the ownership and possession of the model weights of any dual-use foundation models, and the physical and cybersecurity measures taken to protect those model weights; and\n",
      "\n",
      "(C) the results of any developed dual-use foundation model‚Äôs performance in relevant AI red-team testing based on guidance developed by NIST pursuant to subsection 4.1(a)(ii) of this section, and a description of any associated measures the company has taken to meet safety objectives, such as mitigations to improve performance on these red-team tests and strengthen overall model security. Prior to the development of guidance on red-team testing standards by NIST pursuant to subsection 4.1(a)(ii) of this section, this description shall include the results of any red-team testing that the company has conducted relating to lowering the barrier to entry for the development, acquisition, and use of biological weapons by non-state actors; the discovery of software vulnerabilities and development of associated exploits; the use of software or tools to influence real or virtual events; the possibility for self-replication or propagation; and associated measures to meet safety objectives; and\n",
      "\n",
      "(ii) Companies, individuals, or other organizations or entities that acquire, develop, or possess a potential large-scale computing cluster to report any such acquisition, development, or possession, including the existence and location of these clusters and the amount of total computing power available in each cluster.\n",
      "\n",
      "(b) The Secretary of Commerce, in consultation with the Secretary of State, the Secretary of Defense, the Secretary of Energy, and the Director of National Intelligence, shall define, and thereafter update as needed on a regular basis, the set of technical conditions for models and computing clusters that would be subject to the reporting requirements of subsection 4.2(a) of this section. Until such technical conditions are defined, the Secretary shall require compliance with these reporting requirements for:\n",
      "\n",
      "(i) any model that was trained using a quantity of computing power greater than 1026 integer or floating-point operations, or using primarily biological sequence data and using a quantity of computing power greater than 1023 integer or floating-point operations; and\n",
      "\n",
      "(ii) any computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum computing capacity of 1020 integer or floating-point operations per second for training AI.\n",
      "\n",
      "(c) Because I find that additional steps must be taken to deal with the national emergency related to significant malicious cyber-enabled activities declared in Executive Order 13694 of April 1, 2015 (Blocking the Property of Certain Persons Engaging in Significant Malicious Cyber-Enabled Activities), as amended by Executive Order 13757 of December 28, 2016 (Taking Additional Steps to Address the National Emergency With Respect to Significant Malicious Cyber-Enabled Activities), and further amended by Executive Order 13984, to address the use of United States Infrastructure as a Service (IaaS) Products by foreign malicious cyber actors, including to impose additional record-keeping obligations with respect to foreign transactions and to assist in the investigation of transactions involving foreign malicious cyber actors, I hereby direct the Secretary of Commerce, within 90 days of the date of this order, to:\n",
      "\n",
      "(i) Propose regulations that require United States IaaS Providers to submit a report to the Secretary of Commerce when a foreign person transacts with that United States IaaS Provider to train a large AI model with potential capabilities that could be used in malicious cyber-enabled activity (a ‚Äútraining run‚Äù). Such reports shall include, at a minimum, the identity of the foreign person and the existence of any training run of an AI model meeting the criteria set forth in this section, or other criteria defined by the Secretary in regulations, as well as any additional information identified by the Secretary.\n",
      "\n",
      "(ii) Include a requirement in the regulations proposed pursuant to subsection 4.2(c)(i) of this section that United States IaaS Providers prohibit any foreign reseller of their United States IaaS Product from providing those products unless such foreign reseller submits to the United States IaaS Provider a report, which the United States IaaS Provider must provide to the Secretary of Commerce, detailing each instance in which a foreign person transacts with the foreign reseller to use the United States IaaS Product to conduct a training run described in subsection 4.2(c)(i) of this section. Such reports shall include, at a minimum, the information specified in subsection 4.2(c)(i) of this section as well as any additional information identified by the Secretary.\n",
      "\n",
      "(iii) Determine the set of technical conditions for a large AI model to have potential capabilities that could be used in malicious cyber-enabled activity, and revise that determination as necessary and appropriate. Until the Secretary makes such a determination, a model shall be considered to have potential capabilities that could be used in malicious cyber-enabled activity if it requires a quantity of computing power greater than 1026 integer or floating-point operations and is trained on a computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum compute capacity of 1020 integer or floating-point operations per second for training AI.\n",
      "\n",
      "(d) Within 180 days of the date of this order, pursuant to the finding set forth in subsection 4.2(c) of this section, the Secretary of Commerce shall propose regulations that require United States IaaS Providers to ensure that foreign resellers of United States IaaS Products verify the identity of any foreign person that obtains an IaaS account (account) from the foreign reseller. These regulations shall, at a minimum:\n",
      "\n",
      "(i) Set forth the minimum standards that a United States IaaS Provider must require of foreign resellers of its United States IaaS Products to verify the identity of a foreign person who opens an account or maintains an existing account with a foreign reseller, including:\n",
      "\n",
      "(A) the types of documentation and procedures that foreign resellers of United States IaaS Products must require to verify the identity of any foreign person acting as a lessee or sub-lessee of these products or services;\n",
      "\n",
      "(B) records that foreign resellers of United States IaaS Products must securely maintain regarding a foreign person that obtains an account, including information establishing:\n",
      "\n",
      "(1) the identity of such foreign person, including name and address;\n",
      "\n",
      "(2) the means and source of payment (including any associated financial institution and other identifiers such as credit card number, account number, customer identifier, transaction identifiers, or virtual currency wallet or wallet address identifier);\n",
      "\n",
      "(3) the electronic mail address and telephonic contact information used to verify a foreign person‚Äôs identity; and\n",
      "\n",
      "(4) the Internet Protocol addresses used for access or administration and the date and time of each such access or administrative action related to ongoing verification of such foreign person‚Äôs ownership of such an account; and\n",
      "\n",
      "(C) methods that foreign resellers of United States IaaS Products must implement to limit all third-party access to the information described in this subsection, except insofar as such access is otherwise consistent with this order and allowed under applicable law;\n",
      "\n",
      "(ii) Take into consideration the types of accounts maintained by foreign resellers of United States IaaS Products, methods of opening an account, and types of identifying information available to accomplish the objectives of identifying foreign malicious cyber actors using any such products and avoiding the imposition of an undue burden on such resellers; and\n",
      "\n",
      "(iii) Provide that the Secretary of Commerce, in accordance with such standards and procedures as the Secretary may delineate and in consultation with the Secretary of Defense, the Attorney General, the Secretary of Homeland Security, and the Director of National Intelligence, may exempt a United States IaaS Provider with respect to any specific foreign reseller of their United States IaaS Products, or with respect to any specific type of account or lessee, from the requirements of any regulation issued pursuant to this subsection. Such standards and procedures may include a finding by the Secretary that such foreign reseller, account, or lessee complies with security best practices to otherwise deter abuse of United States IaaS Products.\n",
      "\n",
      "(e) The Secretary of Commerce is hereby authorized to take such actions, including the promulgation of rules and regulations, and to employ all powers granted to the President by the International Emergency Economic Powers Act, 50 U.S.C. 1701 et seq., as may be necessary to carry out the purposes of subsections 4.2(c) and (d) of this section. Such actions may include a requirement that United States IaaS Providers require foreign resellers of United States IaaS Products to provide United States IaaS Providers verifications relative to those subsections.\n",
      "\n",
      "4.3. Managing AI in Critical Infrastructure and in Cybersecurity. (a) To ensure the protection of critical infrastructure, the following actions shall be taken:\n",
      "\n",
      "(i) Within 90 days of the date of this order, and at least annually thereafter, the head of each agency with relevant regulatory authority over critical infrastructure and the heads of relevant SRMAs, in coordination with the Director of the Cybersecurity and Infrastructure Security Agency within the Department of Homeland Security for consideration of cross-sector risks, shall evaluate and provide to the Secretary of Homeland Security an assessment of potential risks related to the use of AI in critical infrastructure sectors involved, including ways in which deploying AI may make critical infrastructure systems more vulnerable to critical failures, physical attacks, and cyber attacks, and shall consider ways to mitigate these vulnerabilities. Independent regulatory agencies are encouraged, as they deem appropriate, to contribute to sector-specific risk assessments.\n",
      "\n",
      "(ii) Within 150 days of the date of this order, the Secretary of the Treasury shall issue a public report on best practices for financial institutions to manage AI-specific cybersecurity risks.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Secretary of Homeland Security, in coordination with the Secretary of Commerce and with SRMAs and other regulators as determined by the Secretary of Homeland Security, shall incorporate as appropriate the AI Risk Management Framework, NIST AI 100-1, as well as other appropriate security guidance, into relevant safety and security guidelines for use by critical infrastructure owners and operators.\n",
      "\n",
      "(iv) Within 240 days of the completion of the guidelines described in subsection 4.3(a)(iii) of this section, the Assistant to the President for National Security Affairs and the Director of OMB, in consultation with the Secretary of Homeland Security, shall coordinate work by the heads of agencies with authority over critical infrastructure to develop and take steps for the Federal Government to mandate such guidelines, or appropriate portions thereof, through regulatory or other appropriate action. Independent regulatory agencies are encouraged, as they deem appropriate, to consider whether to mandate guidance through regulatory action in their areas of authority and responsibility.\n",
      "\n",
      "(v) The Secretary of Homeland Security shall establish an Artificial Intelligence Safety and Security Board as an advisory committee pursuant to section 871 of the Homeland Security Act of 2002 (Public Law 107-296). The Advisory Committee shall include AI experts from the private sector, academia, and government, as appropriate, and provide to the Secretary of Homeland Security and the Federal Government‚Äôs critical infrastructure community advice, information, or recommendations for improving security, resilience, and incident response related to AI usage in critical infrastructure.\n",
      "\n",
      "(b) To capitalize on AI‚Äôs potential to improve United States cyber defenses:\n",
      "\n",
      "(i) The Secretary of Defense shall carry out the actions described in subsections 4.3(b)(ii) and (iii) of this section for national security systems, and the Secretary of Homeland Security shall carry out these actions for non-national security systems. Each shall do so in consultation with the heads of other relevant agencies as the Secretary of Defense and the Secretary of Homeland Security may deem appropriate.\n",
      "\n",
      "(ii) As set forth in subsection 4.3(b)(i) of this section, within 180 days of the date of this order, the Secretary of Defense and the Secretary of Homeland Security shall, consistent with applicable law, each develop plans for, conduct, and complete an operational pilot project to identify, develop, test, evaluate, and deploy AI capabilities, such as large-language models, to aid in the discovery and remediation of vulnerabilities in critical United States Government software, systems, and networks.\n",
      "\n",
      "(iii) As set forth in subsection 4.3(b)(i) of this section, within 270 days of the date of this order, the Secretary of Defense and the Secretary of Homeland Security shall each provide a report to the Assistant to the President for National Security Affairs on the results of actions taken pursuant to the plans and operational pilot projects required by subsection 4.3(b)(ii) of this section, including a description of any vulnerabilities found and fixed through the development and deployment of AI capabilities and any lessons learned on how to identify, develop, test, evaluate, and deploy AI capabilities effectively for cyber defense.\n",
      "\n",
      "4.4. Reducing Risks at the Intersection of AI and CBRN Threats. (a) To better understand and mitigate the risk of AI being misused to assist in the development or use of CBRN threats ‚Äî with a particular focus on biological weapons ‚Äî the following actions shall be taken:\n",
      "\n",
      "(i) Within 180 days of the date of this order, the Secretary of Homeland Security, in consultation with the Secretary of Energy and the Director of the Office of Science and Technology Policy (OSTP), shall evaluate the potential for AI to be misused to enable the development or production of CBRN threats, while also considering the benefits and application of AI to counter these threats, including, as appropriate, the results of work conducted under section 8(b) of this order. The Secretary of Homeland Security shall:\n",
      "\n",
      "(A) consult with experts in AI and CBRN issues from the Department of Energy, private AI laboratories, academia, and third-party model evaluators, as appropriate, to evaluate AI model capabilities to present CBRN threats ‚Äî for the sole purpose of guarding against those threats ‚Äî as well as options for minimizing the risks of AI model misuse to generate or exacerbate those threats; and\n",
      "\n",
      "(B) submit a report to the President that describes the progress of these efforts, including an assessment of the types of AI models that may present CBRN risks to the United States, and that makes recommendations for regulating or overseeing the training, deployment, publication, or use of these models, including requirements for safety evaluations and guardrails for mitigating potential threats to national security.\n",
      "\n",
      "(ii) Within 120 days of the date of this order, the Secretary of Defense, in consultation with the Assistant to the President for National Security Affairs and the Director of OSTP, shall enter into a contract with the National Academies of Sciences, Engineering, and Medicine to conduct ‚Äî and submit to the Secretary of Defense, the Assistant to the President for National Security Affairs, the Director of the Office of Pandemic Preparedness and Response Policy, the Director of OSTP, and the Chair of the Chief Data Officer Council ‚Äî a study that:\n",
      "\n",
      "(A) assesses the ways in which AI can increase biosecurity risks, including risks from generative AI models trained on biological data, and makes recommendations on how to mitigate these risks;\n",
      "\n",
      "(B) considers the national security implications of the use of data and datasets, especially those associated with pathogens and omics studies, that the United States Government hosts, generates, funds the creation of, or otherwise owns, for the training of generative AI models, and makes recommendations on how to mitigate the risks related to the use of these data and datasets;\n",
      "\n",
      "(C) assesses the ways in which AI applied to biology can be used to reduce biosecurity risks, including recommendations on opportunities to coordinate data and high-performance computing resources; and\n",
      "\n",
      "(D) considers additional concerns and opportunities at the intersection of AI and synthetic biology that the Secretary of Defense deems appropriate.\n",
      "\n",
      "(b) To reduce the risk of misuse of synthetic nucleic acids, which could be substantially increased by AI‚Äôs capabilities in this area, and improve biosecurity measures for the nucleic acid synthesis industry, the following actions shall be taken:\n",
      "\n",
      "(i) Within 180 days of the date of this order, the Director of OSTP, in consultation with the Secretary of State, the Secretary of Defense, the Attorney General, the Secretary of Commerce, the Secretary of Health and Human Services (HHS), the Secretary of Energy, the Secretary of Homeland Security, the Director of National Intelligence, and the heads of other relevant agencies as the Director of OSTP may deem appropriate, shall establish a framework, incorporating, as appropriate, existing United States Government guidance, to encourage providers of synthetic nucleic acid sequences to implement comprehensive, scalable, and verifiable synthetic nucleic acid procurement screening mechanisms, including standards and recommended incentives. As part of this framework, the Director of OSTP shall:\n",
      "\n",
      "(A) establish criteria and mechanisms for ongoing identification of biological sequences that could be used in a manner that would pose a risk to the national security of the United States; and\n",
      "\n",
      "(B) determine standardized methodologies and tools for conducting and verifying the performance of sequence synthesis procurement screening, including customer screening approaches to support due diligence with respect to managing security risks posed by purchasers of biological sequences identified in subsection 4.4(b)(i)(A) of this section, and processes for the reporting of concerning activity to enforcement entities.\n",
      "\n",
      "(ii) Within 180 days of the date of this order, the Secretary of Commerce, acting through the Director of NIST, in coordination with the Director of OSTP, and in consultation with the Secretary of State, the Secretary of HHS, and the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall initiate an effort to engage with industry and relevant stakeholders, informed by the framework developed under subsection 4.4(b)(i) of this section, to develop and refine for possible use by synthetic nucleic acid sequence providers:\n",
      "\n",
      "(A) specifications for effective nucleic acid synthesis procurement screening;\n",
      "\n",
      "(B) best practices, including security and access controls, for managing sequence-of-concern databases to support such screening;\n",
      "\n",
      "(C) technical implementation guides for effective screening; and\n",
      "\n",
      "(D) conformity-assessment best practices and mechanisms.\n",
      "\n",
      "(iii) Within 180 days of the establishment of the framework pursuant to subsection 4.4(b)(i) of this section, all agencies that fund life-sciences research shall, as appropriate and consistent with applicable law, establish that, as a requirement of funding, synthetic nucleic acid procurement is conducted through providers or manufacturers that adhere to the framework, such as through an attestation from the provider or manufacturer. The Assistant to the President for National Security Affairs and the Director of OSTP shall coordinate the process of reviewing such funding requirements to facilitate consistency in implementation of the framework across funding agencies.\n",
      "\n",
      "(iv) In order to facilitate effective implementation of the measures described in subsections 4.4(b)(i)-(iii) of this section, the Secretary of Homeland Security, in consultation with the heads of other relevant agencies as the Secretary of Homeland Security may deem appropriate, shall:\n",
      "\n",
      "(A) within 180 days of the establishment of the framework pursuant to subsection 4.4(b)(i) of this section, develop a framework to conduct structured evaluation and stress testing of nucleic acid synthesis procurement screening, including the systems developed in accordance with subsections 4.4(b)(i)-(ii) of this section and implemented by providers of synthetic nucleic acid sequences; and\n",
      "\n",
      "(B) following development of the framework pursuant to subsection 4.4(b)(iv)(A) of this section, submit an annual report to the Assistant to the President for National Security Affairs, the Director of the Office of Pandemic Preparedness and Response Policy, and the Director of OSTP on any results of the activities conducted pursuant to subsection 4.4(b)(iv)(A) of this section, including recommendations, if any, on how to strengthen nucleic acid synthesis procurement screening, including customer screening systems.\n",
      "\n",
      "4.5. Reducing the Risks Posed by Synthetic Content.\n",
      "\n",
      "To foster capabilities for identifying and labeling synthetic content produced by AI systems, and to establish the authenticity and provenance of digital content, both synthetic and not synthetic, produced by the Federal Government or on its behalf: (a) Within 240 days of the date of this order, the Secretary of Commerce, in consultation with the heads of other relevant agencies as the Secretary of Commerce may deem appropriate, shall submit a report to the Director of OMB and the Assistant to the President for National Security Affairs identifying the existing standards, tools, methods, and practices, as well as the potential development of further science-backed standards and techniques, for:\n",
      "\n",
      "(i) authenticating content and tracking its provenance;\n",
      "\n",
      "(ii) labeling synthetic content, such as using watermarking;\n",
      "\n",
      "(iii) detecting synthetic content;\n",
      "\n",
      "(iv) preventing generative AI from producing child sexual abuse material or producing non-consensual intimate imagery of real individuals (to include intimate digital depictions of the body or body parts of an identifiable individual);\n",
      "\n",
      "(v) testing software used for the above purposes; and\n",
      "\n",
      "(vi) auditing and maintaining synthetic content. (b) Within 180 days of submitting the report required under subsection 4.5(a) of this section, and updated periodically thereafter, the Secretary of Commerce, in coordination with the Director of OMB, shall develop guidance regarding the existing tools and practices for digital content authentication and synthetic content detection measures. The guidance shall include measures for the purposes listed in subsection 4.5(a) of this section. (c) Within 180 days of the development of the guidance required under subsection 4.5(b) of this section, and updated periodically thereafter, the Director of OMB, in consultation with the Secretary of State; the Secretary of Defense; the Attorney General; the Secretary of Commerce, acting through the Director of NIST; the Secretary of Homeland Security; the Director of National Intelligence; and the heads of other agencies that the Director of OMB deems appropriate, shall ‚Äî for the purpose of strengthening public confidence in the integrity of official United States Government digital content ‚Äî issue guidance to agencies for labeling and authenticating such content that they produce or publish. (d) The Federal Acquisition Regulatory Council shall, as appropriate and consistent with applicable law, consider amending the Federal Acquisition Regulation to take into account the guidance established under subsection 4.5 of this section.\n",
      "\n",
      "4.6. Soliciting Input on Dual-Use Foundation Models with Widely Available Model Weights. When the weights for a dual-use foundation model are widely available ‚Äî such as when they are publicly posted on the Internet ‚Äî there can be substantial benefits to innovation, but also substantial security risks, such as the removal of safeguards within the model. To address the risks and potential benefits of dual-use foundation models with widely available weights, within 270 days of the date of this order, the Secretary of Commerce, acting through the Assistant Secretary of Commerce for Communications and Information, and in consultation with the Secretary of State, shall: (a) solicit input from the private sector, academia, civil society, and other stakeholders through a public consultation process on potential risks, benefits, other implications, and appropriate policy and regulatory approaches related to dual-use foundation models for which the model weights are widely available, including:\n",
      "\n",
      "(i) risks associated with actors fine-tuning dual-use foundation models for which the model weights are widely available or removing those models‚Äô safeguards;\n",
      "\n",
      "(ii) benefits to AI innovation and research, including research into AI safety and risk management, of dual-use foundation models for which the model weights are widely available; and\n",
      "\n",
      "(iii) potential voluntary, regulatory, and international mechanisms to manage the risks and maximize the benefits of dual-use foundation models for which the model weights are widely available; and (b) based on input from the process described in subsection 4.6(a) of this section, and in consultation with the heads of other relevant agencies as the Secretary of Commerce deems appropriate, submit a report to the President on the potential benefits, risks, and implications of dual-use foundation models for which the model weights are widely available, as well as policy and regulatory recommendations pertaining to those models.\n",
      "\n",
      "4.7. Promoting Safe Release and Preventing the Malicious Use of Federal Data for AI Training.To improve public data access and manage security risks, and consistent with the objectives of the Open, Public, Electronic, and Necessary Government Data Act (title II of Public Law 115-435) to expand public access to Federal data assets in a machine-readable format while also taking into account security considerations, including the risk that information in an individual data asset in isolation does not pose a security risk but, when combined with other available information, may pose such a risk: (a) within 270 days of the date of this order, the Chief Data Officer Council, in consultation with the Secretary of Defense, the Secretary of Commerce, the Secretary of Energy, the Secretary of Homeland Security, and the Director of National Intelligence, shall develop initial guidelines for performing security reviews, including reviews to identify and manage the potential security risks of releasing Federal data that could aid in the development of CBRN weapons as well as the development of autonomous offensive cyber capabilities, while also providing public access to Federal Government data in line with the goals stated in the Open, Public, Electronic, and Necessary Government Data Act (title II of Public Law 115-435); and\n",
      "\n",
      "(b) within 180 days of the development of the initial guidelines required by subsection 4.7(a) of this section, agencies shall conduct a security review of all data assets in the comprehensive data inventory required under 44 U.S.C. 3511(a)(1) and (2)(B) and shall take steps, as appropriate and consistent with applicable law, to address the highest-priority potential security risks that releasing that data could raise with respect to CBRN weapons, such as the ways in which that data could be used to train AI systems.\n",
      "\n",
      "4.8. Directing the Development of a National Security Memorandum. To develop a coordinated executive branch approach to managing AI‚Äôs security risks, the Assistant to the President for National Security Affairs and the Assistant to the President and Deputy Chief of Staff for Policy shall oversee an interagency process with the purpose of, within 270 days of the date of this order, developing and submitting a proposed National Security Memorandum on AI to the President. The memorandum shall address the governance of AI used as a component of a national security system or for military and intelligence purposes. The memorandum shall take into account current efforts to govern the development and use of AI for national security systems. The memorandum shall outline actions for the Department of Defense, the Department of State, other relevant agencies, and the Intelligence Community to address the national security risks and potential benefits posed by AI. In particular, the memorandum shall:\n",
      "\n",
      "(a) provide guidance to the Department of Defense, other relevant agencies, and the Intelligence Community on the continued adoption of AI capabilities to advance the United States national security mission, including through directing specific AI assurance and risk-management practices for national security uses of AI that may affect the rights or safety of United States persons and, in appropriate contexts, non-United States persons; and\n",
      "\n",
      "(b) direct continued actions, as appropriate and consistent with applicable law, to address the potential use of AI systems by adversaries and other foreign actors in ways that threaten the capabilities or objectives of the Department of Defense or the Intelligence Community, or that otherwise pose risks to the security of the United States or its allies and partners.\n",
      "\n",
      "Sec. 5. Promoting Innovation and Competition.\n",
      "\n",
      "5.1. Attracting AI Talent to the United States. (a) Within 90 days of the date of this order, to attract and retain talent in AI and other critical and emerging technologies in the United States economy, the Secretary of State and the Secretary of Homeland Security shall take appropriate steps to:\n",
      "\n",
      "(i) streamline processing times of visa petitions and applications, including by ensuring timely availability of visa appointments, for noncitizens who seek to travel to the United States to work on, study, or conduct research in AI or other critical and emerging technologies; and\n",
      "\n",
      "(ii) facilitate continued availability of visa appointments in sufficient volume for applicants with expertise in AI or other critical and emerging technologies.\n",
      "\n",
      "(b) Within 120 days of the date of this order, the Secretary of State shall:\n",
      "\n",
      "(i) consider initiating a rulemaking to establish new criteria to designate countries and skills on the Department of State‚Äôs Exchange Visitor Skills List as it relates to the 2-year foreign residence requirement for certain J-1 nonimmigrants, including those skills that are critical to the United States;\n",
      "\n",
      "(ii) consider publishing updates to the 2009 Revised Exchange Visitor Skills List (74 FR 20108); and\n",
      "\n",
      "(iii) consider implementing a domestic visa renewal program under 22 C.F.R. 41.111(b) to facilitate the ability of qualified applicants, including highly skilled talent in AI and critical and emerging technologies, to continue their work in the United States without unnecessary interruption.\n",
      "\n",
      "(c) Within 180 days of the date of this order, the Secretary of State shall:\n",
      "\n",
      "(i) consider initiating a rulemaking to expand the categories of nonimmigrants who qualify for the domestic visa renewal program covered under 22 C.F.R. 41.111(b) to include academic J-1 research scholars and F-1 students in science, technology, engineering, and mathematics (STEM); and\n",
      "\n",
      "(ii) establish, to the extent permitted by law and available appropriations, a program to identify and attract top talent in AI and other critical and emerging technologies at universities, research institutions, and the private sector overseas, and to establish and increase connections with that talent to educate them on opportunities and resources for research and employment in the United States, including overseas educational components to inform top STEM talent of nonimmigrant and immigrant visa options and potential expedited adjudication of their visa petitions and applications.\n",
      "\n",
      "(d) Within 180 days of the date of this order, the Secretary of Homeland Security shall:\n",
      "\n",
      "(i) review and initiate any policy changes the Secretary determines necessary and appropriate to clarify and modernize immigration pathways for experts in AI and other critical and emerging technologies, including O-1A and EB-1 noncitizens of extraordinary ability; EB-2 advanced-degree holders and noncitizens of exceptional ability; and startup founders in AI and other critical and emerging technologies using the International Entrepreneur Rule; and\n",
      "\n",
      "(ii) continue its rulemaking process to modernize the H-1B program and enhance its integrity and usage, including by experts in AI and other critical and emerging technologies, and consider initiating a rulemaking to enhance the process for noncitizens, including experts in AI and other critical and emerging technologies and their spouses, dependents, and children, to adjust their status to lawful permanent resident.\n",
      "\n",
      "(e) Within 45 days of the date of this order, for purposes of considering updates to the ‚ÄúSchedule A‚Äù list of occupations, 20 C.F.R. 656.5, the Secretary of Labor shall publish a request for information (RFI) to solicit public input, including from industry and worker-advocate communities, identifying AI and other STEM-related occupations, as well as additional occupations across the economy, for which there is an insufficient number of ready, willing, able, and qualified United States workers.\n",
      "\n",
      "(f) The Secretary of State and the Secretary of Homeland Security shall, consistent with applicable law and implementing regulations, use their discretionary authorities to support and attract foreign nationals with special skills in AI and other critical and emerging technologies seeking to work, study, or conduct research in the United States.\n",
      "\n",
      "(g) Within 120 days of the date of this order, the Secretary of Homeland Security, in consultation with the Secretary of State, the Secretary of Commerce, and the Director of OSTP, shall develop and publish informational resources to better attract and retain experts in AI and other critical and emerging technologies, including:\n",
      "\n",
      "(i) a clear and comprehensive guide for experts in AI and other critical and emerging technologies to understand their options for working in the United States, to be published in multiple relevant languages on AI.gov; and\n",
      "\n",
      "(ii) a public report with relevant data on applications, petitions, approvals, and other key indicators of how experts in AI and other critical and emerging technologies have utilized the immigration system through the end of Fiscal Year 2023.\n",
      "\n",
      "5.2. Promoting Innovation. (a) To develop and strengthen public-private partnerships for advancing innovation, commercialization, and risk-mitigation methods for AI, and to help promote safe, responsible, fair, privacy-protecting, and trustworthy AI systems, the Director of NSF shall take the following steps:\n",
      "\n",
      "(i) Within 90 days of the date of this order, in coordination with the heads of agencies that the Director of NSF deems appropriate, launch a pilot program implementing the National AI Research Resource (NAIRR), consistent with past recommendations of the NAIRR Task Force. The program shall pursue the infrastructure, governance mechanisms, and user interfaces to pilot an initial integration of distributed computational, data, model, and training resources to be made available to the research community in support of AI-related research and development. The Director of NSF shall identify Federal and private sector computational, data, software, and training resources appropriate for inclusion in the NAIRR pilot program. To assist with such work, within 45 days of the date of this order, the heads of agencies whom the Director of NSF identifies for coordination pursuant to this subsection shall each submit to the Director of NSF a report identifying the agency resources that could be developed and integrated into such a pilot program. These reports shall include a description of such resources, including their current status and availability; their format, structure, or technical specifications; associated agency expertise that will be provided; and the benefits and risks associated with their inclusion in the NAIRR pilot program. The heads of independent regulatory agencies are encouraged to take similar steps, as they deem appropriate.\n",
      "\n",
      "(ii) Within 150 days of the date of this order, fund and launch at least one NSF Regional Innovation Engine that prioritizes AI-related work, such as AI-related research, societal, or workforce needs.\n",
      "\n",
      "(iii) Within 540 days of the date of this order, establish at least four new National AI Research Institutes, in addition to the 25 currently funded as of the date of this order.\n",
      "\n",
      "(b) Within 120 days of the date of this order, to support activities involving high-performance and data-intensive computing, the Secretary of Energy, in coordination with the Director of NSF, shall, in a manner consistent with applicable law and available appropriations, establish a pilot program to enhance existing successful training programs for scientists, with the goal of training 500 new researchers by 2025 capable of meeting the rising demand for AI talent.\n",
      "\n",
      "(c) To promote innovation and clarify issues related to AI and inventorship of patentable subject matter, the Under Secretary of Commerce for Intellectual Property and Director of the United States Patent and Trademark Office (USPTO Director) shall:\n",
      "\n",
      "(i) within 120 days of the date of this order, publish guidance to USPTO patent examiners and applicants addressing inventorship and the use of AI, including generative AI, in the inventive process, including illustrative examples in which AI systems play different roles in inventive processes and how, in each example, inventorship issues ought to be analyzed;\n",
      "\n",
      "(ii) subsequently, within 270 days of the date of this order, issue additional guidance to USPTO patent examiners and applicants to address other considerations at the intersection of AI and IP, which could include, as the USPTO Director deems necessary, updated guidance on patent eligibility to address innovation in AI and critical and emerging technologies; and\n",
      "\n",
      "(iii) within 270 days of the date of this order or 180 days after the United States Copyright Office of the Library of Congress publishes its forthcoming AI study that will address copyright issues raised by AI, whichever comes later, consult with the Director of the United States Copyright Office and issue recommendations to the President on potential executive actions relating to copyright and AI. The recommendations shall address any copyright and related issues discussed in the United States Copyright Office‚Äôs study, including the scope of protection for works produced using AI and the treatment of copyrighted works in AI training.\n",
      "\n",
      "(d) Within 180 days of the date of this order, to assist developers of AI in combatting AI-related IP risks, the Secretary of Homeland Security, acting through the Director of the National Intellectual Property Rights Coordination Center, and in consultation with the Attorney General, shall develop a training, analysis, and evaluation program to mitigate AI-related IP risks. Such a program shall:\n",
      "\n",
      "(i) include appropriate personnel dedicated to collecting and analyzing reports of AI-related IP theft, investigating such incidents with implications for national security, and, where appropriate and consistent with applicable law, pursuing related enforcement actions;\n",
      "\n",
      "(ii) implement a policy of sharing information and coordinating on such work, as appropriate and consistent with applicable law, with the Federal Bureau of Investigation; United States Customs and Border Protection; other agencies; State and local agencies; and appropriate international organizations, including through work-sharing agreements;\n",
      "\n",
      "(iii) develop guidance and other appropriate resources to assist private sector actors with mitigating the risks of AI-related IP theft;\n",
      "\n",
      "(iv) share information and best practices with AI developers and law enforcement personnel to identify incidents, inform stakeholders of current legal requirements, and evaluate AI systems for IP law violations, as well as develop mitigation strategies and resources; and\n",
      "\n",
      "(v) assist the Intellectual Property Enforcement Coordinator in updating the Intellectual Property Enforcement Coordinator Joint Strategic Plan on Intellectual Property Enforcement to address AI-related issues.\n",
      "\n",
      "(e) To advance responsible AI innovation by a wide range of healthcare technology developers that promotes the welfare of patients and workers in the healthcare sector, the Secretary of HHS shall identify and, as appropriate and consistent with applicable law and the activities directed in section 8 of this order, prioritize grantmaking and other awards, as well as undertake related efforts, to support responsible AI development and use, including:\n",
      "\n",
      "(i) collaborating with appropriate private sector actors through HHS programs that may support the advancement of AI-enabled tools that develop personalized immune-response profiles for patients, consistent with section 4 of this order;\n",
      "\n",
      "(ii) prioritizing the allocation of 2024 Leading Edge Acceleration Project cooperative agreement awards to initiatives that explore ways to improve healthcare-data quality to support the responsible development of AI tools for clinical care, real-world-evidence programs, population health, public health, and related research; and\n",
      "\n",
      "(iii) accelerating grants awarded through the National Institutes of Health Artificial Intelligence/Machine Learning Consortium to Advance Health Equity and Researcher Diversity (AIM-AHEAD) program and showcasing current AIM-AHEAD activities in underserved communities.\n",
      "\n",
      "(f) To advance the development of AI systems that improve the quality of veterans‚Äô healthcare, and in order to support small businesses‚Äô innovative capacity, the Secretary of Veterans Affairs shall:\n",
      "\n",
      "(i) within 365 days of the date of this order, host two 3-month nationwide AI Tech Sprint competitions; and\n",
      "\n",
      "(ii) as part of the AI Tech Sprint competitions and in collaboration with appropriate partners, provide participants access to technical assistance, mentorship opportunities, individualized expert feedback on products under development, potential contract opportunities, and other programming and resources.\n",
      "\n",
      "(g) Within 180 days of the date of this order, to support the goal of strengthening our Nation‚Äôs resilience against climate change impacts and building an equitable clean energy economy for the future, the Secretary of Energy, in consultation with the Chair of the Federal Energy Regulatory Commission, the Director of OSTP, the Chair of the Council on Environmental Quality, the Assistant to the President and National Climate Advisor, and the heads of other relevant agencies as the Secretary of Energy may deem appropriate, shall:\n",
      "\n",
      "(i) issue a public report describing the potential for AI to improve planning, permitting, investment, and operations for electric grid infrastructure and to enable the provision of clean, affordable, reliable, resilient, and secure electric power to all Americans;\n",
      "\n",
      "(ii) develop tools that facilitate building foundation models useful for basic and applied science, including models that streamline permitting and environmental reviews while improving environmental and social outcomes;\n",
      "\n",
      "(iii) collaborate, as appropriate, with private sector organizations and members of academia to support development of AI tools to mitigate climate change risks;\n",
      "\n",
      "(iv) take steps to expand partnerships with industry, academia, other agencies, and international allies and partners to utilize the Department of Energy‚Äôs computing capabilities and AI testbeds to build foundation models that support new applications in science and energy, and for national security, including partnerships that increase community preparedness for climate-related risks, enable clean-energy deployment (including addressing delays in permitting reviews), and enhance grid reliability and resilience; and\n",
      "\n",
      "(v) establish an office to coordinate development of AI and other critical and emerging technologies across Department of Energy programs and the 17 National Laboratories.\n",
      "\n",
      "(h) Within 180 days of the date of this order, to understand AI‚Äôs implications for scientific research, the President‚Äôs Council of Advisors on Science and Technology shall submit to the President and make publicly available a report on the potential role of AI, especially given recent developments in AI, in research aimed at tackling major societal and global challenges. The report shall include a discussion of issues that may hinder the effective use of AI in research and practices needed to ensure that AI is used responsibly for research.\n",
      "\n",
      "5.3. Promoting Competition. (a) The head of each agency developing policies and regulations related to AI shall use their authorities, as appropriate and consistent with applicable law, to promote competition in AI and related technologies, as well as in other markets. Such actions include addressing risks arising from concentrated control of key inputs, taking steps to stop unlawful collusion and prevent dominant firms from disadvantaging competitors, and working to provide new opportunities for small businesses and entrepreneurs. In particular, the Federal Trade Commission is encouraged to consider, as it deems appropriate, whether to exercise the Commission‚Äôs existing authorities, including its rulemaking authority under the Federal Trade Commission Act, 15 U.S.C. 41 et seq., to ensure fair competition in the AI marketplace and to ensure that consumers and workers are protected from harms that may be enabled by the use of AI.\n",
      "\n",
      "(b) To promote competition and innovation in the semiconductor industry, recognizing that semiconductors power AI technologies and that their availability is critical to AI competition, the Secretary of Commerce shall, in implementing division A of Public Law 117-167, known as the Creating Helpful Incentives to Produce Semiconductors (CHIPS) Act of 2022, promote competition by:\n",
      "\n",
      "(i) implementing a flexible membership structure for the National Semiconductor Technology Center that attracts all parts of the semiconductor and microelectronics ecosystem, including startups and small firms;\n",
      "\n",
      "(ii) implementing mentorship programs to increase interest and participation in the semiconductor industry, including from workers in underserved communities;\n",
      "\n",
      "(iii) increasing, where appropriate and to the extent permitted by law, the availability of resources to startups and small businesses, including:\n",
      "\n",
      "(A) funding for physical assets, such as specialty equipment or facilities, to which startups and small businesses may not otherwise have access;\n",
      "\n",
      "(B) datasets ‚Äî potentially including test and performance data ‚Äî collected, aggregated, or shared by CHIPS research and development programs;\n",
      "\n",
      "(C) workforce development programs;\n",
      "\n",
      "(D) design and process technology, as well as IP, as appropriate; and\n",
      "\n",
      "(E) other resources, including technical and intellectual property assistance, that could accelerate commercialization of new technologies by startups and small businesses, as appropriate; and\n",
      "\n",
      "(iv) considering the inclusion, to the maximum extent possible, and as consistent with applicable law, of competition-increasing measures in notices of funding availability for commercial research-and-development facilities focused on semiconductors, including measures that increase access to facility capacity for startups or small firms developing semiconductors used to power AI technologies.\n",
      "\n",
      "(c) To support small businesses innovating and commercializing AI, as well as in responsibly adopting and deploying AI, the Administrator of the Small Business Administration shall:\n",
      "\n",
      "(i) prioritize the allocation of Regional Innovation Cluster program funding for clusters that support planning activities related to the establishment of one or more Small Business AI Innovation and Commercialization Institutes that provide support, technical assistance, and other resources to small businesses seeking to innovate, commercialize, scale, or otherwise advance the development of AI;\n",
      "\n",
      "(ii) prioritize the allocation of up to $2 million in Growth Accelerator Fund Competition bonus prize funds for accelerators that support the incorporation or expansion of AI-related curricula, training, and technical assistance, or other AI-related resources within their programming; and\n",
      "\n",
      "(iii) assess the extent to which the eligibility criteria of existing programs, including the State Trade Expansion Program, Technical and Business Assistance funding, and capital-access programs ‚Äî such as the 7(a) loan program, 504 loan program, and Small Business Investment Company (SBIC) program ‚Äî support appropriate expenses by small businesses related to the adoption of AI and, if feasible and appropriate, revise eligibility criteria to improve support for these expenses.\n",
      "\n",
      "(d) The Administrator of the Small Business Administration, in coordination with resource partners, shall conduct outreach regarding, and raise awareness of, opportunities for small businesses to use capital-access programs described in subsection 5.3(c) of this section for eligible AI-related purposes, and for eligible investment funds with AI-related expertise ‚Äî particularly those seeking to serve or with experience serving underserved communities ‚Äî to apply for an SBIC license.\n",
      "\n",
      "Sec. 6. Supporting Workers.(a) To advance the Government‚Äôs understanding of AI‚Äôs implications for workers, the following actions shall be taken within 180 days of the date of this order:\n",
      "\n",
      "(i) The Chairman of the Council of Economic Advisers shall prepare and submit a report to the President on the labor-market effects of AI.\n",
      "\n",
      "(ii) To evaluate necessary steps for the Federal Government to address AI-related workforce disruptions, the Secretary of Labor shall submit to the President a report analyzing the abilities of agencies to support workers displaced by the adoption of AI and other technological advancements. The report shall, at a minimum:\n",
      "\n",
      "(A) assess how current or formerly operational Federal programs designed to assist workers facing job disruptions ‚Äî including unemployment insurance and programs authorized by the Workforce Innovation and Opportunity Act (Public Law 113-128) ‚Äî could be used to respond to possible future AI-related disruptions; and\n",
      "\n",
      "(B) identify options, including potential legislative measures, to strengthen or develop additional Federal support for workers displaced by AI and, in consultation with the Secretary of Commerce and the Secretary of Education, strengthen and expand education and training opportunities that provide individuals pathways to occupations related to AI.\n",
      "\n",
      "(b) To help ensure that AI deployed in the workplace advances employees‚Äô well-being:\n",
      "\n",
      "(i) The Secretary of Labor shall, within 180 days of the date of this order and in consultation with other agencies and with outside entities, including labor unions and workers, as the Secretary of Labor deems appropriate, develop and publish principles and best practices for employers that could be used to mitigate AI‚Äôs potential harms to employees‚Äô well-being and maximize its potential benefits. The principles and best practices shall include specific steps for employers to take with regard to AI, and shall cover, at a minimum:\n",
      "\n",
      "(A) job-displacement risks and career opportunities related to AI, including effects on job skills and evaluation of applicants and workers;\n",
      "\n",
      "(B) labor standards and job quality, including issues related to the equity, protected-activity, compensation, health, and safety implications of AI in the workplace; and\n",
      "\n",
      "(C) implications for workers of employers‚Äô AI-related collection and use of data about them, including transparency, engagement, management, and activity protected under worker-protection laws.\n",
      "\n",
      "(ii) After principles and best practices are developed pursuant to subsection (b)(i) of this section, the heads of agencies shall consider, in consultation with the Secretary of Labor, encouraging the adoption of these guidelines in their programs to the extent appropriate for each program and consistent with applicable law.\n",
      "\n",
      "(iii) To support employees whose work is monitored or augmented by AI in being compensated appropriately for all of their work time, the Secretary of Labor shall issue guidance to make clear that employers that deploy AI to monitor or augment employees‚Äô work must continue to comply with protections that ensure that workers are compensated for their hours worked, as defined under the Fair Labor Standards Act of 1938, 29 U.S.C. 201 et seq., and other legal requirements.\n",
      "\n",
      "(c) To foster a diverse AI-ready workforce, the Director of NSF shall prioritize available resources to support AI-related education and AI-related workforce development through existing programs. The Director shall additionally consult with agencies, as appropriate, to identify further opportunities for agencies to allocate resources for those purposes. The actions by the Director shall use appropriate fellowship programs and awards for these purposes.\n",
      "\n",
      "Sec. 7. Advancing Equity and Civil Rights.\n",
      "\n",
      "7.1. Strengthening AI and Civil Rights in the Criminal Justice System. (a) To address unlawful discrimination and other harms that may be exacerbated by AI, the Attorney General shall:\n",
      "\n",
      "(i) consistent with Executive Order 12250 of November 2, 1980 (Leadership and Coordination of Nondiscrimination Laws), Executive Order 14091, and 28 C.F.R. 0.50-51, coordinate with and support agencies in their implementation and enforcement of existing Federal laws to address civil rights and civil liberties violations and discrimination related to AI;\n",
      "\n",
      "(ii) direct the Assistant Attorney General in charge of the Civil Rights Division to convene, within 90 days of the date of this order, a meeting of the heads of Federal civil rights offices ‚Äî for which meeting the heads of civil rights offices within independent regulatory agencies will be encouraged to join ‚Äî to discuss comprehensive use of their respective authorities and offices to: prevent and address discrimination in the use of automated systems, including algorithmic discrimination; increase coordination between the Department of Justice‚Äôs Civil Rights Division and Federal civil rights offices concerning issues related to AI and algorithmic discrimination; improve external stakeholder engagement to promote public awareness of potential discriminatory uses and effects of AI; and develop, as appropriate, additional training, technical assistance, guidance, or other resources; and\n",
      "\n",
      "(iii) consider providing, as appropriate and consistent with applicable law, guidance, technical assistance, and training to State, local, Tribal, and territorial investigators and prosecutors on best practices for investigating and prosecuting civil rights violations and discrimination related to automated systems, including AI.\n",
      "\n",
      "(b) To promote the equitable treatment of individuals and adhere to the Federal Government‚Äôs fundamental obligation to ensure fair and impartial justice for all, with respect to the use of AI in the criminal justice system, the Attorney General shall, in consultation with the Secretary of Homeland Security and the Director of OSTP:\n",
      "\n",
      "(i) within 365 days of the date of this order, submit to the President a report that addresses the use of AI in the criminal justice system, including any use in:\n",
      "\n",
      "(A) sentencing;\n",
      "\n",
      "(B) parole, supervised release, and probation;\n",
      "\n",
      "(C) bail, pretrial release, and pretrial detention;\n",
      "\n",
      "(D) risk assessments, including pretrial, earned time, and early release or transfer to home-confinement determinations;\n",
      "\n",
      "(E) police surveillance;\n",
      "\n",
      "(F) crime forecasting and predictive policing, including the ingestion of historical crime data into AI systems to predict high-density ‚Äúhot spots‚Äù;\n",
      "\n",
      "(G) prison-management tools; and\n",
      "\n",
      "(H) forensic analysis;\n",
      "\n",
      "(ii) within the report set forth in subsection 7.1(b)(i) of this section:\n",
      "\n",
      "(A) identify areas where AI can enhance law enforcement efficiency and accuracy, consistent with protections for privacy, civil rights, and civil liberties; and\n",
      "\n",
      "(B) recommend best practices for law enforcement agencies, including safeguards and appropriate use limits for AI, to address the concerns set forth in section 13(e)(i) of Executive Order 14074 as well as the best practices and the guidelines set forth in section 13(e)(iii) of Executive Order 14074; and\n",
      "\n",
      "(iii) supplement the report set forth in subsection 7.1(b)(i) of this section as appropriate with recommendations to the President, including with respect to requests for necessary legislation.\n",
      "\n",
      "(c) To advance the presence of relevant technical experts and expertise (such as machine-learning engineers, software and infrastructure engineering, data privacy experts, data scientists, and user experience researchers) among law enforcement professionals:\n",
      "\n",
      "(i) The interagency working group created pursuant to section 3 of Executive Order 14074 shall, within 180 days of the date of this order, identify and share best practices for recruiting and hiring law enforcement professionals who have the technical skills mentioned in subsection 7.1(c) of this section, and for training law enforcement professionals about responsible application of AI.\n",
      "\n",
      "(ii) Within 270 days of the date of this order, the Attorney General shall, in consultation with the Secretary of Homeland Security, consider those best practices and the guidance developed under section 3(d) of Executive Order 14074 and, if necessary, develop additional general recommendations for State, local, Tribal, and territorial law enforcement agencies and criminal justice agencies seeking to recruit, hire, train, promote, and retain highly qualified and service-oriented officers and staff with relevant technical knowledge. In considering this guidance, the Attorney General shall consult with State, local, Tribal, and territorial law enforcement agencies, as appropriate.\n",
      "\n",
      "(iii) Within 365 days of the date of this order, the Attorney General shall review the work conducted pursuant to section 2(b) of Executive Order 14074 and, if appropriate, reassess the existing capacity to investigate law enforcement deprivation of rights under color of law resulting from the use of AI, including through improving and increasing training of Federal law enforcement officers, their supervisors, and Federal prosecutors on how to investigate and prosecute cases related to AI involving the deprivation of rights under color of law pursuant to 18 U.S.C. 242.\n",
      "\n",
      "7.2. Protecting Civil Rights Related to Government Benefits and Programs. (a) To advance equity and civil rights, consistent with the directives of Executive Order 14091, and in addition to complying with the guidance on Federal Government use of AI issued pursuant to section 10.1(b) of this order, agencies shall use their respective civil rights and civil liberties offices and authorities ‚Äî as appropriate and consistent with applicable law ‚Äî to prevent and address unlawful discrimination and other harms that result from uses of AI in Federal Government programs and benefits administration. This directive does not apply to agencies‚Äô civil or criminal enforcement authorities. Agencies shall consider opportunities to ensure that their respective civil rights and civil liberties offices are appropriately consulted on agency decisions regarding the design, development, acquisition, and use of AI in Federal Government programs and benefits administration. To further these objectives, agencies shall also consider opportunities to increase coordination, communication, and engagement about AI as appropriate with community-based organizations; civil-rights and civil-liberties organizations; academic institutions; industry; State, local, Tribal, and territorial governments; and other stakeholders.\n",
      "\n",
      "(b) To promote equitable administration of public benefits:\n",
      "\n",
      "(i) The Secretary of HHS shall, within 180 days of the date of this order and in consultation with relevant agencies, publish a plan, informed by the guidance issued pursuant to section 10.1(b) of this order, addressing the use of automated or algorithmic systems in the implementation by States and localities of public benefits and services administered by the Secretary, such as to promote: assessment of access to benefits by qualified recipients; notice to recipients about the presence of such systems; regular evaluation to detect unjust denials; processes to retain appropriate levels of discretion of expert agency staff; processes to appeal denials to human reviewers; and analysis of whether algorithmic systems in use by benefit programs achieve equitable and just outcomes.\n",
      "\n",
      "(ii) The Secretary of Agriculture shall, within 180 days of the date of this order and as informed by the guidance issued pursuant to section 10.1(b) of this order, issue guidance to State, local, Tribal, and territorial public-benefits administrators on the use of automated or algorithmic systems in implementing benefits or in providing customer support for benefit programs administered by the Secretary, to ensure that programs using those systems:\n",
      "\n",
      "(A) maximize program access for eligible recipients;\n",
      "\n",
      "(B) employ automated or algorithmic systems in a manner consistent with any requirements for using merit systems personnel in public-benefits programs;\n",
      "\n",
      "(C) identify instances in which reliance on automated or algorithmic systems would require notification by the State, local, Tribal, or territorial government to the Secretary;\n",
      "\n",
      "(D) identify instances when applicants and participants can appeal benefit determinations to a human reviewer for reconsideration and can receive other customer support from a human being;\n",
      "\n",
      "(E) enable auditing and, if necessary, remediation of the logic used to arrive at an individual decision or determination to facilitate the evaluation of appeals; and\n",
      "\n",
      "(F) enable the analysis of whether algorithmic systems in use by benefit programs achieve equitable outcomes.\n",
      "\n",
      "7.3. Strengthening AI and Civil Rights in the Broader Economy. (a) Within 365 days of the date of this order, to prevent unlawful discrimination from AI used for hiring, the Secretary of Labor shall publish guidance for Federal contractors regarding nondiscrimination in hiring involving AI and other technology-based hiring systems.\n",
      "\n",
      "(b) To address discrimination and biases against protected groups in housing markets and consumer financial markets, the Director of the Federal Housing Finance Agency and the Director of the Consumer Financial Protection Bureau are encouraged to consider using their authorities, as they deem appropriate, to require their respective regulated entities, where possible, to use appropriate methodologies including AI tools to ensure compliance with Federal law and:\n",
      "\n",
      "(i) evaluate their underwriting models for bias or disparities affecting protected groups; and\n",
      "\n",
      "(ii) evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.\n",
      "\n",
      "(c) Within 180 days of the date of this order, to combat unlawful discrimination enabled by automated or algorithmic tools used to make decisions about access to housing and in other real estate-related transactions, the Secretary of Housing and Urban Development shall, and the Director of the Consumer Financial Protection Bureau is encouraged to, issue additional guidance:\n",
      "\n",
      "(i) addressing the use of tenant screening systems in ways that may violate the Fair Housing Act (Public Law 90-284), the Fair Credit Reporting Act (Public Law 91-508), or other relevant Federal laws, including how the use of data, such as criminal records, eviction records, and credit information, can lead to discriminatory outcomes in violation of Federal law; and\n",
      "\n",
      "(ii) addressing how the Fair Housing Act, the Consumer Financial Protection Act of 2010 (title X of Public Law 111-203), or the Equal Credit Opportunity Act (Public Law 93-495) apply to the advertising of housing, credit, and other real estate-related transactions through digital platforms, including those that use algorithms to facilitate advertising delivery, as well as on best practices to avoid violations of Federal law.\n",
      "\n",
      "(d) To help ensure that people with disabilities benefit from AI‚Äôs promise while being protected from its risks, including unequal treatment from the use of biometric data like gaze direction, eye tracking, gait analysis, and hand motions, the Architectural and Transportation Barriers Compliance Board is encouraged, as it deems appropriate, to solicit public participation and conduct community engagement; to issue technical assistance and recommendations on the risks and benefits of AI in using biometric data as an input; and to provide people with disabilities access to information and communication technology and transportation services.\n",
      "\n",
      "Sec. 8. Protecting Consumers, Patients, Passengers, and Students. (a) Independent regulatory agencies are encouraged, as they deem appropriate, to consider using their full range of authorities to protect American consumers from fraud, discrimination, and threats to privacy and to address other risks that may arise from the use of AI, including risks to financial stability, and to consider rulemaking, as well as emphasizing or clarifying where existing regulations and guidance apply to AI, including clarifying the responsibility of regulated entities to conduct due diligence on and monitor any third-party AI services they use, and emphasizing or clarifying requirements and expectations related to the transparency of AI models and regulated entities‚Äô ability to explain their use of AI models.\n",
      "\n",
      "(b) To help ensure the safe, responsible deployment and use of AI in the healthcare, public-health, and human-services sectors:\n",
      "\n",
      "(i) Within 90 days of the date of this order, the Secretary of HHS shall, in consultation with the Secretary of Defense and the Secretary of Veterans Affairs, establish an HHS AI Task Force that shall, within 365 days of its creation, develop a strategic plan that includes policies and frameworks ‚Äî possibly including regulatory action, as appropriate ‚Äî on responsible deployment and use of AI and AI-enabled technologies in the health and human services sector (including research and discovery, drug and device safety, healthcare delivery and financing, and public health), and identify appropriate guidance and resources to promote that deployment, including in the following areas:\n",
      "\n",
      "(A) development, maintenance, and use of predictive and generative AI-enabled technologies in healthcare delivery and financing ‚Äî including quality measurement, performance improvement, program integrity, benefits administration, and patient experience ‚Äî taking into account considerations such as appropriate human oversight of the application of AI-generated output;\n",
      "\n",
      "(B) long-term safety and real-world performance monitoring of AI-enabled technologies in the health and human services sector, including clinically relevant or significant modifications and performance across population groups, with a means to communicate product updates to regulators, developers, and users;\n",
      "\n",
      "(C) incorporation of equity principles in AI-enabled technologies used in the health and human services sector, using disaggregated data on affected populations and representative population data sets when developing new models, monitoring algorithmic performance against discrimination and bias in existing models, and helping to identify and mitigate discrimination and bias in current systems;\n",
      "\n",
      "(D) incorporation of safety, privacy, and security standards into the software-development lifecycle for protection of personally identifiable information, including measures to address AI-enhanced cybersecurity threats in the health and human services sector;\n",
      "\n",
      "(E) development, maintenance, and availability of documentation to help users determine appropriate and safe uses of AI in local settings in the health and human services sector;\n",
      "\n",
      "(F) work to be done with State, local, Tribal, and territorial health and human services agencies to advance positive use cases and best practices for use of AI in local settings; and\n",
      "\n",
      "(G) identification of uses of AI to promote workplace efficiency and satisfaction in the health and human services sector, including reducing administrative burdens.\n",
      "\n",
      "(ii) Within 180 days of the date of this order, the Secretary of HHS shall direct HHS components, as the Secretary of HHS deems appropriate, to develop a strategy, in consultation with relevant agencies, to determine whether AI-enabled technologies in the health and human services sector maintain appropriate levels of quality, including, as appropriate, in the areas described in subsection (b)(i) of this section. This work shall include the development of AI assurance policy ‚Äî to evaluate important aspects of the performance of AI-enabled healthcare tools ‚Äî and infrastructure needs for enabling pre-market assessment and post-market oversight of AI-enabled healthcare-technology algorithmic system performance against real-world data.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Secretary of HHS shall, in consultation with relevant agencies as the Secretary of HHS deems appropriate, consider appropriate actions to advance the prompt understanding of, and compliance with, Federal nondiscrimination laws by health and human services providers that receive Federal financial assistance, as well as how those laws relate to AI. Such actions may include:\n",
      "\n",
      "(A) convening and providing technical assistance to health and human services providers and payers about their obligations under Federal nondiscrimination and privacy laws as they relate to AI and the potential consequences of noncompliance; and\n",
      "\n",
      "(B) issuing guidance, or taking other action as appropriate, in response to any complaints or other reports of noncompliance with Federal nondiscrimination and privacy laws as they relate to AI.\n",
      "\n",
      "(iv) Within 365 days of the date of this order, the Secretary of HHS shall, in consultation with the Secretary of Defense and the Secretary of Veterans Affairs, establish an AI safety program that, in partnership with voluntary federally listed Patient Safety Organizations:\n",
      "\n",
      "(A) establishes a common framework for approaches to identifying and capturing clinical errors resulting from AI deployed in healthcare settings as well as specifications for a central tracking repository for associated incidents that cause harm, including through bias or discrimination, to patients, caregivers, or other parties;\n",
      "\n",
      "(B) analyzes captured data and generated evidence to develop, wherever appropriate, recommendations, best practices, or other informal guidelines aimed at avoiding these harms; and\n",
      "\n",
      "(C) disseminates those recommendations, best practices, or other informal guidance to appropriate stakeholders, including healthcare providers.\n",
      "\n",
      "(v) Within 365 days of the date of this order, the Secretary of HHS shall develop a strategy for regulating the use of AI or AI-enabled tools in drug-development processes. The strategy shall, at a minimum:\n",
      "\n",
      "(A) define the objectives, goals, and high-level principles required for appropriate regulation throughout each phase of drug development;\n",
      "\n",
      "(B) identify areas where future rulemaking, guidance, or additional statutory authority may be necessary to implement such a regulatory system;\n",
      "\n",
      "(C) identify the existing budget, resources, personnel, and potential for new public/private partnerships necessary for such a regulatory system; and\n",
      "\n",
      "(D) consider risks identified by the actions undertaken to implement section 4 of this order.\n",
      "\n",
      "(c) To promote the safe and responsible development and use of AI in the transportation sector, in consultation with relevant agencies:\n",
      "\n",
      "(i) Within 30 days of the date of this order, the Secretary of Transportation shall direct the Nontraditional and Emerging Transportation Technology (NETT) Council to assess the need for information, technical assistance, and guidance regarding the use of AI in transportation. The Secretary of Transportation shall further direct the NETT Council, as part of any such efforts, to:\n",
      "\n",
      "(A) support existing and future initiatives to pilot transportation-related applications of AI, as they align with policy priorities articulated in the Department of Transportation‚Äôs (DOT) Innovation Principles, including, as appropriate, through technical assistance and connecting stakeholders;\n",
      "\n",
      "(B) evaluate the outcomes of such pilot programs in order to assess when DOT, or other Federal or State agencies, have sufficient information to take regulatory actions, as appropriate, and recommend appropriate actions when that information is available; and\n",
      "\n",
      "(C) establish a new DOT Cross-Modal Executive Working Group, which will consist of members from different divisions of DOT and coordinate applicable work among these divisions, to solicit and use relevant input from appropriate stakeholders.\n",
      "\n",
      "(ii) Within 90 days of the date of this order, the Secretary of Transportation shall direct appropriate Federal Advisory Committees of the DOT to provide advice on the safe and responsible use of AI in transportation. The committees shall include the Advanced Aviation Advisory Committee, the Transforming Transportation Advisory Committee, and the Intelligent Transportation Systems Program Advisory Committee.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Secretary of Transportation shall direct the Advanced Research Projects Agency-Infrastructure (ARPA-I) to explore the transportation-related opportunities and challenges of AI ‚Äî including regarding software-defined AI enhancements impacting autonomous mobility ecosystems. The Secretary of Transportation shall further encourage ARPA-I to prioritize the allocation of grants to those opportunities, as appropriate. The work tasked to ARPA-I shall include soliciting input on these topics through a public consultation process, such as an RFI.\n",
      "\n",
      "(d) To help ensure the responsible development and deployment of AI in the education sector, the Secretary of Education shall, within 365 days of the date of this order, develop resources, policies, and guidance regarding AI. These resources shall address safe, responsible, and nondiscriminatory uses of AI in education, including the impact AI systems have on vulnerable and underserved communities, and shall be developed in consultation with stakeholders as appropriate. They shall also include the development of an ‚ÄúAI toolkit‚Äù for education leaders implementing recommendations from the Department of Education‚Äôs AI and the Future of Teaching and Learning report, including appropriate human review of AI decisions, designing AI systems to enhance trust and safety and align with privacy-related laws and regulations in the educational context, and developing education-specific guardrails.\n",
      "\n",
      "(e) The Federal Communications Commission is encouraged to consider actions related to how AI will affect communications networks and consumers, including by:\n",
      "\n",
      "(i) examining the potential for AI to improve spectrum management, increase the efficiency of non-Federal spectrum usage, and expand opportunities for the sharing of non-Federal spectrum;\n",
      "\n",
      "(ii) coordinating with the National Telecommunications and Information Administration to create opportunities for sharing spectrum between Federal and non-Federal spectrum operations;\n",
      "\n",
      "(iii) providing support for efforts to improve network security, resiliency, and interoperability using next-generation technologies that incorporate AI, including self-healing networks, 6G, and Open RAN; and\n",
      "\n",
      "(iv) encouraging, including through rulemaking, efforts to combat unwanted robocalls and robotexts that are facilitated or exacerbated by AI and to deploy AI technologies that better serve consumers by blocking unwanted robocalls and robotexts.\n",
      "\n",
      "Sec. 9. Protecting Privacy. (a) To mitigate privacy risks potentially exacerbated by AI ‚Äî including by AI‚Äôs facilitation of the collection or use of information about individuals, or the making of inferences about individuals ‚Äî the Director of OMB shall:\n",
      "\n",
      "(i) evaluate and take steps to identify commercially available information (CAI) procured by agencies, particularly CAI that contains personally identifiable information and including CAI procured from data brokers and CAI procured and processed indirectly through vendors, in appropriate agency inventory and reporting processes (other than when it is used for the purposes of national security);\n",
      "\n",
      "(ii) evaluate, in consultation with the Federal Privacy Council and the Interagency Council on Statistical Policy, agency standards and procedures associated with the collection, processing, maintenance, use, sharing, dissemination, and disposition of CAI that contains personally identifiable information (other than when it is used for the purposes of national security) to inform potential guidance to agencies on ways to mitigate privacy and confidentiality risks from agencies‚Äô activities related to CAI;\n",
      "\n",
      "(iii) within 180 days of the date of this order, in consultation with the Attorney General, the Assistant to the President for Economic Policy, and the Director of OSTP, issue an RFI to inform potential revisions to guidance to agencies on implementing the privacy provisions of the E-Government Act of 2002 (Public Law 107-347). The RFI shall seek feedback regarding how privacy impact assessments may be more effective at mitigating privacy risks, including those that are further exacerbated by AI; and\n",
      "\n",
      "(iv) take such steps as are necessary and appropriate, consistent with applicable law, to support and advance the near-term actions and long-term strategy identified through the RFI process, including issuing new or updated guidance or RFIs or consulting other agencies or the Federal Privacy Council.\n",
      "\n",
      "(b) Within 365 days of the date of this order, to better enable agencies to use PETs to safeguard Americans‚Äô privacy from the potential threats exacerbated by AI, the Secretary of Commerce, acting through the Director of NIST, shall create guidelines for agencies to evaluate the efficacy of differential-privacy-guarantee protections, including for AI. The guidelines shall, at a minimum, describe the significant factors that bear on differential-privacy safeguards and common risks to realizing differential privacy in practice.\n",
      "\n",
      "(c) To advance research, development, and implementation related to PETs:\n",
      "\n",
      "(i) Within 120 days of the date of this order, the Director of NSF, in collaboration with the Secretary of Energy, shall fund the creation of a Research Coordination Network (RCN) dedicated to advancing privacy research and, in particular, the development, deployment, and scaling of PETs. The RCN shall serve to enable privacy researchers to share information, coordinate and collaborate in research, and develop standards for the privacy-research community.\n",
      "\n",
      "(ii) Within 240 days of the date of this order, the Director of NSF shall engage with agencies to identify ongoing work and potential opportunities to incorporate PETs into their operations. The Director of NSF shall, where feasible and appropriate, prioritize research ‚Äî including efforts to translate research discoveries into practical applications ‚Äî that encourage the adoption of leading-edge PETs solutions for agencies‚Äô use, including through research engagement through the RCN described in subsection (c)(i) of this section.\n",
      "\n",
      "(iii) The Director of NSF shall use the results of the United States-United Kingdom PETs Prize Challenge to inform the approaches taken, and opportunities identified, for PETs research and adoption.\n",
      "\n",
      "Sec. 10. Advancing Federal Government Use of AI.\n",
      "\n",
      "10.1. Providing Guidance for AI Management. (a) To coordinate the use of AI across the Federal Government, within 60 days of the date of this order and on an ongoing basis as necessary, the Director of OMB shall convene and chair an interagency council to coordinate the development and use of AI in agencies‚Äô programs and operations, other than the use of AI in national security systems. The Director of OSTP shall serve as Vice Chair for the interagency council. The interagency council‚Äôs membership shall include, at minimum, the heads of the agencies identified in 31 U.S.C. 901(b), the Director of National Intelligence, and other agencies as identified by the Chair. Until agencies designate their permanent Chief AI Officers consistent with the guidance described in subsection 10.1(b) of this section, they shall be represented on the interagency council by an appropriate official at the Assistant Secretary level or equivalent, as determined by the head of each agency.\n",
      "\n",
      "(b) To provide guidance on Federal Government use of AI, within 150 days of the date of this order and updated periodically thereafter, the Director of OMB, in coordination with the Director of OSTP, and in consultation with the interagency council established in subsection 10.1(a) of this section, shall issue guidance to agencies to strengthen the effective and appropriate use of AI, advance AI innovation, and manage risks from AI in the Federal Government. The Director of OMB‚Äôs guidance shall specify, to the extent appropriate and consistent with applicable law:\n",
      "\n",
      "(i) the requirement to designate at each agency within 60 days of the issuance of the guidance a Chief Artificial Intelligence Officer who shall hold primary responsibility in their agency, in coordination with other responsible officials, for coordinating their agency‚Äôs use of AI, promoting AI innovation in their agency, managing risks from their agency‚Äôs use of AI, and carrying out the responsibilities described in section 8(c) of Executive Order 13960 of December 3, 2020 (Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government), and section 4(b) of Executive Order 14091;\n",
      "\n",
      "(ii) the Chief Artificial Intelligence Officers‚Äô roles, responsibilities, seniority, position, and reporting structures;\n",
      "\n",
      "(iii) for the agencies identified in 31 U.S.C. 901(b), the creation of internal Artificial Intelligence Governance Boards, or other appropriate mechanisms, at each agency within 60 days of the issuance of the guidance to coordinate and govern AI issues through relevant senior leaders from across the agency;\n",
      "\n",
      "(iv) required minimum risk-management practices for Government uses of AI that impact people‚Äôs rights or safety, including, where appropriate, the following practices derived from OSTP‚Äôs Blueprint for an AI Bill of Rights and the NIST AI Risk Management Framework: conducting public consultation; assessing data quality; assessing and mitigating disparate impacts and algorithmic discrimination; providing notice of the use of AI; continuously monitoring and evaluating deployed AI; and granting human consideration and remedies for adverse decisions made using AI;\n",
      "\n",
      "(v) specific Federal Government uses of AI that are presumed by default to impact rights or safety;\n",
      "\n",
      "(vi) recommendations to agencies to reduce barriers to the responsible use of AI, including barriers related to information technology infrastructure, data, workforce, budgetary restrictions, and cybersecurity processes;\n",
      "\n",
      "(vii) requirements that agencies identified in 31 U.S.C. 901(b) develop AI strategies and pursue high-impact AI use cases;\n",
      "\n",
      "(viii) in consultation with the Secretary of Commerce, the Secretary of Homeland Security, and the heads of other appropriate agencies as determined by the Director of OMB, recommendations to agencies regarding:\n",
      "\n",
      "(A) external testing for AI, including AI red-teaming for generative AI, to be developed in coordination with the Cybersecurity and Infrastructure Security Agency;\n",
      "\n",
      "(B) testing and safeguards against discriminatory, misleading, inflammatory, unsafe, or deceptive outputs, as well as against producing child sexual abuse material and against producing non-consensual intimate imagery of real individuals (including intimate digital depictions of the body or body parts of an identifiable individual), for generative AI;\n",
      "\n",
      "(C) reasonable steps to watermark or otherwise label output from generative AI;\n",
      "\n",
      "(D) application of the mandatory minimum risk-management practices defined under subsection 10.1(b)(iv) of this section to procured AI;\n",
      "\n",
      "(E) independent evaluation of vendors‚Äô claims concerning both the effectiveness and risk mitigation of their AI offerings;\n",
      "\n",
      "(F) documentation and oversight of procured AI;\n",
      "\n",
      "(G) maximizing the value to agencies when relying on contractors to use and enrich Federal Government data for the purposes of AI development and operation;\n",
      "\n",
      "(H) provision of incentives for the continuous improvement of procured AI; and\n",
      "\n",
      "(I) training on AI in accordance with the principles set out in this order and in other references related to AI listed herein; and\n",
      "\n",
      "(ix) requirements for public reporting on compliance with this guidance.\n",
      "\n",
      "(c) To track agencies‚Äô AI progress, within 60 days of the issuance of the guidance established in subsection 10.1(b) of this section and updated periodically thereafter, the Director of OMB shall develop a method for agencies to track and assess their ability to adopt AI into their programs and operations, manage its risks, and comply with Federal policy on AI. This method should draw on existing related efforts as appropriate and should address, as appropriate and consistent with applicable law, the practices, processes, and capabilities necessary for responsible AI adoption, training, and governance across, at a minimum, the areas of information technology infrastructure, data, workforce, leadership, and risk management.\n",
      "\n",
      "(d) To assist agencies in implementing the guidance to be established in subsection 10.1(b) of this section:\n",
      "\n",
      "(i) within 90 days of the issuance of the guidance, the Secretary of Commerce, acting through the Director of NIST, and in coordination with the Director of OMB and the Director of OSTP, shall develop guidelines, tools, and practices to support implementation of the minimum risk-management practices described in subsection 10.1(b)(iv) of this section; and\n",
      "\n",
      "(ii) within 180 days of the issuance of the guidance, the Director of OMB shall develop an initial means to ensure that agency contracts for the acquisition of AI systems and services align with the guidance described in subsection 10.1(b) of this section and advance the other aims identified in section 7224(d)(1) of the Advancing American AI Act (Public Law 117-263, div. G, title LXXII, subtitle B).\n",
      "\n",
      "(e) To improve transparency for agencies‚Äô use of AI, the Director of OMB shall, on an annual basis, issue instructions to agencies for the collection, reporting, and publication of agency AI use cases, pursuant to section 7225(a) of the Advancing American AI Act. Through these instructions, the Director shall, as appropriate, expand agencies‚Äô reporting on how they are managing risks from their AI use cases and update or replace the guidance originally established in section 5 of Executive Order 13960.\n",
      "\n",
      "(f) To advance the responsible and secure use of generative AI in the Federal Government:\n",
      "\n",
      "(i) As generative AI products become widely available and common in online platforms, agencies are discouraged from imposing broad general bans or blocks on agency use of generative AI. Agencies should instead limit access, as necessary, to specific generative AI services based on specific risk assessments; establish guidelines and limitations on the appropriate use of generative AI; and, with appropriate safeguards in place, provide their personnel and programs with access to secure and reliable generative AI capabilities, at least for the purposes of experimentation and routine tasks that carry a low risk of impacting Americans‚Äô rights. To protect Federal Government information, agencies are also encouraged to employ risk-management practices, such as training their staff on proper use, protection, dissemination, and disposition of Federal information; negotiating appropriate terms of service with vendors; implementing measures designed to ensure compliance with record-keeping, cybersecurity, confidentiality, privacy, and data protection requirements; and deploying other measures to prevent misuse of Federal Government information in generative AI.\n",
      "\n",
      "(ii) Within 90 days of the date of this order, the Administrator of General Services, in coordination with the Director of OMB, and in consultation with the Federal Secure Cloud Advisory Committee and other relevant agencies as the Administrator of General Services may deem appropriate, shall develop and issue a framework for prioritizing critical and emerging technologies offerings in the Federal Risk and Authorization Management Program authorization process, starting with generative AI offerings that have the primary purpose of providing large language model-based chat interfaces, code-generation and debugging tools, and associated application programming interfaces, as well as prompt-based image generators. This framework shall apply for no less than 2 years from the date of its issuance. Agency Chief Information Officers, Chief Information Security Officers, and authorizing officials are also encouraged to prioritize generative AI and other critical and emerging technologies in granting authorities for agency operation of information technology systems and any other applicable release or oversight processes, using continuous authorizations and approvals wherever feasible.\n",
      "\n",
      "(iii) Within 180 days of the date of this order, the Director of the Office of Personnel Management (OPM), in coordination with the Director of OMB, shall develop guidance on the use of generative AI for work by the Federal workforce.\n",
      "\n",
      "(g) Within 30 days of the date of this order, to increase agency investment in AI, the Technology Modernization Board shall consider, as it deems appropriate and consistent with applicable law, prioritizing funding for AI projects for the Technology Modernization Fund for a period of at least 1 year. Agencies are encouraged to submit to the Technology Modernization Fund project funding proposals that include AI ‚Äî and particularly generative AI ‚Äî in service of mission delivery.\n",
      "\n",
      "(h) Within 180 days of the date of this order, to facilitate agencies‚Äô access to commercial AI capabilities, the Administrator of General Services, in coordination with the Director of OMB, and in collaboration with the Secretary of Defense, the Secretary of Homeland Security, the Director of National Intelligence, the Administrator of the National Aeronautics and Space Administration, and the head of any other agency identified by the Administrator of General Services, shall take steps consistent with applicable law to facilitate access to Federal Government-wide acquisition solutions for specified types of AI services and products, such as through the creation of a resource guide or other tools to assist the acquisition workforce. Specified types of AI capabilities shall include generative AI and specialized computing infrastructure.\n",
      "\n",
      "(i) The initial means, instructions, and guidance issued pursuant to subsections 10.1(a)-(h) of this section shall not apply to AI when it is used as a component of a national security system, which shall be addressed by the proposed National Security Memorandum described in subsection 4.8 of this order.\n",
      "\n",
      "10.2. Increasing AI Talent in Government. (a) Within 45 days of the date of this order, to plan a national surge in AI talent in the Federal Government, the Director of OSTP and the Director of OMB, in consultation with the Assistant to the President for National Security Affairs, the Assistant to the President for Economic Policy, the Assistant to the President and Domestic Policy Advisor, and the Assistant to the President and Director of the Gender Policy Council, shall identify priority mission areas for increased Federal Government AI talent, the types of talent that are highest priority to recruit and develop to ensure adequate implementation of this order and use of relevant enforcement and regulatory authorities to address AI risks, and accelerated hiring pathways.\n",
      "\n",
      "(b) Within 45 days of the date of this order, to coordinate rapid advances in the capacity of the Federal AI workforce, the Assistant to the President and Deputy Chief of Staff for Policy, in coordination with the Director of OSTP and the Director of OMB, and in consultation with the National Cyber Director, shall convene an AI and Technology Talent Task Force, which shall include the Director of OPM, the Director of the General Services Administration‚Äôs Technology Transformation Services, a representative from the Chief Human Capital Officers Council, the Assistant to the President for Presidential Personnel, members of appropriate agency technology talent programs, a representative of the Chief Data Officer Council, and a representative of the interagency council convened under subsection 10.1(a) of this section. The Task Force‚Äôs purpose shall be to accelerate and track the hiring of AI and AI-enabling talent across the Federal Government, including through the following actions:\n",
      "\n",
      "(i) within 180 days of the date of this order, tracking and reporting progress to the President on increasing AI capacity across the Federal Government, including submitting to the President a report and recommendations for further increasing capacity;\n",
      "\n",
      "(ii) identifying and circulating best practices for agencies to attract, hire, retain, train, and empower AI talent, including diversity, inclusion, and accessibility best practices, as well as to plan and budget adequately for AI workforce needs;\n",
      "\n",
      "(iii) coordinating, in consultation with the Director of OPM, the use of fellowship programs and agency technology-talent programs and human-capital teams to build hiring capabilities, execute hires, and place AI talent to fill staffing gaps; and\n",
      "\n",
      "(iv) convening a cross-agency forum for ongoing collaboration between AI professionals to share best practices and improve retention.\n",
      "\n",
      "(c) Within 45 days of the date of this order, to advance existing Federal technology talent programs, the United States Digital Service, Presidential Innovation Fellowship, United States Digital Corps, OPM, and technology talent programs at agencies, with support from the AI and Technology Talent Task Force described in subsection 10.2(b) of this section, as appropriate and permitted by law, shall develop and begin to implement plans to support the rapid recruitment of individuals as part of a Federal Government-wide AI talent surge to accelerate the placement of key AI and AI-enabling talent in high-priority areas and to advance agencies‚Äô data and technology strategies.\n",
      "\n",
      "(d) To meet the critical hiring need for qualified personnel to execute the initiatives in this order, and to improve Federal hiring practices for AI talent, the Director of OPM, in consultation with the Director of OMB, shall:\n",
      "\n",
      "(i) within 60 days of the date of this order, conduct an evidence-based review on the need for hiring and workplace flexibility, including Federal Government-wide direct-hire authority for AI and related data-science and technical roles, and, where the Director of OPM finds such authority is appropriate, grant it; this review shall include the following job series at all General Schedule (GS) levels: IT Specialist (2210), Computer Scientist (1550), Computer Engineer (0854), and Program Analyst (0343) focused on AI, and any subsequently developed job series derived from these job series;\n",
      "\n",
      "(ii) within 60 days of the date of this order, consider authorizing the use of excepted service appointments under 5 C.F.R. 213.3102(i)(3) to address the need for hiring additional staff to implement directives of this order;\n",
      "\n",
      "(iii) within 90 days of the date of this order, coordinate a pooled-hiring action informed by subject-matter experts and using skills-based assessments to support the recruitment of AI talent across agencies;\n",
      "\n",
      "(iv) within 120 days of the date of this order, as appropriate and permitted by law, issue guidance for agency application of existing pay flexibilities or incentive pay programs for AI, AI-enabling, and other key technical positions to facilitate appropriate use of current pay incentives;\n",
      "\n",
      "(v) within 180 days of the date of this order, establish guidance and policy on skills-based, Federal Government-wide hiring of AI, data, and technology talent in order to increase access to those with nontraditional academic backgrounds to Federal AI, data, and technology roles;\n",
      "\n",
      "(vi) within 180 days of the date of this order, establish an interagency working group, staffed with both human-resources professionals and recruiting technical experts, to facilitate Federal Government-wide hiring of people with AI and other technical skills;\n",
      "\n",
      "(vii) within 180 days of the date of this order, review existing Executive Core Qualifications (ECQs) for Senior Executive Service (SES) positions informed by data and AI literacy competencies and, within 365 days of the date of this order, implement new ECQs as appropriate in the SES assessment process;\n",
      "\n",
      "(viii) within 180 days of the date of this order, complete a review of competencies for civil engineers (GS-0810 series) and, if applicable, other related occupations, and make recommendations for ensuring that adequate AI expertise and credentials in these occupations in the Federal Government reflect the increased use of AI in critical infrastructure; and\n",
      "\n",
      "(ix) work with the Security, Suitability, and Credentialing Performance Accountability Council to assess mechanisms to streamline and accelerate personnel-vetting requirements, as appropriate, to support AI and fields related to other critical and emerging technologies.\n",
      "\n",
      "(e) To expand the use of special authorities for AI hiring and retention, agencies shall use all appropriate hiring authorities, including Schedule A(r) excepted service hiring and direct-hire authority, as applicable and appropriate, to hire AI talent and AI-enabling talent rapidly. In addition to participating in OPM-led pooled hiring actions, agencies shall collaborate, where appropriate, on agency-led pooled hiring under the Competitive Service Act of 2015 (Public Law 114-137) and other shared hiring. Agencies shall also, where applicable, use existing incentives, pay-setting authorities, and other compensation flexibilities, similar to those used for cyber and information technology positions, for AI and data-science professionals, as well as plain-language job titles, to help recruit and retain these highly skilled professionals. Agencies shall ensure that AI and other related talent needs (such as technology governance and privacy) are reflected in strategic workforce planning and budget formulation.\n",
      "\n",
      "(f) To facilitate the hiring of data scientists, the Chief Data Officer Council shall develop a position-description library for data scientists (job series 1560) and a hiring guide to support agencies in hiring data scientists.\n",
      "\n",
      "(g) To help train the Federal workforce on AI issues, the head of each agency shall implement ‚Äî or increase the availability and use of ‚Äî AI training and familiarization programs for employees, managers, and leadership in technology as well as relevant policy, managerial, procurement, regulatory, ethical, governance, and legal fields. Such training programs should, for example, empower Federal employees, managers, and leaders to develop and maintain an operating knowledge of emerging AI technologies to assess opportunities to use these technologies to enhance the delivery of services to the public, and to mitigate risks associated with these technologies. Agencies that provide professional-development opportunities, grants, or funds for their staff should take appropriate steps to ensure that employees who do not serve in traditional technical roles, such as policy, managerial, procurement, or legal fields, are nonetheless eligible to receive funding for programs and courses that focus on AI, machine learning, data science, or other related subject areas.\n",
      "\n",
      "(h) Within 180 days of the date of this order, to address gaps in AI talent for national defense, the Secretary of Defense shall submit a report to the President through the Assistant to the President for National Security Affairs that includes:\n",
      "\n",
      "(i) recommendations to address challenges in the Department of Defense‚Äôs ability to hire certain noncitizens, including at the Science and Technology Reinvention Laboratories;\n",
      "\n",
      "(ii) recommendations to clarify and streamline processes for accessing classified information for certain noncitizens through Limited Access Authorization at Department of Defense laboratories;\n",
      "\n",
      "(iii) recommendations for the appropriate use of enlistment authority under 10 U.S.C. 504(b)(2) for experts in AI and other critical and emerging technologies; and\n",
      "\n",
      "(iv) recommendations for the Department of Defense and the Department of Homeland Security to work together to enhance the use of appropriate authorities for the retention of certain noncitizens of vital importance to national security by the Department of Defense and the Department of Homeland Security.\n",
      "\n",
      "Sec. 11. Strengthening American Leadership Abroad. (a) To strengthen United States leadership of global efforts to unlock AI‚Äôs potential and meet its challenges, the Secretary of State, in coordination with the Assistant to the President for National Security Affairs, the Assistant to the President for Economic Policy, the Director of OSTP, and the heads of other relevant agencies as appropriate, shall:\n",
      "\n",
      "(i) lead efforts outside of military and intelligence areas to expand engagements with international allies and partners in relevant bilateral, multilateral, and multi-stakeholder fora to advance those allies‚Äô and partners‚Äô understanding of existing and planned AI-related guidance and policies of the United States, as well as to enhance international collaboration; and\n",
      "\n",
      "(ii) lead efforts to establish a strong international framework for managing the risks and harnessing the benefits of AI, including by encouraging international allies and partners to support voluntary commitments similar to those that United States companies have made in pursuit of these objectives and coordinating the activities directed by subsections (b), (c), (d), and (e) of this section, and to develop common regulatory and other accountability principles for foreign nations, including to manage the risk that AI systems pose.\n",
      "\n",
      "(b) To advance responsible global technical standards for AI development and use outside of military and intelligence areas, the Secretary of Commerce, in coordination with the Secretary of State and the heads of other relevant agencies as appropriate, shall lead preparations for a coordinated effort with key international allies and partners and with standards development organizations, to drive the development and implementation of AI-related consensus standards, cooperation and coordination, and information sharing. In particular, the Secretary of Commerce shall:\n",
      "\n",
      "(i) within 270 days of the date of this order, establish a plan for global engagement on promoting and developing AI standards, with lines of effort that may include:\n",
      "\n",
      "(A) AI nomenclature and terminology;\n",
      "\n",
      "(B) best practices regarding data capture, processing, protection, privacy, confidentiality, handling, and analysis;\n",
      "\n",
      "(C) trustworthiness, verification, and assurance of AI systems; and\n",
      "\n",
      "(D) AI risk management;\n",
      "\n",
      "(ii) within 180 days of the date the plan is established, submit a report to the President on priority actions taken pursuant to the plan; and\n",
      "\n",
      "(iii) ensure that such efforts are guided by principles set out in the NIST AI Risk Management Framework and United States Government National Standards Strategy for Critical and Emerging Technology.\n",
      "\n",
      "(c) Within 365 days of the date of this order, to promote safe, responsible, and rights-affirming development and deployment of AI abroad:\n",
      "\n",
      "(i) The Secretary of State and the Administrator of the United States Agency for International Development, in coordination with the Secretary of Commerce, acting through the director of NIST, shall publish an AI in Global Development Playbook that incorporates the AI Risk Management Framework‚Äôs principles, guidelines, and best practices into the social, technical, economic, governance, human rights, and security conditions of contexts beyond United States borders. As part of this work, the Secretary of State and the Administrator of the United States Agency for International Development shall draw on lessons learned from programmatic uses of AI in global development.\n",
      "\n",
      "(ii) The Secretary of State and the Administrator of the United States Agency for International Development, in collaboration with the Secretary of Energy and the Director of NSF, shall develop a Global AI Research Agenda to guide the objectives and implementation of AI-related research in contexts beyond United States borders. The Agenda shall:\n",
      "\n",
      "(A) include principles, guidelines, priorities, and best practices aimed at ensuring the safe, responsible, beneficial, and sustainable global development and adoption of AI; and\n",
      "\n",
      "(B) address AI‚Äôs labor-market implications across international contexts, including by recommending risk mitigations.\n",
      "\n",
      "(d) To address cross-border and global AI risks to critical infrastructure, the Secretary of Homeland Security, in coordination with the Secretary of State, and in consultation with the heads of other relevant agencies as the Secretary of Homeland Security deems appropriate, shall lead efforts with international allies and partners to enhance cooperation to prevent, respond to, and recover from potential critical infrastructure disruptions resulting from incorporation of AI into critical infrastructure systems or malicious use of AI.\n",
      "\n",
      "(i) Within 270 days of the date of this order, the Secretary of Homeland Security, in coordination with the Secretary of State, shall develop a plan for multilateral engagements to encourage the adoption of the AI safety and security guidelines for use by critical infrastructure owners and operators developed in section 4.3(a) of this order.\n",
      "\n",
      "(ii) Within 180 days of establishing the plan described in subsection (d)(i) of this section, the Secretary of Homeland Security shall submit a report to the President on priority actions to mitigate cross-border risks to critical United States infrastructure.\n",
      "\n",
      "Sec. 12. Implementation. (a) There is established, within the Executive Office of the President, the White House Artificial Intelligence Council (White House AI Council). The function of the White House AI Council is to coordinate the activities of agencies across the Federal Government to ensure the effective formulation, development, communication, industry engagement related to, and timely implementation of AI-related policies, including policies set forth in this order.\n",
      "\n",
      "(b) The Assistant to the President and Deputy Chief of Staff for Policy shall serve as Chair of the White House AI Council.\n",
      "\n",
      "(c) In addition to the Chair, the White House AI Council shall consist of the following members, or their designees:\n",
      "\n",
      "(i) the Secretary of State;\n",
      "\n",
      "(ii) the Secretary of the Treasury;\n",
      "\n",
      "(iii) the Secretary of Defense;\n",
      "\n",
      "(iv) the Attorney General;\n",
      "\n",
      "(v) the Secretary of Agriculture;\n",
      "\n",
      "(vi) the Secretary of Commerce;\n",
      "\n",
      "(vii) the Secretary of Labor;\n",
      "\n",
      "(viii) the Secretary of HHS;\n",
      "\n",
      "(ix) the Secretary of Housing and Urban Development;\n",
      "\n",
      "(x) the Secretary of Transportation;\n",
      "\n",
      "(xi) the Secretary of Energy;\n",
      "\n",
      "(xii) the Secretary of Education;\n",
      "\n",
      "(xiii) the Secretary of Veterans Affairs;\n",
      "\n",
      "(xiv) the Secretary of Homeland Security;\n",
      "\n",
      "(xv) the Administrator of the Small Business Administration;\n",
      "\n",
      "(xvi) the Administrator of the United States Agency for International Development;\n",
      "\n",
      "(xvii) the Director of National Intelligence;\n",
      "\n",
      "(xviii) the Director of NSF;\n",
      "\n",
      "(xix) the Director of OMB;\n",
      "\n",
      "(xx) the Director of OSTP;\n",
      "\n",
      "(xxi) the Assistant to the President for National Security Affairs;\n",
      "\n",
      "(xxii) the Assistant to the President for Economic Policy;\n",
      "\n",
      "(xxiii) the Assistant to the President and Domestic Policy Advisor;\n",
      "\n",
      "(xxiv) the Assistant to the President and Chief of Staff to the Vice President;\n",
      "\n",
      "(xxv) the Assistant to the President and Director of the Gender Policy Council;\n",
      "\n",
      "(xxvi) the Chairman of the Council of Economic Advisers;\n",
      "\n",
      "(xxvii) the National Cyber Director;\n",
      "\n",
      "(xxviii) the Chairman of the Joint Chiefs of Staff; and\n",
      "\n",
      "(xxix) the heads of such other agencies, independent regulatory agencies, and executive offices as the Chair may from time to time designate or invite to participate.\n",
      "\n",
      "(d) The Chair may create and coordinate subgroups consisting of White House AI Council members or their designees, as appropriate.\n",
      "\n",
      "Sec. 13. General Provisions. (a) Nothing in this order shall be construed to impair or otherwise affect:\n",
      "\n",
      "(i) the authority granted by law to an executive department or agency, or the head thereof; or\n",
      "\n",
      "(ii) the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals.\n",
      "\n",
      "(b) This order shall be implemented consistent with applicable law and subject to the availability of appropriations. (c) This order is not intended to, and does not, create any right or benefit, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person.\n",
      "\n",
      "JOSEPH R. BIDEN JR.\n",
      "\n",
      "THE WHITE HOUSE, October 30, 2023.\n",
      "\n",
      "\n",
      "\n",
      "Stay Connected\n",
      "\n",
      "Opt in to send and receive text messages from President Biden.\n",
      "\n",
      "Share\n",
      "\n",
      "Share this page on Facebook\n",
      "\n",
      "Share this page on Twitter\n",
      "\n",
      "https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/?utm_source=link' metadata={'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\white_house_executive_order_nov_2023.html'}\n",
      "{'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\white_house_executive_order_nov_2023.html'}\n"
     ]
    }
   ],
   "source": [
    "# HTML Loader Example\n",
    "# Requires: pip install unstructured\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "path = r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\white_house_executive_order_nov_2023.html\"\n",
    "\n",
    "loader = UnstructuredHTMLLoader(path)\n",
    "data = loader.load()\n",
    "print(data[0])\n",
    "print(data[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09eedd",
   "metadata": {},
   "source": [
    "## ‚≠ê2. Splitting External Data for Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23eb62",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![img_2](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_Developing_LLMs_Applications_with_LangChain/_img/0302.jpeg)\n",
    "\n",
    "**Concept Overview:**\n",
    "- Documents must be split into chunks to fit the LLM's context window.\n",
    "- Use `CharacterTextSplitter` or `RecursiveCharacterTextSplitter`.\n",
    "- `chunk_size` and `chunk_overlap` control chunk boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ca39b",
   "metadata": {},
   "source": [
    "### üîπ Why we use `chunk_size`, `chunk_overlap`, and `separator`\n",
    "\n",
    "\n",
    "#### ‚úÖ `chunk_size`\n",
    "- Sets the **maximum number of characters** in each chunk.\n",
    "- Ensures the text is split into **small, manageable pieces** for tasks like embedding or retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ `chunk_overlap`\n",
    "- Ensures that each chunk **shares a few characters** with the next one (3 in this example).\n",
    "- Helps **preserve context** between chunks, which improves semantic understanding.\n",
    "  \n",
    "![Chunk Overlap Example](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_Developing_LLMs_Applications_with_LangChain/_img/0303.jpeg)\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ `separator='.'`\n",
    "- Tells the splitter to try breaking the text at **sentence boundaries** (periods).\n",
    "- Ensures chunks **end naturally**, ideally at the end of a sentence.\n",
    "\n",
    "---\n",
    "\n",
    "### üî∏ Text Splitter: RecursiveCharacterTextSplitter\n",
    "\n",
    "This splitter tries to **preserve meaning** by recursively splitting the text at increasingly granular levels:\n",
    "\n",
    "1. **Paragraph**: `\"\\n\\n\"`\n",
    "2. **Sentence**: `\"\\n\"`\n",
    "3. **Word**: `\" \"`\n",
    "4. **Character**: `\".\"` *(fallback if nothing else works)*\n",
    "\n",
    "üîÅ If the text cannot be split cleanly at one level, it **falls back to the next**.\n",
    "\n",
    "‚úÖ **Goal**: Create chunks that are both **semantically meaningful** and within the size limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b9b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 52, which is longer than the specified 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One machine can do the work of fifty ordinary humans', 'No machine can do the work of one extraordinary human']\n",
      "[52, 53]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "quote = '''One machine can do the work of fifty ordinary humans.\\nNo machine can do the work of one extraordinary human.'''\n",
    "chunk_size = 24\n",
    "chunk_overlap = 3\n",
    "\n",
    "ct_splitter = CharacterTextSplitter(separator='.',\n",
    "                                    chunk_size=chunk_size,\n",
    "                                    chunk_overlap=chunk_overlap)\n",
    "\n",
    "docs = ct_splitter.split_text(quote)\n",
    "\n",
    "print(docs)\n",
    "print([len(doc) for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eecbcc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani‚àó\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer‚àó\\nGoogle Brain\\nnoam@google'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='.com\\nNoam Shazeer‚àó\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar‚àó\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit‚àó\\nGoogle Research\\nusz@google.com\\nLlion Jones‚àó\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez‚àó ‚Ä†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\n≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='.toronto.edu\\n≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó ‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='.\\n‚àóEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n‚Ä†Work performed while at Google Brain.\\n‚Ä°Work performed while at Google Research'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}, page_content='.\\n‚Ä†Work performed while at Google Brain.\\n‚Ä°Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='1 Introduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35, 2, 5]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht‚àí1 and the input for position t'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='.\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}, page_content='..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3'}, page_content='.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by ‚àödk, and apply a softmax function to obtain the weights on the\\nvalues'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n‚àödk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1‚àödk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1‚àödk\\n.\\n3.2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4'}, page_content='. Then their dot product, q ¬∑ k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V) = Concat(head1, ...,headh)WO\\nwhere headi = Attention(QWQ\\ni , KWK\\ni , V WV\\ni )\\nWhere the projections are parameter matricesWQ\\ni ‚àà Rdmodel√ódk , WK\\ni ‚àà Rdmodel√ódk , WV\\ni ‚àà Rdmodel√ódv\\nand WO ‚àà Rhdv√ódmodel'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n‚Ä¢ In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n‚Ä¢ The encoder contains self-attention layers'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='.\\n‚Ä¢ The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n‚Ä¢ Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to ‚àí‚àû) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5'}, page_content='. In the embedding layers, we multiply those weights by ‚àödmodel.\\n5'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 ¬∑ d) O(1) O(1)\\nRecurrent O(n ¬∑ d2) O(n) O(n)\\nConvolutional O(k ¬∑ n ¬∑ d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r ¬∑ n ¬∑ d) O(1) O(n/r)\\n3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere pos is the position and i is the dimension'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2œÄ to 10000 ¬∑ 2œÄ'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. The wavelengths form a geometric progression from 2œÄ to 10000 ¬∑ 2œÄ. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E))'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ‚àà Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6'}, page_content='. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='length n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < ndoes not connect all pairs of input and output\\npositions'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k ¬∑ n ¬∑ d + n ¬∑ d2)'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [20] with Œ≤1 = 0.9, Œ≤2 = 0'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [20] with Œ≤1 = 0.9, Œ≤2 = 0.98 and œµ = 10‚àí9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d‚àí0.5\\nmodel ¬∑ min(step_num‚àí0.5, step_num ¬∑ warmup_steps‚àí1'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='.5\\nmodel ¬∑ min(step_num‚àí0.5, step_num ¬∑ warmup_steps‚àí1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7'}, page_content='. We used\\nwarmup_steps = 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\n7'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [18] 23.75\\nDeep-Att + PosUnk [39] 39.2 1'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.75\\nDeep-Att + PosUnk [39] 39.2 1.0 ¬∑ 1020\\nGNMT + RL [38] 24.6 39.92 2.3 ¬∑ 1019 1.4 ¬∑ 1020\\nConvS2S [9] 25.16 40.46 9.6 ¬∑ 1018 1.5 ¬∑ 1020\\nMoE [32] 26.03 40.56 2.0 ¬∑ 1019 1.2 ¬∑ 1020\\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 ¬∑ 1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 ¬∑ 1020 1'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.4 8.0 ¬∑ 1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 ¬∑ 1020 1.1 ¬∑ 1021\\nConvS2S Ensemble [9] 26.36 41.29 7.7 ¬∑ 1019 1.2 ¬∑ 1021\\nTransformer (base model) 27.3 38.1 3.3 ¬∑ 1018\\nTransformer (big) 28.4 41.8 2'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.7 ¬∑ 1019 1.2 ¬∑ 1021\\nTransformer (base model) 27.3 38.1 3.3 ¬∑ 1018\\nTransformer (big) 28.4 41.8 2.3 ¬∑ 1019\\nResidual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing During training, we employed label smoothing of value œµls = 0.1 [36]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.1.\\nLabel Smoothing During training, we employed label smoothing of value œµls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty Œ± = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8'}, page_content='.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='.\\nN d model dff h d k dv Pdrop œµls\\ntrain PPL BLEU params\\nsteps (dev) (dev) √ó106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='.\\n6.3 English Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}, page_content='.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and Œ± = 0'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and Œ± = 0.3\\nfor both WSJ only and the semi-supervised setting'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8]'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10'}, page_content='. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, √áaglar G√ºl√ßehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770‚Äì778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and J√ºrgen Schmidhuber'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and J√ºrgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and J√ºrgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735‚Äì1780, 1997'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. Long short-term memory. Neural computation,\\n9(8):1735‚Äì1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832‚Äì841. ACL, August 2009'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] ≈Åukasz Kaiser and Samy Bengio'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. arXiv preprint arXiv:1602.02410, 2016.\\n[16] ≈Åukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] ≈Åukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='.\\n[17] ≈Åukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}, page_content='. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313‚Äì330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152‚Äì159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar T√§ckstr√∂m, Dipanjan Das, and Jakob Uszkoreit'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. ACL, June 2006.\\n[27] Ankur Parikh, Oscar T√§ckstr√∂m, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433‚Äì440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929‚Äì1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440‚Äì2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104‚Äì3112, 2014'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. In Advances in Neural Information Processing Systems, pages 3104‚Äì3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Google‚Äôs neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12'}, page_content='. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434‚Äì443. ACL, August 2013.\\n12'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‚Äòmaking‚Äô, completing the phrase ‚Äòmaking..'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}, page_content='...more difficult‚Äô. Attentions here shown only for\\nthe word ‚Äòmaking‚Äô. Different colors represent different heads. Best viewed in color.\\n13'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}, page_content='.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‚Äòits‚Äô for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion'), Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}, page_content='.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the HTML document into memory\n",
    "path = r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\white_house_executive_order_nov_2023.html\"\n",
    "loader = UnstructuredHTMLLoader(path)\n",
    "\n",
    "# Define variables\n",
    "chunk_size = 300\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Split the HTML\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\".\"]  # Splitting on periods\n",
    ")\n",
    "\n",
    "docs = splitter.split_documents(data)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84bd66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Provided proper' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:\\\\01_Github_Repo\\\\GenAI-with-Langchain-and-Huggingface\\\\_Developing_LLMs_Applications_with_LangChain\\\\_data\\\\attention_is_all_you_need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "Provided proper\n",
      "[15, 21, 19, 20, 20, 20, 21, 20, 17, 22, 16, 20, 12, 15, 12, 19, 13, 12, 15, 12, 15, 16, 16, 15, 14, 12, 15, 16, 17, 21, 20, 14, 12, 23, 19, 23, 13, 8, 21, 21, 19, 16, 20, 20, 20, 23, 22, 17, 22, 16, 23, 18, 12, 23, 20, 14, 21, 16, 15, 19, 21, 15, 19, 16, 21, 14, 19, 23, 9, 22, 19, 10, 23, 13, 23, 23, 23, 20, 21, 21, 20, 22, 23, 20, 22, 15, 22, 17, 23, 18, 21, 18, 13, 21, 23, 22, 15, 21, 12, 20, 23, 16, 20, 19, 23, 11, 18, 23, 17, 17, 22, 20, 16, 22, 14, 23, 9, 23, 11, 22, 19, 18, 20, 12, 19, 21, 10, 18, 21, 23, 18, 20, 18, 21, 17, 22, 23, 20, 16, 18, 15, 22, 22, 19, 19, 15, 21, 15, 21, 20, 23, 16, 19, 23, 15, 21, 23, 19, 22, 20, 19, 23, 12, 12, 14, 21, 17, 17, 17, 21, 13, 22, 13, 21, 22, 21, 15, 19, 18, 21, 18, 20, 22, 8, 18, 19, 14, 16, 21, 22, 21, 23, 19, 19, 16, 21, 19, 21, 20, 12, 21, 16, 16, 21, 23, 21, 18, 23, 22, 21, 19, 19, 22, 13, 16, 23, 18, 16, 23, 23, 23, 22, 23, 21, 20, 15, 20, 22, 21, 22, 21, 18, 17, 16, 22, 15, 18, 23, 19, 9, 20, 21, 21, 23, 15, 17, 11, 15, 16, 18, 21, 15, 20, 23, 20, 15, 20, 22, 23, 13, 13, 21, 17, 20, 23, 16, 18, 21, 13, 22, 23, 20, 23, 23, 20, 19, 23, 21, 19, 15, 19, 14, 20, 23, 16, 18, 23, 11, 18, 20, 20, 11, 22, 15, 22, 14, 19, 17, 17, 22, 10, 22, 20, 19, 22, 10, 19, 19, 20, 23, 18, 19, 10, 12, 20, 19, 22, 23, 22, 10, 22, 21, 21, 23, 18, 17, 23, 22, 19, 17, 16, 20, 16, 13, 20, 18, 22, 18, 18, 15, 19, 15, 23, 18, 20, 11, 23, 23, 20, 21, 15, 19, 13, 23, 7, 21, 18, 21, 21, 15, 17, 20, 3, 12, 18, 23, 20, 15, 12, 20, 12, 15, 16, 22, 15, 19, 18, 18, 19, 23, 21, 23, 16, 23, 22, 21, 18, 17, 22, 11, 14, 22, 12, 16, 8, 23, 16, 17, 19, 14, 14, 19, 19, 20, 12, 22, 22, 21, 23, 22, 23, 11, 18, 17, 12, 22, 12, 22, 13, 11, 20, 10, 23, 23, 20, 15, 15, 23, 16, 22, 20, 16, 8, 18, 15, 19, 19, 20, 12, 20, 23, 15, 21, 14, 23, 21, 22, 22, 18, 22, 18, 17, 13, 19, 18, 22, 19, 17, 9, 22, 23, 22, 20, 22, 18, 19, 14, 20, 19, 21, 9, 1, 13, 20, 21, 23, 20, 20, 13, 22, 21, 20, 20, 20, 21, 21, 19, 19, 13, 23, 14, 23, 22, 16, 18, 22, 18, 21, 14, 15, 14, 18, 19, 22, 20, 22, 20, 17, 19, 19, 19, 17, 22, 18, 22, 20, 13, 21, 20, 15, 23, 16, 21, 14, 21, 21, 21, 14, 16, 23, 20, 23, 23, 21, 17, 17, 22, 10, 18, 22, 18, 23, 18, 14, 19, 18, 22, 21, 21, 18, 18, 20, 18, 18, 17, 23, 18, 18, 16, 23, 16, 22, 17, 13, 15, 22, 18, 15, 21, 17, 16, 22, 8, 15, 18, 20, 17, 20, 22, 12, 13, 21, 15, 19, 22, 18, 18, 21, 13, 22, 17, 18, 20, 22, 22, 12, 1, 18, 9, 20, 23, 18, 18, 18, 21, 10, 16, 17, 12, 20, 16, 23, 16, 22, 18, 15, 14, 22, 4, 12, 18, 9, 22, 17, 19, 22, 22, 11, 19, 21, 17, 23, 22, 23, 20, 21, 22, 19, 21, 21, 14, 7, 23, 21, 23, 19, 23, 15, 20, 22, 22, 20, 23, 20, 21, 11, 20, 19, 10, 21, 23, 23, 22, 18, 20, 7, 21, 21, 22, 16, 17, 22, 14, 7, 20, 22, 17, 16, 20, 12, 22, 20, 22, 14, 23, 12, 20, 23, 21, 15, 21, 22, 21, 5, 22, 20, 18, 18, 18, 21, 21, 17, 19, 23, 21, 22, 19, 20, 22, 19, 19, 21, 21, 12, 15, 21, 21, 21, 16, 19, 7, 1, 16, 9, 23, 18, 23, 23, 16, 12, 22, 23, 21, 23, 23, 7, 21, 16, 21, 21, 16, 18, 21, 17, 23, 19, 22, 21, 18, 23, 22, 20, 19, 22, 22, 14, 21, 6, 21, 22, 17, 22, 11, 20, 23, 1, 24, 22, 14, 16, 22, 20, 21, 20, 20, 20, 17, 21, 14, 14, 22, 20, 23, 15, 15, 18, 14, 20, 21, 12, 13, 21, 20, 21, 13, 20, 19, 19, 14, 22, 22, 15, 14, 18, 20, 21, 20, 20, 16, 14, 20, 23, 23, 4, 21, 19, 19, 20, 21, 19, 12, 20, 15, 18, 18, 15, 21, 22, 21, 22, 23, 23, 20, 23, 22, 20, 12, 23, 22, 21, 22, 21, 10, 23, 23, 23, 14, 11, 22, 23, 12, 19, 22, 16, 21, 18, 23, 17, 23, 21, 12, 22, 23, 21, 23, 16, 21, 12, 8, 12, 21, 21, 18, 20, 17, 12, 20, 20, 19, 14, 22, 18, 16, 23, 17, 15, 19, 22, 14, 16, 21, 20, 23, 20, 19, 20, 19, 23, 13, 17, 21, 14, 12, 21, 21, 21, 19, 18, 7, 22, 17, 19, 16, 23, 21, 22, 22, 22, 11, 21, 20, 16, 22, 19, 16, 20, 18, 20, 20, 21, 22, 14, 22, 19, 21, 22, 23, 14, 23, 18, 11, 18, 11, 18, 17, 21, 22, 21, 20, 17, 16, 20, 23, 21, 17, 14, 16, 18, 19, 22, 17, 19, 20, 17, 23, 21, 21, 15, 17, 20, 19, 22, 23, 16, 20, 17, 16, 11, 1, 21, 23, 20, 21, 20, 10, 19, 21, 17, 21, 23, 19, 15, 20, 21, 22, 13, 15, 21, 20, 19, 10, 21, 19, 19, 19, 23, 18, 19, 14, 22, 17, 16, 23, 15, 21, 20, 22, 22, 21, 15, 22, 17, 19, 22, 21, 23, 6, 23, 22, 16, 18, 23, 23, 6, 22, 19, 19, 14, 23, 18, 16, 21, 22, 20, 22, 21, 10, 22, 20, 22, 19, 12, 22, 13, 22, 1, 15, 22, 1, 16, 21, 23, 23, 16, 17, 8, 16, 18, 22, 16, 21, 22, 8, 19, 19, 18, 18, 18, 21, 18, 19, 19, 21, 18, 23, 23, 7, 20, 18, 18, 23, 23, 12, 17, 15, 16, 22, 22, 22, 20, 7, 20, 22, 23, 19, 23, 13, 20, 16, 20, 18, 18, 18, 17, 23, 22, 22, 17, 20, 19, 18, 22, 16, 23, 17, 20, 23, 22, 20, 18, 18, 21, 19, 23, 10, 21, 2, 14, 17, 16, 23, 21, 21, 16, 21, 8, 19, 18, 21, 20, 20, 21, 23, 18, 19, 15, 17, 19, 21, 21, 16, 21, 21, 20, 21, 20, 20, 20, 20, 21, 7, 15, 19, 23, 17, 18, 19, 12, 21, 19, 14, 19, 18, 19, 15, 23, 22, 17, 16, 19, 23, 6, 22, 22, 19, 18, 20, 22, 22, 20, 19, 15, 19, 15, 23, 13, 11, 21, 22, 21, 15, 17, 1, 24, 23, 23, 22, 19, 8, 23, 19, 17, 21, 18, 23, 21, 10, 21, 21, 19, 20, 23, 22, 21, 22, 12, 18, 17, 19, 21, 21, 23, 11, 22, 18, 19, 21, 23, 22, 23, 19, 21, 22, 16, 19, 19, 17, 23, 21, 18, 8, 20, 22, 22, 21, 17, 20, 15, 20, 15, 22, 20, 14, 19, 22, 17, 15, 22, 23, 23, 22, 20, 19, 21, 19, 19, 14, 23, 12, 23, 19, 22, 19, 23, 18, 16, 23, 16, 18, 18, 17, 23, 19, 23, 23, 20, 22, 9, 22, 16, 17, 21, 22, 16, 23, 16, 22, 16, 17, 10, 22, 22, 23, 15, 21, 17, 17, 19, 23, 21, 20, 15, 21, 18, 15, 20, 17, 20, 20, 22, 11, 22, 11, 22, 10, 19, 21, 20, 23, 23, 16, 20, 18, 19, 23, 21, 13, 21, 23, 16, 19, 23, 9, 14, 16, 12, 21, 21, 21, 23, 18, 21, 19, 20, 15, 23, 19, 21, 23, 21, 22, 22, 11, 21, 6, 20, 22, 17, 20, 19, 16, 17, 11, 13, 16, 23, 22, 22, 23, 22, 23, 19, 22, 15, 13, 7, 19, 10, 23, 19, 17, 17, 21, 13, 22, 15, 17, 13, 21, 21, 23, 19, 7, 20, 18, 21, 23, 16, 1, 24, 20, 16, 13, 23, 13, 21, 21, 23, 20, 21, 5, 18, 12, 23, 18, 22, 20, 19, 21, 21, 23, 22, 10, 20, 22, 10, 17, 22, 20, 23, 22, 21, 20, 21, 21, 17, 22, 20, 22, 20, 19, 21, 21, 14, 18, 21, 12, 19, 21, 21, 23, 18, 21, 7, 23, 23, 23, 22, 23, 12, 22, 19, 17, 18, 18, 20, 20, 22, 17, 19, 21, 17, 15, 9, 23, 15, 22, 21, 13, 19, 18, 5, 23, 19, 15, 17, 23, 13, 20, 22, 23, 23, 16, 20, 23, 22, 23, 20, 19, 13, 14, 20, 19, 20, 23, 14, 23, 15, 22, 21, 19, 20, 21, 20, 21, 16, 22, 20, 21, 11, 8, 23, 22, 23, 21, 4, 20, 23, 7, 23, 22, 17, 23, 19, 5, 15, 23, 22, 23, 23, 23, 21, 20, 22, 19, 21, 17, 21, 23, 23, 21, 13, 18, 21, 19, 20, 19, 22, 15, 16, 23, 20, 23, 14, 22, 23, 22, 18, 14, 21, 15, 20, 22, 19, 20, 21, 15, 16, 16, 23, 23, 20, 15, 17, 23, 22, 18, 14, 18, 19, 13, 21, 20, 18, 23, 20, 22, 21, 13, 23, 1, 22, 18, 22, 19, 22, 20, 22, 10, 21, 23, 18, 6, 16, 18, 16, 16, 23, 17, 18, 22, 22, 18, 21, 22, 23, 20, 21, 23, 19, 18, 18, 19, 19, 18, 14, 14, 22, 22, 13, 17, 21, 17, 13, 13, 13, 14, 20, 22, 22, 21, 13, 16, 21, 22, 22, 15, 21, 6, 21, 16, 22, 11, 23, 23, 19, 23, 21, 13, 21, 21, 21, 22, 20, 20, 17, 21, 23, 22, 21, 23, 20, 23, 20, 17, 22, 23, 19, 13, 16, 20, 22, 11, 20, 13, 17, 23, 21, 21, 19, 16, 18, 17, 23, 23, 19, 22, 21, 11, 21, 21, 18, 19, 23, 16, 19, 15, 11, 20, 7, 18, 22, 23, 17, 18, 21, 10, 21, 18, 18, 17, 20, 21, 17, 20, 18, 20, 22, 23, 20, 20, 23, 23, 21, 13, 20, 21, 20, 17, 23, 21, 14, 19, 15, 18, 22, 23, 23, 8, 16, 22, 17, 17, 23, 13, 15, 23, 21, 16, 22, 23, 13, 23, 8, 19, 22, 21, 22, 23, 22, 23, 23, 20, 17, 23, 14, 20, 23, 8, 21, 23, 13, 20, 1, 24, 19, 15, 20, 23, 17, 7, 22, 9, 23, 22, 14, 20, 4, 20, 21, 20, 4, 22, 14, 20, 4, 22, 13, 20, 4, 22, 17, 20, 4, 22, 20, 4, 21, 11, 20, 4, 22, 11, 20, 4, 23, 18, 20, 4, 22, 23, 4, 19, 22, 4, 22, 19, 21, 21, 22, 23, 22, 22, 21, 12, 23, 8, 22, 17, 21, 11, 21, 16, 23, 15, 21, 23, 19, 20, 21, 6, 16, 22, 12, 18, 20, 16, 21, 15, 13, 21, 23, 15, 23, 21, 12, 16, 22, 20, 18, 21, 23, 20, 23, 21, 21, 23, 18, 12, 15, 22, 22, 14, 21, 11, 18, 5, 15, 16, 19, 13, 22, 12, 17, 21, 23, 23, 22, 20, 22, 19, 19, 20, 19, 18, 18, 21, 23, 18, 18, 21, 19, 16, 23, 19, 21, 17, 23, 21, 23, 11, 21, 23, 22, 18, 19, 23, 19, 17, 22, 23, 12, 22, 23, 12, 23, 22, 23, 21, 15, 18, 21, 16, 10, 23, 21, 21, 15, 20, 14, 23, 21, 19, 18, 23, 22, 22, 10, 21, 20, 20, 5, 21, 23, 23, 15, 22, 9, 19, 20, 21, 5, 22, 19, 17, 20, 15, 19, 11, 23, 23, 2, 23, 13, 21, 22, 22, 15, 18, 23, 22, 9, 23, 15, 20, 20, 5, 21, 23, 18, 14, 19, 23, 5, 8, 23, 19, 23, 19, 18, 23, 17, 20, 18, 16, 18, 21, 15, 20, 5, 15, 23, 15, 23, 18, 19, 16, 20, 18, 15, 18, 22, 21, 23, 19, 16, 17, 18, 21, 15, 14, 19, 5, 17, 18, 14, 21, 22, 14, 22, 16, 18, 20, 23, 18, 21, 7, 19, 21, 22, 22, 11, 18, 20, 21, 20, 19, 23, 16, 19, 23, 21, 23, 5, 20, 23, 23, 14, 19, 21, 21, 22, 21, 18, 23, 20, 21, 22, 23, 10, 20, 19, 17, 22, 19, 19, 17, 15, 13, 22, 18, 15, 14, 23, 22, 20, 17, 14, 21, 21, 22, 22, 22, 19, 17, 20, 16, 10, 11, 23, 13, 22, 21, 21, 19, 22, 15, 23, 14, 22, 20, 8, 19, 5, 19, 23, 16, 22, 19, 19, 16, 22, 22, 20, 20, 17, 18, 14, 22, 14, 21, 18, 19, 23, 15, 18, 15, 14, 23, 17, 17, 21, 23, 18, 12, 16, 16, 20, 23, 19, 14, 23, 22, 19, 23, 18, 18, 18, 20, 18, 15, 14, 23, 22, 21, 23, 20, 23, 13, 20, 20, 14, 23, 2, 23, 18, 23, 23, 16, 17, 22, 18, 23, 12, 20, 20, 16, 20, 17, 18, 23, 15, 18, 21, 19, 17, 18, 16, 19, 15, 18, 13, 16, 23, 22, 14, 9, 19, 20, 19, 20, 5, 19, 22, 18, 22, 23, 21, 20, 14, 23, 22, 20, 23, 23, 18, 18, 22, 19, 21, 11, 22, 13, 13, 20, 23, 19, 23, 18, 5, 19, 20, 22, 19, 19, 22, 8, 23, 19, 23, 21, 23, 14, 22, 13, 19, 21, 23, 18, 15, 18, 23, 20, 17, 16, 14, 18, 22, 13, 18, 18, 21, 23, 23, 23, 21, 19, 22, 22, 23, 23, 13, 17, 18, 18, 22, 14, 21, 19, 21, 15, 18, 6, 23, 23, 23, 21, 15, 17, 18, 21, 22, 20, 18, 11, 20, 23, 15, 18, 20, 20, 21, 18, 21, 19, 14, 22, 23, 16, 18, 22, 20, 19, 14, 13, 22, 20, 13, 21, 5, 22, 22, 22, 22, 22, 12, 18, 21, 19, 14, 21, 18, 23, 16, 23, 17, 23, 21, 19, 22, 22, 14, 19, 20, 21, 17, 20, 14, 23, 19, 23, 22, 16, 18, 21, 12, 22, 14, 20, 21, 5, 19, 15, 21, 20, 20, 22, 12, 23, 21, 18, 21, 18, 22, 19, 17, 2, 24, 21, 20, 22, 20, 20, 20, 19, 15, 19, 22, 22, 19, 23, 20, 20, 22, 20, 20, 20, 19, 15, 19, 22, 22, 19, 23, 11, 23, 16, 19, 19, 23, 19, 22, 21, 14, 22, 17, 23, 2, 18, 20, 10, 21, 22, 19, 18, 19, 16, 16, 19, 21, 21, 2, 22, 21, 22, 21, 21, 21, 22, 23, 21, 21, 22, 21, 21, 21, 22, 23, 13, 22, 21, 22, 21, 21, 21, 22, 23, 21, 21, 22, 21, 21, 21, 22, 23, 13, 23, 21, 21, 18, 20, 20, 4, 19, 19, 16, 19, 18, 18, 19, 17, 20, 23, 23, 14, 2, 22, 21, 22, 21, 21, 21, 22, 23, 21, 21, 22, 21, 21, 21, 22, 23, 13, 22, 21, 22, 21, 21, 21, 22, 23, 21, 21, 22, 21, 21, 21, 22, 23, 13, 21, 22, 23, 20, 20, 23, 21, 22, 20, 18, 20, 16, 22, 20, 23, 18, 20, 16, 2]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "path = r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\attention_is_all_you_need.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "chunk_size = 24\n",
    "chunk_overlap = 10\n",
    "\n",
    "rc_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "docs = rc_splitter.split_documents(data)\n",
    "\n",
    "print(docs[0])\n",
    "print(docs[0].metadata)\n",
    "print(docs[0].page_content[:1000]) # Print first 100 characters of the first document)\n",
    "print([len(doc.page_content) for doc in docs])  # Print length of each document's content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a270654",
   "metadata": {},
   "source": [
    "## ‚≠ê3. RAG Storage and Retrieval Using Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb916ef5",
   "metadata": {},
   "source": [
    "![img_4](https://raw.githubusercontent.com/mohd-faizy/GenAI-with-Langchain-and-Huggingface/refs/heads/main/_Developing_LLMs_Applications_with_LangChain/_img/0304.jpeg)\n",
    "\n",
    "\n",
    "**Concept Overview:**\n",
    "- Vector databases store and retrieve document embeddings.\n",
    "- Common choices include Chroma, Pinecone, FAISS, etc.\n",
    "- Use retrievers to query documents most similar to a user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcabcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Chroma Vector Store with Google Gemini Embeddings\n",
    "\n",
    "# Import necessary modules for LLM, embeddings, vector store, document handling, and environment variable loading\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Google Gemini 1.5 Flash language model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    # temperature=0.2,  # (optional) control creativity\n",
    "    # max_tokens=50     # (optional) limit output length\n",
    ")\n",
    "\n",
    "# Initialize the embedding function using Google's embedding model\n",
    "embedding_function = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\"\n",
    ")\n",
    "\n",
    "# Create example documents with metadata\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"In all marketing copy, TechStack should always be written with the T and S capitalized.\",\n",
    "        metadata={\"guideline\": \"brand-capitalization\"}  # Tagging the guideline type\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Our users should be referred to as techies in both internal and external communications.\",\n",
    "        metadata={\"guideline\": \"referring-to-users\"}  # Tagging the guideline type\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create a Chroma vector store from the documents, using the embedding function\n",
    "# Persist the data to a local directory for future retrieval\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=\" \"  # Save vector DB locally\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store to fetch the top 2 most similar documents based on embeddings\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",         # Use similarity search\n",
    "    search_kwargs={\"k\": 2}            # Retrieve top 2 similar docs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c558c2",
   "metadata": {},
   "source": [
    "## ‚≠ê4. Chaining it All Together with Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd625198",
   "metadata": {},
   "source": [
    "**Concept Overview:**\n",
    "- Use LangChain's `ChatPromptTemplate` to build reusable prompt structures.\n",
    "- Chain retriever output with LLM using `RunnablePassthrough`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eef5f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "message = '''\n",
    "        Review and fix the following TechStack marketing copy with the following guidelines in consideration:\n",
    "\n",
    "        Guidelines:\n",
    "        {guidelines}\n",
    "\n",
    "        Copy:\n",
    "        {copy}\n",
    "\n",
    "        Fixed Copy:\n",
    "        '''\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"human\", message)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229f2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here at TechStack, our users are the best in the world!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = ({\"guidelines\": retriever, \"copy\": RunnablePassthrough()} \n",
    "             |prompt_template \n",
    "             |llm)\n",
    "\n",
    "response = rag_chain.invoke(\"Here at techstack, our users are the best in the world!\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c2a59",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c3c7cd",
   "metadata": {},
   "source": [
    "## Full c‚≠ïde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc986db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text does not explicitly state the main innovation of the \"Attention is All You Need\" paper.  While it mentions self-attention and multi-head attention, it doesn't identify either as the *main* innovation.\n"
     ]
    }
   ],
   "source": [
    "# This script:\n",
    "# 1. Loads a PDF and splits it into chunks\n",
    "# 2. Embeds the chunks using Google Gemini embeddings\n",
    "# 3. Stores them in a Chroma vector store\n",
    "# 4. Sets up a retriever for similarity search\n",
    "# 5. Creates a prompt template and links it to an RAG chain using Gemini LLM\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Load environment variables from .env file (e.g., API keys)\n",
    "load_dotenv()\n",
    "\n",
    "# --- Step 1: Load the PDF file ---\n",
    "pdf_path = r\"E:\\01_Github_Repo\\GenAI-with-Langchain-and-Huggingface\\_Developing_LLMs_Applications_with_LangChain\\_data\\attention_is_all_you_need.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "raw_documents = loader.load()\n",
    "\n",
    "# --- Step 2: Split the document into smaller overlapping text chunks ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "documents = splitter.split_documents(raw_documents)\n",
    "\n",
    "# --- Step 3: Generate vector embeddings using Gemini ---\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# --- Step 4: Store vectors in a Chroma vector database ---\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=os.getcwd()  # Save in current working directory\n",
    ")\n",
    "\n",
    "# --- Step 5: Create a retriever for similarity-based search ---\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Return top 3 most relevant chunks\n",
    ")\n",
    "\n",
    "# --- Step 6: Define prompt template for the RAG chain ---\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"\"\"\n",
    "      Answer the following question using only the provided context.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\")\n",
    "    ])\n",
    "\n",
    "# --- Step 7: Initialize the Gemini LLM for response generation ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# --- Step 8: Compose a Retrieval-Augmented Generation (RAG) chain ---\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} |\n",
    "    prompt_template |\n",
    "    llm\n",
    "    )\n",
    "\n",
    "# --- Step 9: Ask a relevant question about the paper ---\n",
    "question = \"What is the main innovation introduced by the 'Attention is All You Need' paper?\"\n",
    "\n",
    "# --- Step 10: Get and print the response from the RAG pipeline ---\n",
    "response = rag_chain.invoke(question)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
